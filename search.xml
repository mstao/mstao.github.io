<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[全限定名、简单名称和描述符是什么东西？]]></title>
    <url>%2F2018%2F09%2F18%2F%E5%85%A8%E9%99%90%E5%AE%9A%E5%90%8D%E3%80%81%E7%AE%80%E5%8D%95%E5%90%8D%E7%A7%B0%E5%92%8C%E6%8F%8F%E8%BF%B0%E7%AC%A6%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%9C%E8%A5%BF%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[在看Class文件的结构时，我们会遇到这样几个概念，全限定名（Fully Qualified Name）、简单名称（Simple Name）和描述符（Descriptor），那么这些是什么东东呢？ 首先来说全限定名，一个类的全限定名是将类全名的.全部替换为/，示例如下： 1me/mingshan/cglib/SampleClass 简单名称是指没有类型和参数修饰的方法或字段名称，比如一个类的test()方法，它的简单名称是test。 那么描述符是什么呢？下面是JVM规范的定义： A descriptor is a string representing the type of a field or method. 注意描述符的概念是针对Java字节码的。描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值。在JVM规范中，定义了两种类型的描述符，Field Descriptors 和 Method Descriptors。 Field Descriptors A field descriptor represents the type of a class, instance, or local variable. 字段描述符包含BaseType、ObjectType、ArrayType三部分，对于基本数据类型(byte、char、double、float、int、long、short、boolean)都用一个大写字母来表示，而对象用字符L加对象的全限定名和；来表示，具体表示如下： FieldType term Type Interpretation B byte signed byte C char Unicode character code point in the Basic Multilingual Plane, encoded with UTF-16 D double double-precision floating-point value F float single-precision floating-point value I int integer J long long integer L ClassName ; reference an instance of class ClassName S short signed short Z boolean true or false [ reference one array dimension 对于数组类型，每一个维度使用一个前置的[来描述，如一个定义为java.lang.String[][]类型的二维数组，将被记录为[[Ljava/lang/String;，一个double型数组double[][][]将被记录为[[[D。 Method Descriptors A method descriptor contains zero or more parameter descriptors, representing the types of parameters that the method takes, and a return descriptor, representing the type of the value (if any) that the method returns. 方法描述符用来描述方法，一个方法既有参数，又有返回值，那么在用描述符描述方法时，按照先参数列表，后返回值的顺序描述。参数列表按照参数的严格顺序放在一组小括号()内，如下： 1( &#123;ParameterDescriptor&#125; ) ReturnDescriptor 注意如果返回值为void，那么就是一个大写字母V表示。 例如，一个方法的定义如下： 1Object m(int i, double d, Thread t) &#123;...&#125; 那么它的描述符就是： 1(IDLjava/lang/Thread;)Ljava/lang/Object; 又如方法的参数列表和返回值为空，如下： 1void test() 它的描述符为： 1()V 最后上代码分析一波 我们新建Test类，包含一个成员变量和方法。 12345678910package me.mingshan.cglib;public class Test &#123; private int a; public String inc(int b) &#123; int c = a + b; return c + "666"; &#125;&#125; 利用javap -c Test来查看字节码，如下： 123456789101112131415161718public class me.mingshan.cglib.Test &#123; public me.mingshan.cglib.Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public java.lang.String inc(int); Code: 0: aload_0 1: getfield #2 // Field a:I 4: iload_1 5: iadd 6: istore_2 7: iload_2 8: invokedynamic #3, 0 // InvokeDynamic #0:makeConcatWithConstants:(I)Ljava/lang/String; 13: areturn&#125; 可以看到Field a:I和(I)Ljava/lang/String;， 没什么错^_^ 参考： jls JVM Descriptor 深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO之Channels]]></title>
    <url>%2F2018%2F09%2F10%2FNIO~Channels%2F</url>
    <content type="text"><![CDATA[Channel介绍Channel? 我们在使用Buffer的时候，需要往Buffer中放数据，再从Buffer中取数据，那么在NIO体系中，与Buffer交互是什么呢，没错，就是Channel。所有的NIO的I/O操作都是从Channel 开始的，读操作的时候将Channel中的数据填充到Buffer 中，而写操作时将Buffer中的数据写入到Channel中。 下面Channel的官方解释： A channel represents an open connection to an entity such as a hardware device, a file, a network socket, or a program component that is capable of performing one or more distinct I/O operations, for example reading or writing. As specified in the Channel interface, channels are either open or closed, and they are both asynchronously closeable and interruptible. 在官方文档中，Channels根据不同的使用场景实现不一样，官方文档Channels可以在以下场景使用： File channels Multiplexed, non-blocking I/O Asynchronous I/O FileChannel类支持从连接到文件的通道中读取字节和将字节写入到通道。 多路复用、非阻塞I/O由selector、selectable channels和SelectionKey提供，它比阻塞I/O更具可伸缩性。 异步通道是一种能够进行异步I/O操作的特殊通道。异步通道是非阻塞的，并定义方法来启动异步操作，返回表示每个操作的Future。 目前使用较多Channel的实现类有： FileChannel：文件通道，用于文件的读和写 DatagramChannel：用于 UDP 连接的接收和发送 SocketChannel：TCP通道，用于TCP数据传输 ServerSocketChannel：用于监听服务端某个端口进来的TCP请求 FileChannelJava针对支持通道的类提供了getChannel()方法来获取FileChannel，FileChannel是一个用来写、读、映射和操作文件的通道。下面是利用FileChannel读写文件的一个例子: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657FileInputStream fis = null;FileOutputStream fos = null;FileChannel inChannel = null;FileChannel outChannel = null;try &#123; fis = new FileInputStream("1.png"); fos = new FileOutputStream("2.png"); // 获取通道 inChannel = fis.getChannel(); outChannel = fos.getChannel(); // 创建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); while (inChannel.read(buffer) != -1) &#123; // 切换到读数据模式 buffer.flip(); // 将缓冲区的内容写入通道 outChannel.write(buffer); // 清空缓冲区 buffer.clear(); &#125;&#125; catch (Exception e) &#123; e.printStackTrace();&#125; finally &#123; if (inChannel != null) &#123; try &#123; inChannel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (outChannel != null) &#123; try &#123; outChannel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (fis != null) &#123; try &#123; fis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (fos != null) &#123; try &#123; fos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 由于FileChannel是抽象类，它的read、write和map通过其实现类FileChannelImpl实现，注意FileChannelImpl是在sun.nio.ch包中的，这里类需要在openjdk源码中看到，代码如下： 12345678910111213141516171819202122232425public int read(ByteBuffer dst) throws IOException &#123; ensureOpen(); if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; if (direct) Util.checkChannelPositionAligned(position(), alignment); int n = 0; int ti = -1; try &#123; beginBlocking(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.read(fd, dst, -1, direct, alignment, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); endBlocking(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125; 在这个方法中，会检测通道是否可用，如果操作position和size，会进行同步处理，加上对象锁，然后调用IOUtil类的read方法，注意是while循环，条件IOStatus是INTERRUPTED（系统底层调用中断？），在IOStatus类中，定义了一些常量，如下： 1234567@Native public static final int EOF = -1; // End of file@Native public static final int UNAVAILABLE = -2; // Nothing available (non-blocking)@Native public static final int INTERRUPTED = -3; // System call interrupted@Native public static final int UNSUPPORTED = -4; // Operation not supported@Native public static final int THROWN = -5; // Exception thrown in JNI code@Native public static final int UNSUPPORTED_CASE = -6; // This case not supported IOUtil的代码如下所示： 12345678910111213141516171819202122232425262728static int read(FileDescriptor fd, ByteBuffer dst, long position, boolean directIO, int alignment, NativeDispatcher nd) throws IOException &#123; if (dst.isReadOnly()) throw new IllegalArgumentException(&quot;Read-only buffer&quot;); if (dst instanceof DirectBuffer) return readIntoNativeBuffer(fd, dst, position, directIO, alignment, nd); // Substitute a native buffer ByteBuffer bb; int rem = dst.remaining(); if (directIO) &#123; Util.checkRemainingBufferSizeAligned(rem, alignment); bb = Util.getTemporaryAlignedDirectBuffer(rem, alignment); &#125; else &#123; bb = Util.getTemporaryDirectBuffer(rem); &#125; try &#123; int n = readIntoNativeBuffer(fd, bb, position, directIO, alignment,nd); bb.flip(); if (n &gt; 0) dst.put(bb); return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125;&#125; 通过上面的代码可以大致了解到，FileChannel读取数据过程如下： 判断用户传入的buffer是否是DirectBuffer，如果是直接由readIntoNativeBuffer进行读取 如果不是（directIO为false），申请一块和缓存同大小的DirectByteBuffer bb 读取数据到缓存bb，底层由NativeDispatcher的read实现 把bb的数据读取到dst（用户定义的ByteBuffer，在jvm中分配内存） 其他方法的具体实现细节可参考openjdk的代码，就不再分析了。 ServerSocketChannel和SocketChannelServerSocketChannel可以监听新进来的TCP连接，主要用于处理网络连接。对每一个新进来的连接都会创建一个SocketChannel。ServerSocketChannel可以被设置为阻塞或者非阻塞， 如果设置为阻塞，那么通道的读写等操作是阻塞的，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务 如果设置为非阻塞，那么读写请求并不会阻塞当前线程，在数据可读/写前当前线程可以继续做其它事情，所以一个单独的线程可以管理多个输入和输出通道。需要结合Selector使用。 下面仅介绍阻塞式的写法，非阻塞在Selector中详细探讨下。代码如下： Server端： 12345678910111213141516171819202122// 创建通道ServerSocketChannel server = ServerSocketChannel.open();// 绑定端口server.bind(new InetSocketAddress(9898));FileChannel outChannel = FileChannel.open(Paths.get("2.png"), StandardOpenOption.WRITE,StandardOpenOption.READ,StandardOpenOption.CREATE);// 获取客户端连接的通道SocketChannel socketChannel = server.accept();// 分配指定大小的缓冲区ByteBuffer buffer = ByteBuffer.allocate(1024);// 接受客户端的数据，并保存到本地while(socketChannel.read(buffer) != -1)&#123; buffer.flip(); outChannel.write(buffer); buffer.clear();&#125;// 关闭通道socketChannel.close();outChannel.close();server.close(); 通过上面代码我们可以总结下Server端的流程： 创建ServerSocketChannel通道 绑定ip地址和端口号 通过ServerSocketChannel的accept()方法创建一个SocketChannel对象，用户从客户端读/写数据 创建读数据/写数据缓冲区对象来读取客户端数据或向客户端发送数据 关闭SocketChannel和ServerSocketChannel Client端： 123456789101112131415161718// 获取通道SocketChannel client = SocketChannel.open(new InetSocketAddress("127.0.0.1", 9898));// 获取文件FileChannel inChannel = FileChannel.open(Paths.get("1.png"), StandardOpenOption.READ); // 分配缓冲区ByteBuffer buffer = ByteBuffer.allocate(1024);// 读取本地文件while (inChannel.read(buffer) != -1) &#123; buffer.flip(); client.write(buffer); buffer.clear();&#125;// 关闭inChannel.close();client.close(); 总结下Client端的流程： 获取SocketChannel，绑定ip和端口 创建读数据/写数据缓冲区对象来读取服务端数据或向服务端发送数据 关闭SocketChannel 参考 JDK API Java NIO 之 Channel（通道） 深入浅出NIO之Channel、Buffer Java进阶（五）Java I/O模型从BIO到NIO和Reactor模式]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Class类文件结构简单分析]]></title>
    <url>%2F2018%2F09%2F08%2FClass%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[代码编译的结果从本地机器码转变为字节码，是存储格式发展的一小步，却是编程语言的一大步。 在Java平台中，实现语言无关性基础是虚拟机和存储格式。Java虚拟机不和Java等运行在其上的语言绑定，它只是与Class文件这种特殊的字节码文件所关联，每一个类文件包含单个类、接口或模块的定义。 ClassFile的structureClass文件由一组8位字节为基础的二进制流。在最新的Java虚拟机规范中，Class文件由叫做ClassFile的structure组成。class文件结构在JVM占有重要地位，具体位于第四章，标题是“The class File Format”，总共五百多页的虚拟机规范，类文件结构就写了三百多页，是不是很可怕^_^ 那么这个东西长什么样呢？如下： 123456789101112131415161718ClassFile &#123; u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];&#125; 咦？怎么这么像C语言的结构体呢，说的没错，虚拟机规范这是这么描述的(pseudostructures 伪结构)，刚才说了，它的真实结构是一组以8位字节为基础单位的二进制流，包含多个数据项，各个数据项严格按照顺序紧凑的排列在Class文件中（后面再进行分析）。下面我们来看看这个伪结构包含了什么。 从上面的伪结构来看，u2、u4是什么鬼？后面的看着像是属性，那么u2、u4似乎是类型的样子，呃，，没错，这种东西被称为数据类型，而且在伪结构中只有两种数据类型，无符号数（unsigned quantity）和表（table）。 无符号数属于基本的数据类型，u2、u4分别代表2个字节、4个字节的无符号数。无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码的字符串。 那么cp_info、field_info、method_info和attribute_info就是所谓的table了，可以看出都是以_info结尾，这些存些什么数据呢？在一个类中，总有字段吧，那么就存到field_info里面，总有些方法吧，存到method_info，或许还会有常量什么的，存到cp_info里面，在Class文件、字段表、方法表都可以携带自己的attribute_info，用于描述某些场景专有的信息。 说完了伪结构的数据类型，uX和*_info后面那些类似字段名称的东西是什么意思呢？在虚拟机规范中，被称作item，原话这么说的： the contents of the structures describing the class file format arereferred to as items 好吧，不知道叫啥，就叫item吧，大家知道就行了(￣.￣)。 在介绍上面的items之前，我们先来一个简单的Java类编译后的Class的十六进制文件，源代码如下： 1234567public class Demo &#123; private int i; public int inc() &#123; return i + 1; &#125;&#125; 用javac编译后，我选择Hexpad这个编辑器来打开class文件，如下： magic与class文件的版本magic 每个Class文件的头四个字节被称为魔数（Magic Number），默认值为0xCAFEBABE，用于确定一个文件是否能被JVM接受。 minor_version, major_version 紧接着四个字节就是minor_version和major_version，看着像是版本号的意思，没错，这四个字节存储的是Class文件的版本号，第5和6个字节存储的是次版本号（Minor Version），第7个和8个字节存储的是主版本号（Major Version）。由上面的图片可知，minor_version为0x0000，major_version为0x0036，转为是十进制为54，即我用JDK10编译的。下面为各个版本JVM能接受Class文件版本号的范围： Java SE class file format version range 1.0.2 45.0 ≤ v ≤ 45.3 1.1 45.0 ≤ v ≤ 45.65535 1.2 45.0 ≤ v ≤ 46.0 1.3 45.0 ≤ v ≤ 47.0 1.4 45.0 ≤ v ≤ 48.0 5.0 45.0 ≤ v ≤ 49.0 6 45.0 ≤ v ≤ 50.0 7 45.0 ≤ v ≤ 51.0 8 45.0 ≤ v ≤ 52.0 9 45.0 ≤ v ≤ 53.0 10 45.0 ≤ v ≤ 54.0 constant_pool_count，constant_pool[]constant_pool_count 接着主版本号之后是常量池容量计数值（constant_pool_count），由于常量池中常量的数量是不固定的，所以需要一个u2类型的数据来统计。注意该值计数从1开始而不是0。如上图所示，constant_pool_count值为0x0013，转为十进制为19，这就代表常量池中有18项常量，索引值范围为1~18（1 ~ constant_pool_count - 1）。 可能此时会有疑问，为啥我一个常量没定义，常量池这么多常量呢？有这个疑问就对了，原因是常量池中不仅存放static final修饰的字段，这个被称作字面量（Literal），还包括符号引用（Symbolic References），在虚拟机规范中是这样写的： constants, class and interface names, field names, and other constants that arereferred to within the ClassFile structure and its substructures. 符号引用具体包括哪些呢？如下： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 access_flags在常量池结束之后，紧接着2个字节表示访问标志（access_flags），这个标志用于识别一些类和接口层次的访问信息。具体列表如下： Flag Name Value Interpretation ACC_PUBLIC 0x0001 Declared public; may be accessed from outside its package. ACC_FINAL 0x0010 Declared final; no subclasses allowed. ACC_SUPER 0x0020 Treat superclass methods specially when invoked by the invokespecial instruction. ACC_INTERFACE 0x0200 Is an interface, not a class. ACC_ABSTRACT 0x0400 Declared abstract; must not be instantiated. ACC_SYNTHETIC 0x1000 Declared synthetic; not present in the source code. ACC_ANNOTATION 0x2000 Declared as an annotation type. ACC_ENUM 0x4000 Declared as an enum type. ACC_MODULE 0x8000 Is a module, not a class or interface. ACC_MODULE 需要注意ACC_MODULE，这个是新增的，ACC_MODULE标志表示这个Class文件定义了一个模块，而不是一个类或接口。 ACC_SUPER 在jdk1.02之前，有个叫invokenonvirtual的指令。在1.02后，这个指令被改名叫做invokespecial。invokenonvirtual的时候没有invokespecial那样只允许调用superclass、private方法或方法。于是在所有的1.02后的class 都必须设置ACC_SUPER这个标志，来表明强加给invokespecial的新的约束必须要被遵守。 this_class, super_class, interfaces_count, interfaces[]this_class（类索引）、super_class（父类索引）都是一个u2类型的数据，而interfaces（接口索引集合）是一组u2类型的数据集合。Class文件由这三项来确定这个类的继承关系。 this_class（类索引）和 super_class（父类索引） 类索引和父类索引表示，它们各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONSTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量的全限定名字符串。大致如下： 1this_class -&gt; CONSTANT_Class_info -&gt; CONSTANT_Utf8_info interfaces_count（接口计数器） 这个项的值表示当前类或接口的直接超接口的数量。 interfaces[] （接口表） 就是这个类所实现的接口。里边同样是常量池的索引值。接口表里边的顺序和源代码的接口顺序是一致的。 fields_count，fields[]field_info（字段表）用于描述接口或者类中声明的变量。fields表中只包含当前类或接口中的字段，不包含超类或super 接口中的字段，也不包括在方法内部声明的局部变量。 methods_count，methods[]method_info用来表示当前类或接口中的某个方法的完整描述。 attributes_count, attributes[]在Class文件、字段表、方法表都可以携带自己的attribute_info，用于描述某些场景专有的信息。 参考： The Java® Virtual Machine Specification (Java SE 10 Edition) 深入理解Java虚拟机：JVM高级特性与最佳实践（第2版） 来自JVM的一封ClassFile介绍信]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO之Buffers]]></title>
    <url>%2F2018%2F08%2F29%2FNIO~Buffers%2F</url>
    <content type="text"><![CDATA[Buffer？我们很容易想到缓冲区的概念，在NIO中，它是直接和Channel打交道的缓冲区，通常场景或是从Buffer写入Channel，或是从Channel读入Buffer。Buffer是一个抽象类，Java提供如下图的实现类，我是直接在Eclipse截出来的^_^ 其实核心是ByteBuffer，除了布尔类型，所有原始类型都有相应的Buffer实现，只是包装了一下ByteBuffer而已，我们使用最多的通常是ByteBuffer。 我们应该将Buffer理解为一个数组，IntBuffer、CharBuffer、DoubleBuffer 等分别对应int[]、char[]、double[]等。 上图没有包括MappedByteBuffer，该类用户内存映射文件，放到最后再说吧。 Buffer有四个重要的属性，分别为：mark、position、limit、capacity，和两个重要方法分别为：flip和clear。Buffer的底层存储结构为数组。这四个属性有以下特点： 1mark &lt;= position &lt;= limit &lt;= capacity 那么这几个属性分别起着什么作用呢？下面的介绍都以ByteBuffer为例，来分析ByteBuffer的使用流程和原理。 下面是这四个属性的简单介绍： capacity ：缓冲区的容量大小 limit ：界限，表示缓冲区可以操作数据的大小。 （limit后数据不能进行读写） position: 位置，代表下一次的写入位置，初始值是 0，每往 Buffer 中写入一个值，position 就自动加 1 mark : 标记，表示记录当前position 的位置可以通过reset()来恢复到 mark的位置，初始为 -1 对ByteBuffer操作主要包括读和写，向缓冲区写入数据和从缓冲区读取数据会影响以上四个属性的值的变化，我们分别对读和写以及之间切换进行分析。 写操作 首先分配1024字节的缓冲区，然后向缓冲区放入5字节的字符串“abcde”，代码如下： 1234567891011121314151617String str=&quot;abcde&quot;;// 分配一个指定大小的缓冲区ByteBuffer buffer=ByteBuffer.allocate(1024);System.out.println(&quot;---------allocate------&quot;);System.out.println(buffer.position());System.out.println(buffer.limit());System.out.println(buffer.capacity());// 利用put() 向缓冲区放数据buffer.put(str.getBytes());System.out.println(&quot;--------放数据------&quot;);System.out.println(buffer.position());System.out.println(buffer.limit());System.out.println(buffer.capacity()); 初始化position，limit，capacity位置如下图所示 我们发现position为0，而limit和capacity均指向内存区域最大位置，代表此时缓存区内是空的，已放入capacity大小的数据。 当我们向缓冲区放入5个字节的数据，position，limit，capacity位置发生了变化，如下图所示 从上图可以看出，在写入数据后，position会向后移动5个位置，指向第六个位置，代表下次写数据的位置，limit和capacity没有改变。 切换到读操作 由写模式切换到读模式需要调用flip方法，这个方法是什么意思呢？在JDK源码中，此方法的代码如下： 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 从代码中我们可以清晰的看出，limit被设置为当前position的大小，position归0，mark还是为默认值-1，我们还是看图比较直观，如下图所示： 和上一张图片进行对比，我们可以发现limit替换了position的位置，代表当前可以操作的位置，在写的时候，limit的值代表最大的可写位置，在读的时候，limit的值代表最大的可读位置。很明显我们现在是要读数据，就代表最大可读位置。 读操作 通过filp方法切换为读模式后，我们就可以从缓存区里面读取数据，代码如下： 123456789// 从缓冲区读数据byte[] dst=new byte[buffer.limit()];buffer.get(dst);System.out.println("------读取数据-------");System.out.println(new String(dst,0,dst.length));System.out.println(buffer.position());System.out.println(buffer.limit());System.out.println(buffer.capacity()); 此时position，limit，capacity位置如下图所示 从上图可以看出，position的位置变成了5，由于我们将缓存区里面的数据读完了，就是这个情况，所以读操作的时候，每读一个值，position 就自动加 1。在HeapByteBuffer源码中，就是增加一个offset的偏移量。 123protected int ix(int i) &#123; return i + offset;&#125; 重复读数据 上一步读数据的操作已经将position移动了limit的位置，我们想读数据就读不到了，但能不能重复读取数据呢？肯定可以呀，这时我们就可以用rewind方法来重复读写，代码如下： 123456//rewind 可重复读数据buffer.rewind();System.out.println("------重复读取数据-------");System.out.println(buffer.position());System.out.println(buffer.limit());System.out.println(buffer.capacity()); 此时position，limit，capacity位置如下图所示 有没有发现和flip操作后一致，此时肯定要一样了，这样我们才可以重复读取。 清空缓冲区 此时我们不想要缓冲区的数据了，需要清空掉，可以用clear方法来操作，代码如下 123456// 清空缓冲区，缓冲区的数据仍然存在，但处于被遗忘的状态，不能被读取buffer.clear();System.out.println("------清空缓冲区-------");System.out.println(buffer.position());System.out.println(buffer.limit());System.out.println(buffer.capacity()); 此时position，limit，capacity位置如下图所示 注意缓冲区的数据仍然存在，但处于被遗忘的状态，不能被读取 mark() &amp; reset() 除了 position、limit、capacity 这三个基本的属性外，还有一个常用的属性就是 mark。 mark 用于临时保存 position 的值，每次调用 mark() 方法都会将 mark 设值为当前的 position，便于后续需要的时候使用。 1234public final Buffer mark() &#123; mark = position; return this;&#125; 那到底什么时候用呢？考虑以下场景，我们在 position 为 5 的时候，先 mark() 一下，然后继续往下读，读到第 10 的时候，我想重新回到 position 为 5 的地方重新来一遍，那只要调一下 reset() 方法，position 就回到 5 了。 1234567public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; rewind() &amp; clear() &amp; compact() rewind()：会重置 position 为 0，通常用于重新从头读写 Buffer。 12345public final Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; clear()：有点重置 Buffer 的意思，相当于重新实例化了一样。 通常，我们会先填充 Buffer，然后从 Buffer 读取数据，之后我们再重新往里填充新的数据，我们一般在重新填充之前先调用 clear()。 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; compact()：和 clear() 一样的是，它们都是在准备往 Buffer 填充新的数据之前调用。 前面说的 clear() 方法会重置几个属性，但是我们要看到，clear() 方法并不会将 Buffer 中的数据清空，只不过后续的写入会覆盖掉原来的数据，也就相当于清空了数据了。 而 compact() 方法有点不一样，调用这个方法以后，会先处理还没有读取的数据，也就是 position 到 limit 之间的数据（还没有读过的数据），先将这些数据移到左边，然后在这个基础上再开始写入。很明显，此时 limit 还是等于 capacity，position 指向原来数据的右边。 参考： Java NIO：Buffer、Channel 和 Selector NIO API]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot应用被系统Kill相关问题分析]]></title>
    <url>%2F2018%2F08%2F25%2FSpringBoot%E5%BA%94%E7%94%A8%E8%A2%AB%E7%B3%BB%E7%BB%9FKill%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[SpringBoot在启动的时候，有默认的JVM启动参数，在部署到Linux服务器上时，如果Linxus内存不够时，会导致应用被操作系统kill掉，导致部署的服务莫名其妙的挂掉，就我遇到的项目而言，记录SpringBoot的log如下： 1234562018-08-23 07:53:25.231 INFO [demo,,,,] 1 --- [ main] cn.com.superv.provider.Application : Started Application in 5.655 seconds (JVM running for 6.124)2018-08-23 07:55:02.080 INFO [demo,,,,] 1 --- [ Thread-3] ConfigServletWebServerApplicationContext : Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@19dfb72a: startup date [Thu Aug 23 07:53:20 GMT 2018]; root of context hierarchy2018-08-23 07:55:02.087 INFO [demo,,,,] 1 --- [ Thread-3] o.s.c.support.DefaultLifecycleProcessor : Stopping beans in phase 21474836472018-08-23 07:55:02.087 INFO [demo,,,,] 1 --- [ Thread-3] o.s.j.e.a.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown2018-08-23 07:55:02.088 INFO [demo,,,,] 1 --- [ Thread-3] o.s.j.e.a.AnnotationMBeanExporter : Unregistering JMX-exposed beans2018-08-23 07:55:02.099 INFO [demo,,,,] 1 --- [ Thread-3] com.alibaba.druid.pool.DruidDataSource : &#123;dataSource-1&#125; closed 才开始我以为代码写错了，导致应用启动崩溃，但我这个应用在另一台Linux机器上跑的挺好的，没有出现上面的问题。其中log中有以下日志： 12Unregistering JMX-exposed beans on shutdownUnregistering JMX-exposed beans 在网上查的信息说SpringBoot内嵌的Tomcat无法正常启动才导致这个错误，结合这个项目在其他机器上能运行，就排除了Tomcat的问题。后来我想想会不会是跟Linux内存有关系呢？我赶紧用top命令查看了服务器的内存的使用情况，我檫，16G的内存只剩下三百多兆了，看来是我项目运行的时候请求内存导致系统内存不足，被系统kill掉。这时可以用jinfo -flags &lt;pid&gt;命令来查看当前应用的JVM参数。运行 dmesg | grep &quot;(java)&quot;命令看看是不是操作系统把我的应用给干掉了，结果屏幕输入类似如下日志： 1Out of memory: Kill process[PID] [process name] score 这又是什么意思呢？好像是内存溢出被操作系统干掉了，所以一查，还真是Out of memory 问题，这通常是因为某时刻应用程序大量请求内存导致系统内存不足造成的，这通常会触发 Linux 内核里的 Out of Memory (OOM) killer，OOM killer会杀掉某个进程以腾出内存留给系统用，不致于让系统立刻崩溃。详细原因分析参考：linux 终端报错 Out of memory: Kill process[PID] [process name] score问题分析 我在网上发现一哥们和我遇到了一样的问题，链接：项目连续几天突然挂掉，不过他的比较严重，可能刚开始没有整明白这个问题发生的原因，内心慌乱，其实仔细分析就可以查到问题发生的蛛丝马迹，从而解决问题。 找到问题发生的原因，接下来就要思考如何解决了。既然是内存的问题，那我们来改变下JVM参数，将最大堆内存(-Xmx)调小点，并禁止伸缩，将-Xms和-Xmx设置一样大，项目就可以运行了，-Xmx和-Xms具体值根据服务器内存和项目运行占用内存进行优化设置。 另外这个问题我在用Docker启动SpringBoot应用中也遇到过，利用docker ps命令可以发现该容器正在运行，但外界就是无法通过开放的端口来访问，利用命令docker logs -f container-id来查看容器启动的log，发现日志和上述的一样，所以也需要设置JVM参数, 命令如下： 1docker run -e JAVA_OPTS=&apos;-Xmx512m&apos; -p 8080:8080 -t springboot/spring-boot-docker 最后推荐一个JVM调优相关的网站： 一只懂JVM参数的狐狸，非常好用，可以查看JVM参数介绍以及变迁，还可以根据机器生成推荐JVM参数，真好用啊^_^]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器传递Spring Profile]]></title>
    <url>%2F2018%2F08%2F22%2FDocker%E5%AE%B9%E5%99%A8%E5%90%AF%E7%94%A8Spring%20Profiles%2F</url>
    <content type="text"><![CDATA[我们在利用Docker启动SpringBoot应用时，需要在启动时指定Profile来确定运行环境，如果再需要指定其他参数，参数的传递就十分有必要了。下面是stackoverflow关于这方面的讨论，链接如下： Passing env variables to DOCKER Spring Boot 通过Dockerfile定义Spring Profile 通常在命令行中我们可以使用java -jar 运行 Spring Boot应用。而Profiles信息可以作为额外参数传递，比如-Dspring.profiles.active=dev 1java -Djava.security.egd=file:/dev/./urandom -Dspring.profiles.active=dev -jar app.jar 相似的，我们可以在Dockerfile中将Profile的信息作为参数传递进去，例如： 1234FROM openjdk:8-jdk-alpineVOLUME /tmpADD spring-boot-docker-0.0.1-SNAPSHOT.jar app.jarENTRYPOINT [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-Dspring.profiles.active=dev&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 需要注意最后的ENTRYPOINT一行，在这行中我们传递java命令以执行jar文件，所有需要的参数和值以逗号方式分隔传递。-Dspring.profiles.active=dev 是我们定义dev profile的地方，我们可以替换dev为任何需要的名字。 通过Docker run命令定义Spring Profile 可以将spring profile作为环境变量传递给docker run命令，使用 -e 标记。例如-e “SPRING_PROFILES_ACTIVE=dev”会将dev profile传递给Docker容器 1docker run -d -p 8080:8080 -e &quot;SPRING_PROFILES_ACTIVE=dev&quot; --name rest-api dockerImage:latest Dockerfile中改为 1ENTRYPOINT [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-Dspring.profiles.active=$&#123;SPRING_PROFILES_ACTIVE&#125;&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己如何实现一个简单的动态代理？]]></title>
    <url>%2F2018%2F08%2F19%2F%E8%87%AA%E5%B7%B1%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[经过对JDK动态代理实现原理的解析，我们会对动态代理的实现流程有个根本的认识，具体分析过程参考JDK动态代理实现原理这篇文章，这里就不多谈了。这篇文章主要思考如何去实现一个简易的动态代理，以便加深对其的理解。 模仿着JDK动态代理，我们需要一个代理Proxy类，一个InvocationHandler接口，同时实现一个类加载器，下面为定义的类。 具体实现流程为： 首先定义一个InvocationHandler接口，代码如下： 12345678public interface MyInvocationHandler &#123; /** * proxy: 正在返回的代理对象，一般情况下，都不使用该对象 * method: 正在被调用的方法 * args: 调用方法时传入的参数 */ Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 接口中有一个invoke方法，方法中有三个参数，分别是： proxy: 正在返回的代理对象，一般情况下，都不使用该对象 method: 正在被调用的方法 args: 调用方法时传入的参数 下面就需要实现代理类Proxy，动态代理的核心就是在这个类中实现的，主要功能包括如下几点： 动态生成代理类，类似$Proxy0.java 调用Java编译器，编译生成的代理类 将生成的class文件利用类加载器加载到内存中，然后进行实例化 调用自定义InvocationHandler的invoke方法 详细代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/** * * 定义自己的 Proxy代理 */public class MyProxy &#123; protected MyInvocationHandler h; // 定义回车键 static String rt = "\r\t"; // 用户的当前工作目录,包含项目名 static String workspace = System.getProperty("user.dir"); // 当前类包名 static String packageName = MyProxy.class.getPackage().getName(); /** * 私有构造器，该类禁止被实例化 */ @SuppressWarnings("unused") private MyProxy() &#123;&#125; /** * 由于 MyProxy 内部从不直接调用构造函数，所以 protected 意味着只有子类可以调用 * @param h */ protected MyProxy(MyInvocationHandler h) &#123; this.h = h; &#125; /** * 在内存中创建$proxy0 的实例 * @param loader * @param interfaces * @param h * @return * @throws IllegalArgumentException * @throws IOException */ @SuppressWarnings(&#123; "rawtypes", "resource", "unchecked" &#125;) public static Object createProxyInstance(ClassLoader loader, Class interfaces, MyInvocationHandler h) throws IllegalArgumentException, IOException &#123; Objects.requireNonNull(h); //实际运行这个动态类构造一个对象 System.out.println("=====自定义:类构造一个代理类的java对象"); Method[] methods = interfaces.getMethods(); String proxyClassString = "package pers.han;" + rt + "import java.lang.reflect.Method;" + rt + "public class $Proxy0 implements " + interfaces.getName() + "&#123;" + rt + "protected MyInvocationHandler h;" + rt + "public $Proxy0(MyInvocationHandler h)&#123;" + rt + "this.h=h;" + rt + "&#125;" + rt + getMethodString(methods,interfaces) + rt + "&#125;"; //我们将自定义的代理类转化为文件 String fileName = workspace+"/src/pers/han/$Proxy0.java"; File file = new File(fileName); //向文件写内容 FileWriter fw = new FileWriter(file); fw.write(proxyClassString); fw.flush(); //编译这个文件 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); System.out.println("comiler-" + compiler); StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null); Iterable units = fileManager.getJavaFileObjects(fileName); //编译这个任务 CompilationTask compTask = compiler.getTask(null, fileManager, null, null, null, units); compTask.call(); fileManager.close(); //编译完成后，是不是.java file.delete(); //编译后就是class文件，那么接下来就把这个class文件 加到内存 MyClassLoader classLoader = new MyClassLoader(workspace + "/src/pers/han"); try &#123; Class&lt;?&gt; proxy0Class = classLoader.findClass("$Proxy0"); //等类加载完之后 ，删除 File classFile = new File(workspace + "/src/pers/han/$Proxy0.class"); if (classFile.exists()) &#123; classFile.delete(); &#125; Constructor&lt;?&gt; m = proxy0Class.getConstructor(MyInvocationHandler.class); Object object = m.newInstance(h); return object; &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 实现的方法 * @param methods * @param interfaces * @return */ private static String getMethodString(Method[] methods, Class&lt;?&gt; interfaces) &#123; String proxyMe = ""; for (Method m : methods) &#123; proxyMe += "public void " + m.getName() + "() throws Throwable &#123;" + rt + "Method md=" + interfaces.getName() + ".class.getMethod(\"" + m.getName() + "\", new Class[]&#123;&#125;);" + rt + "this.h.invoke(this,md,null);" + rt + "&#125;" + rt; &#125; return proxyMe; &#125;&#125; 将类加载到内存中需要自定义类加载器，这里继承ClassLoader类，然后重写findClass方法，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 自己的类加载器 * @author mingshan * */public class MyClassLoader extends ClassLoader &#123; private File dir; public MyClassLoader(String path) &#123; dir = new File( path ); &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; if (dir != null) &#123; File classFile = new File(dir, name + ".class"); if (classFile.exists()) &#123; FileInputStream input = null; try &#123; input = new FileInputStream(classFile); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int len; while ((len=input.read(buffer)) != -1) &#123; baos.write(buffer, 0, len); &#125; return defineClass("pers.han." + name, baos.toByteArray(), 0, baos.size()); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (input != null) &#123; try &#123; input.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; return null; &#125;&#125; 生成的代理类$Proxy0.java： 12345678910111213package pers.han; import java.lang.reflect.Method; public class $Proxy0 implements pers.han.Person&#123; protected MyInvocationHandler h; public $Proxy0(MyInvocationHandler h)&#123; this.h=h; &#125; public void say() throws Throwable &#123; Method md=pers.han.Person.class.getMethod(&quot;say&quot;, new Class[]&#123;&#125;); this.h.invoke(this,md,null); &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK中的反射]]></title>
    <url>%2F2018%2F08%2F19%2FJDK%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[反射是Java语言中一个比较重要的特性，它允许对正在运行的Java进行观测，甚至动态修改程序，即在运行态，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性。 反射API介绍获取Class对象通常来说，使用反射API的第一步是获取Class对象，在Java中比较常见的有以下几种： 已知具体的类，通过类的class属性获取，对于基本类型来说，它们的包装类型（wrapper classes）拥有一个名为“TYPE”的final静态字段，指向该基本类型对应的Class对象 已知某个类的实例，调用对象的getClass()方法获取Class对象 已知一个类的全类名，使用静态方法Class.forName来获取 例如，Integer.TYPE 指向 int.class。对于数组类型来说，可以使用类名 +“[ ].class”来访问，如 int[ ].class。 除此之外，Class 类和 java.lang.reflect 包中还提供了许多返回 Class 对象的方法。例如，对于数组类的 Class 对象，调用 Class.getComponentType() 方法可以获得数组元素的类型。 我们还可以利用自定义Classloader来加载我们的类，然后可以获取到该类的Class对象。类似于下面的代码，注意代码可能会抛出异常。 12MyClassLoader classLoader = new MyClassLoader(workspace + "/src/me/mingshan");Class&lt;?&gt; proxy0Class = classLoader.findClass("$Proxy0"); 其他操作拿到Class对象后，我们可以进行很多操作，比如生成该类的实例，访问字段的值，调用方法等。 生成类的实例通过类的Class对象可以生成类的实例，有两种方式 调用的是无参数的构造函数进行实例化 1clazz.newInstance(); 可以选择调用哪个构造函数进行实例化，获取构造器可以传入参数来选择 12Constructor c = clazz.getConstructor();Object obj = c.newInstance(); 访问类的成员通过调用getFiles()/getgetConstructors()/getMethods()来访问该类的成员。同时我们会发现有些方法会带上Declared，这表示调用该方法不会返回父类的成员。 当然我们也可以直接获取类的某个成员，比如成员和方法。 12345// 获取字段Field field = clazz.getField("name");// 获取方法Method method=clazz.getMethod("studyHard", new Class[]&#123;String.class&#125;); 还有一点，我们可以获取该类实现的接口 12// 获取该类所实现的所有接口Class&lt;?&gt; interfaces[] = clazz.getInterfaces(); 对类成员操作当获取到类成员后，我们可以进行下一步操作。 使用 Constructor/Field/Method.setAccessible(true) 来绕开 Java 语言的访问限制。 使用 Constructor.newInstance(Object[]) 来生成该类的实例。 使用 Field.get/set(Object) 来访问字段的值。 使用 Method.invoke(Object, Object[]) 来调用方法。 获取泛型在Java中泛型有擦除机制，那么我们在运行时可不可以获取泛型的具体类型呢？答案是可以的。原因是Class类文件结构中有一个叫Signature的属性。它的作用是存储一个方法在字节码层面的特征签名。这个属性中保存的参数参数类型并不是原生类型，而是包括了参数化类型的信息。 获取成员变量的泛型信息比如在一个类Test中，有一个成员变量list，如下： 1private List&lt;String&gt; list; 现在我想直接想获取List的泛型，怎么获取呢？实现代码如下： 123456Type t = Test.class.getDeclaredField("list").getGenericType(); if (ParameterizedType.class.isAssignableFrom(t.getClass())) &#123; for (Type t1 : ((ParameterizedType) t).getActualTypeArguments()) &#123; System.out.print(t1 + ","); &#125;&#125; 由于可能会有多个泛型参数，例如Map，所以返回是一个数组。 获取类的泛型信息一个类是泛型类，在该类中我们可能需要获取这个泛型到底是啥，然后继续进行下面的逻辑，一个应用是Hibernate动态拼接HQL，需要知道泛型信息。那么如何操作？代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 通过反射获取泛型实例 */public class Genericity&lt;T&gt; &#123; @SuppressWarnings("rawtypes") protected Class clazz; @SuppressWarnings("unchecked") /** * 把泛型的参数提取出来的过程放入到构造函数中写，因为 * 当子类创建对象的时候，直接调用父类的构造函数 */ public Genericity() &#123; // 通过反射机制获取子类传递过来的实体类的类型信息 ParameterizedType type = (ParameterizedType) this.getClass().getGenericSuperclass(); //得到t的实际类型 clazz = (Class&lt;T&gt;) type.getActualTypeArguments()[0]; &#125; /** * 获取指定实例的所有属性名及对应值的Map实例 * @param entity 实例 * @return 字段名及对应值的Map实例 */ protected Map&lt;String, Object&gt; getFieldValueMap(T entity) &#123; // key是属性名，value是对应值 Map&lt;String, Object&gt; fieldValueMap = new HashMap&lt;String, Object&gt;(); // 获取当前加载的实体类中所有属性 Field[] fields = this.clazz.getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; Field f = fields[i]; // 属性名 String key = f.getName(); //属性值 Object value = null; // 忽略序列化版本ID号 if (! "serialVersionUID".equals(key)) &#123; // 取消Java语言访问检查 f.setAccessible(true); try &#123; value =f.get(entity); &#125; catch (IllegalArgumentException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; fieldValueMap.put(key, value); &#125; &#125; return fieldValueMap; &#125;&#125; 在上面的代码中，this.getClass().getGenericSuperclass()返回表示此 Class 所表示的实体（类、接口、基本类型或 void）的直接超类的Type，然后将其转换ParameterizedType。getActualTypeArguments()返回表示此类型实际类型参数的 Type 对象的数组。 反射Array相关APIreflect.Array类位于java.lang.reflect包下,它是个反射工具包，全是静态方法。我们可以利用这个类来对数组进行操作。 调用Class.getComponentType()获取数组元素的类型，代码如下： 12int[] arr = &#123;1,2,3,4,5&#125;;Class&lt;?&gt; c = arr.getClass().getComponentType(); 假设我们需要获取数组长度，用Array的静态方法获取： 1int len = Array.getLength(arr); 当然我们可以用Array类来创建数组，向数组添加元素，修改元素等，具体可以参考官方API。 最后推荐一个反射工具类，可以参考参考。 反射API参考： https://docs.oracle.com/javase/tutorial/reflect/ http://hg.openjdk.java.net/jdk10/jdk10/jdk/file/777356696811/src/java.base/share/classes/jdk/internal/reflect/ReflectionFactory.java#l80 http://hg.openjdk.java.net/jdk10/jdk10/jdk/file/777356696811/src/java.base/share/classes/jdk/internal/reflect/ReflectionFactory.java#l78 https://docs.oracle.com/javase/tutorial/reflect/class/classMembers.html https://docs.oracle.com/javase/10/docs/api/java/lang/reflect/package-summary.html 文章参考： 郑雨迪, JVM是如何实现反射的? 周志明，深入理解Java虚拟机:JVM高级特性与最佳实践（第2版）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins自动构建SpringBoot应用部署到Docker]]></title>
    <url>%2F2018%2F08%2F18%2FJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BASpringBoot%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E5%88%B0Docker%2F</url>
    <content type="text"><![CDATA[在开发SpringCloud微服务时，各个服务需要独立部署，手动部署比较麻烦，所以需要引入持续集成，Jenkins是一个非常好用的持续集成工具，十分好用。在使用Jenkins自动构建源码时，需要按照一定的步骤进行，步骤如下： 从Git获取源代码 代码审查 编译代码 打包文件 部署到Docker 以上步骤我们手动也可以完成，但我们都喜欢自动化，自己点一点就能搞定，干嘛还要一步步来呢。 配置Jenkins环境我们直接使用Docker安装Jenkins，我是直接安装Jenkins每日更新的镜像，Jenkins地址，操作如下： 拉取镜像： 1docker pull jenkinsci/jenkins 修改文件夹的归属者和组： 1chown -R 1000:1000 jenkins_home/ 启动Jenkins容器： 1docker run -itd -p 8088:8080 -p 50000:50000 --name jenkins --privileged=true -v /usr/jenkins_home:/var/jenkins_home docker.io/jenkinsci/jenkins 然后再配置一些个人信息和插件。 新建任务首先我们需要新建Jenkins任务，选择Pipeline类型的任务，如下 然后配置下git信息和构建参数信息 构建参数主要有以下几个： BRANCH_NAME 分支名称 ENV 环境 TARGET_MACHINE_IP 部署集群IP SSH_PORT 部署机器SSH端口 TARGET_PORT 项目启动端口 说到SSH，不要忘了让jenkins服务器能够免密SSH访问目标机器，配置下authorized_key等信息。 接下来就需要编写Jenkinsfile文件了，这个文件需要放在项目主目录下，构建源码时Jenkins会读取该文件，按照该文件配置的步骤进行源码构建。 编写Jenkinsfile文件在Jenkinsfile文件中，利用pipeline来编写步骤。pipeline支持将连续输送Pipeline实施和整合到Jenkins，所以我们可以将上面提到的流程写到pipeline中。这里主要分以下五部： git clone check code build code release package deploy 前两步就不提了，编译用Maven构建代码，release package这一步为打包代码，将一些脚本和编译好的jar文件打包成压缩文件，等待部署。deploy需要将打包的压缩文件拷贝到目标机器上，再执行部署脚本。 详细的Jenkinsfile如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687pipeline &#123; agent any environment &#123; REPOSITORY=&quot;https://github.com/mstao/spring-boot-learning.git&quot; &#125; stages &#123; stage(&apos;git clone&apos;) &#123; steps &#123; echo &quot;&lt;&lt;&lt; Starting fetch code from git:$&#123;REPOSITORY&#125;&quot; git credentialsId: &quot;bd8b65ce-7fd2-4e57-a9fe-45d4fe2924bf&quot;, url: &quot;$&#123;REPOSITORY&#125;&quot;, branch: &quot;$BRANCH_NAME&quot; &#125; &#125; stage(&apos;check code&apos;) &#123; steps &#123; // chek code // Jenkins 集成 sonar 进行代码审查 echo &quot;&lt;&lt;&lt;Starting check and analytic code&quot; &#125; &#125; stage(&apos;build code&apos;) &#123; steps &#123; echo &quot;&lt;&lt;&lt; Starting build code and docker image&quot; withMaven ( maven: &apos;Maven 3.5.4&apos;, mavenLocalRepo: &apos;.repository&apos;) &#123; sh &apos;mvn clean package -Dmaven.test.skip=true&apos; &#125; &#125; &#125; stage(&apos;release package&apos;) &#123; steps &#123; echo &quot;&lt;&lt;&lt; release package to /var/jenkins_home/release/demo/$ENV/$BRANCH_NAME&quot; sh &apos;&apos;&apos; if [ -d target/demo ] then rm -rf target/demo fi mkdir -p target/demo &apos;&apos;&apos; sh &apos;&apos;&apos; cp target/*.jar target/demo/demo-api.jar cp deploy.sh target/demo/ cp Dockerfile target/demo/ cd target tar zcvf demo.tar.gz demo exit &apos;&apos;&apos; sh &apos;&apos;&apos; if [ ! -d /var/jenkins_home/release/demo/$ENV/$BRANCH_NAME ] then mkdir -p /var/jenkins_home/release/demo/$ENV/$BRANCH_NAME fi &apos;&apos;&apos; sh &apos;cp -f target/*.tar.gz /var/jenkins_home/release/demo/$ENV/$BRANCH_NAME&apos; &#125; &#125; stage(&apos;deploy&apos;) &#123; steps &#123; echo &quot;&lt;&lt;&lt; Starting deploy code to docker&quot; script &#123; try &#123; sh &apos;&apos;&apos; ssh -p $SSH_PORT -o StrictHostKeyChecking=no mingshan@$TARGET_MACHINE_IP rm -rf /app/tmp/demo/package ssh -p $SSH_PORT mingshan@$TARGET_MACHINE_IP mkdir -p /app/tmp/demo/package &apos;&apos;&apos; &#125; catch(e) &#123; echo e &#125; &#125; sh &apos;&apos;&apos; scp -P $SSH_PORT /var/jenkins_home/release/demo/$ENV/$BRANCH_NAME/*.tar.gz mingshan@$TARGET_MACHINE_IP:/app/tmp/demo/package/ ssh -p $SSH_PORT mingshan@$TARGET_MACHINE_IP &quot;tar -zxf /app/tmp/demo/package/demo.tar.gz -C /app/tmp/demo/package&quot; ssh -p $SSH_PORT mingshan@$TARGET_MACHINE_IP &quot;cd /app/tmp/demo/package/demo &amp;&amp; chmod +x * &amp;&amp; sh deploy.sh $TARGET_PORT&quot; exit &apos;&apos;&apos; echo &quot;deploy done&quot; &#125; &#125; &#125;&#125; 部署到Docker由于需要将打包的文件部署到Docker，所以需要将部署脚本和压缩文件发送到目标机器，在目标机器上制作Docker镜像，然后运行Docker 容器。 由于Docker需要root用户进行运行，而对于一些机器而言，拿不到root权限，所以需要进行一些操作，参考：免sudo使用docker命令 在Jenkinsfile中deploy步骤中，执行了以下命令： 1ssh -p $SSH_PORT mingshan@$TARGET_MACHINE_IP "cd /app/tmp/demo/package/demo &amp;&amp; chmod +x * &amp;&amp; sh deploy.sh $TARGET_PORT" 这是到目标机器上执行deploy.sh脚本，该脚本的内容如下： 123456789101112131415161718192021222324252627282930#!/bin/bashport=11001image=demoname=demo-serviceif [ -z $1 ]; then echo &quot;&lt;&lt;&lt; Using default port $port&quot;else echo &quot;&lt;&lt;&lt; Set port to $1&quot; $port=$1fiecho &quot;&lt;&lt;&lt; Fetch container id of $name&quot;CID=$(docker ps | grep &quot;demo-service&quot; | awk &apos;&#123;print $1&#125;&apos;)if [ &quot;$CID&quot; != &quot;&quot; ];then echo &quot;&lt;&lt;&lt; Stop and remove old container for $name&quot; docker stop $CID docker rm $CIDfiecho &quot;&lt;&lt;&lt; Remove old image $image&quot;docker rmi $imageecho &quot;&lt;&lt;&lt; Start to build docker image $image&quot;docker build -t $image .echo &quot;&lt;&lt;&lt; Start new container port: $port for $name&quot;docker run -d -p $port:8080 --name $name $image 在deploy.sh脚本中，主要分为以下几步： 停止和删除旧容器 删除旧镜像 构建新镜像 运行容器 这个脚本比较简单，按照上面的几步编写就行了。 最后附上项目的Dockerfile，也没啥说的。 Dockerfile1234FROM openjdk:8-jdk-alpineVOLUME /tmpADD spring-boot-docker-0.0.1-SNAPSHOT.jar app.jarENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Jenkins</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Docker搭建Nexus3私服]]></title>
    <url>%2F2018%2F08%2F05%2F%E5%88%A9%E7%94%A8Docker%E6%90%AD%E5%BB%BANexus3%E7%A7%81%E6%9C%8D%2F</url>
    <content type="text"><![CDATA[搭建私服对于一个团队来说十分有必要，利用Nexus3搭建私服十分方便，结合Docker，那是相当快速。 安装Nexus3拉取Nexus3的镜像 1docker pull sonatype/nexus3 创建文件夹，挂载目录1mkdir /var/nexus-data &amp;&amp; chown -R 200 /var/nexus-data 启动容器 1docker run -d -p 8081:8081 --name nexus -v /var/nexus-data:/nexus-data --restart=always sonatype/nexus3 开启端口 如果让外网访问的话，需要开放8081端口，在CentOS7中，可以利用firewall-cmd来开放端口 123456#开放11001端口 permanent为永久开放firewall-cmd --zone=public --add-port=8081/tcp --permanent#重新读取配置firewall-cmd --reload#查看全部开放端口firewall-cmd --list-all 接下来在浏览器中输入以下网址，就可以看到Nexus3界面了如下图所示，用户名和密码默认为admin，admin123 1http://ip:port 配置阿里云仓库启动Nexus后，需要将中央仓库配置为阿里云仓库，提高国内的访问速度。Nexus的仓库如下： 由上图看出，Nexus的仓库分为这么几类： hosted 宿主仓库：主要用于部署无法从公共仓库获取的包以及自己或第三方的包； proxy 代理仓库：代理公共的远程仓库； group 仓库组：Nexus 通过仓库组的概念统一管理多个仓库，这样我们在项目中直接请求仓库组即可请求到仓库组管理的多个仓库。 示意图如下： 现在点击“Create Repository”按钮，来添加阿里云仓库，Recipe选择maven2(proxy)，在具体配置页面取名aliyun-repository，这里建议用a开头(估计按字母排序将它排第一位)，URL输入：http://maven.aliyun.com/nexus/content/groups/public/，其他默认值即可。 配置maven接下来我们需要配置maven，打开setting.xml文件，在mirrors节点下加入以下配置（根据自己的配置更改）： 将&lt;mirror&gt;&lt;url&gt;标签内的地址修改成nexus服务的地址。 123456&lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;nexus maven&lt;/name&gt; &lt;url&gt;http://www.mingzhiwen.cn:8081/repository/maven-public/&lt;/url&gt;&lt;/mirror&gt; 然后在services节点下加入以下配置，&lt;servers&gt;标签内填写nexus服务的账号密码，发布maven项目到nexus时，需要用到。&lt;server&gt;&lt;id&gt;下id需要跟&lt;mirror&gt;&lt;id&gt;一致。 12345&lt;server&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 最后在项目中的pom.xml文件加入以下配置： 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Releases&lt;/name&gt; &lt;url&gt;http://&#123;your-nexus-ip&#125;:port/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Snapshot&lt;/name&gt; &lt;url&gt;http://&#123;your-nexus-ip&#125;:port/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 运行maven命令，将编译好的Jar包上传到Nexus私服中。 1mvn clean deploy 上传效果如下图所示： 参考 https://www.jianshu.com/p/dbeae430f29d https://github.com/sonatype/docker-nexus3]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Nexus3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[像是昨天]]></title>
    <url>%2F2018%2F08%2F01%2F%E5%83%8F%E6%98%AF%E6%98%A8%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[半夜醒来，想起前尘往事，遂成比文。我一写东西大多是唠叨，夹杂着些许不成熟的想法，姑且记录下来吧。 2016年7月，我的好朋友给我打了个电话让我去武汉玩，从此我真切感受到世界的另一面。本来不想把这些东西写成文章记录下来，但一直在心中憋着，就像一团结在心中缠绕，勒得心中直疼。再加上最近另一个好朋友也遇到此事，自己却没帮上什么忙。虽说自己也不懂什么大道理，说不出让人顿悟警醒的话，但基本的做人做事原则我还是能说上两句。时隔两年，心中除了惆怅和遗憾，还多了些许的无助感。 那么，2016年7月我遇到了什么事情呢？我遇到了所谓被称为传销的东西。传销这个词现在被人说烂了，我们没接触过的人听到这个词不会大惊小怪，新闻经常报道，即使是里面的人，直接会拿这个词给你说道说道，用他们的一套说辞来给你解释这个东西，直到你信以为真。千万不要小看这个让你信以为真的过程，这个过程被称为洗脑，这个词也是很常见，他们用所谓的大道理，所谓的说了一百遍都狗屁不是的话让你确认他们说的是真理，是赚钱迈向成功的一条猛路子，以便达到他们不可告人、见不得光的目地。很多事情在暗地里表面上看起来还是那么一回事，但真正剖析这件事的前因后果，可能发现原来多美好的一件事情，背后指不定有什么道道。虽然结果令人沮丧，但还是要认真面对，因为这是对你人生成长极大的考验，不得不头脑清醒些。 才去的时候挺开心的，毕竟暑假没事在家待着无聊，出去转转散散心也挺好。当我好朋友带我去听人生中第一堂洗脑课时，整个人瞬间一愣，这是在讲什么，这么短时间就能赚这么多钱，不会是传销吧，这时我意识到我朋友可能被人拉进了传销。不过整个过程我十分镇定，依然笑容满面，谈笑风生，一点也没让人看出我内心的慌乱和翻腾。其实我内心早已翻江倒海了，我知道我是清醒的，我在听些什么，但我不确定我朋友内心此时是怎么想的，或者说我已经知道朋友内心是怎么想的，不过这是我最不愿看到的。但事实就是那么残酷，越不想相信的事情，现实就会逼着你去相信。但我看到我朋友坚定的眼神，决心似乎很大，这让我不由得担心起来了。我想劝劝我朋友，早日脱离苦海，但我们终是凡人，谁又能成了佛。 我接触了很多年纪轻轻的从业者，我始终相信他们是善良的，他们是被那些心中怀着鬼胎的垃圾利用了，被那些人操纵着思想，给他们一个光明的目标，他们就以为看到了太阳的曙光。不过他们又有什么错呢？他们只是想赚钱，或许是凭借着自己的“努力”吧，可惜努力用错了地方，光明也不是纯粹的光明。以前我最痛恨的是利用他人的无知来谋取利益，现在呢？把你思想先改变了，再利用你来赚钱，这是最无耻的，也是悄无声息的，所以很多人不知不觉走上了这样的道路，真是可惜可叹。 我不想发那么多的牢骚，因为没什么意思，但我还是愿意不厌其烦地告诫那么不愿意脚踏实地的同学，天下没那么多好事，不要以为自己走了好运而沾沾自喜，那很有可能是别人挖好了坑等着你跳。我们还太年轻，虽说吃点亏不算什么，但不能因为这个坑而改变了自己的所有。人时有穷尽，力所不能及，还是多想想吧。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建一个Tomcat的Docker镜像]]></title>
    <url>%2F2018%2F07%2F28%2F%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AATomcat%E7%9A%84Docker%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[最近在看Docker，对一个事物由陌生到熟悉需要一个过程，而这个过程需要从动手实践开始，下面记录一下我从零开始构建centos7+jdk8+tomcat8.5的docker镜像。 CentOS7 Docker 安装Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker。通过 uname -r 命令查看你当前的内核版本 利用yum安装docker 1yum -y install docker-io 安装完成后，启动docker服务 1service docker start 测试一下 1docker run hello-world 准备文件和构建环境本次需要构建Tomcat的Docker镜像，所以需要Tomcat和JDK安装包，版本分别是 123apache-tomcat-8.5.32.tar.gzjdk-8u172-linux-x64.tar.gz 创建/usr/docker-tomcat文件夹，将以上两个文件解压到该文件夹中，分别重命名为tomcat和jdk文件夹。 创建Dockerfile和run.sh两个文件，最终/usr/docker-tomcat文件夹内容如下图所示： 编辑Dockerfile文件 1vim Dockerfile 向该文件添加如下内容： 123456789101112131415161718192021222324252627# 设置继承的镜像FROM registry.cn-hangzhou.aliyuncs.com/repos_zyl/centos:0.0.1# 创建者信息MAINTAINER mingshan &quot;walkerhan@126.com&quot;# 设置环境变量，所有操作都是非交互式的ENV DEBIAN_FRONTEND noninteractive# 设置tomcat的环境变量ENV CATALINA_HOME /tomcatENV JAVA_HOME /jdk# 复制tomcat和jdk文件到镜像中ADD apache-tomcat /tomcatADD jdk /jdk# 复制启动脚本至镜像，并赋予脚本可执行权限ADD run.sh /run.shRUN chmod +x /*.shRUN chmod +x /tomcat/bin/*.sh# 暴露接口8080，这是我的tomcat接口，默认为8080EXPOSE 8080# 设置自启动命令CMD [&quot;/run.sh&quot;] 保存后，然后编辑run.sh文件 1vim run.sh 添加如下内容： 123#!/bin/bash# 启动tomcatexec $&#123;CATALINA_HOME&#125;/bin/catalina.sh run 保存后接下来就开始构建docker镜像文件 构建docker镜像文件我们可以利用docker build来构建Docker镜像，-t 设置tag名称, 命名规则registry/image:tag. 表示使用当前目录下的Dockerfile文件 1docker build -t tomcat:test . 执行该命令后，Docker就会按照Dockerfile文件顺序执行，会有很多步骤，下面是输出日志： 123456789101112131415161718192021222324252627282930313233343536373839404142434445Sending build context to Docker daemon 403.1 MBStep 1/12 : FROM registry.cn-hangzhou.aliyuncs.com/repos_zyl/centos:0.0.1 ---&gt; e1e65df66640Step 2/12 : MAINTAINER mingshan &quot;walkerhan@126.com&quot; ---&gt; Using cache ---&gt; f030a7c09868Step 3/12 : ENV DEBIAN_FRONTEND noninteractive ---&gt; Using cache ---&gt; ef3f61db3034Step 4/12 : ENV CATALINA_HOME /tomcat ---&gt; Running in 5145fe0de0d1 ---&gt; 9a4af98c3434Removing intermediate container 5145fe0de0d1Step 5/12 : ENV JAVA_HOME /jdk ---&gt; Running in 8bac05b87945 ---&gt; f5b7eb8d180eRemoving intermediate container 8bac05b87945Step 6/12 : ADD tomcat /tomcat ---&gt; d68a1754c19eRemoving intermediate container 29f7625a6b95Step 7/12 : ADD jdk /jdk ---&gt; df1669bd68deRemoving intermediate container dc7de6c936faStep 8/12 : ADD run.sh /run.sh ---&gt; 90a13284ec01Removing intermediate container 5bf2c6666a03Step 9/12 : RUN chmod +x /*.sh ---&gt; Running in 7f22e7927ffb ---&gt; 10fff91bfa16Removing intermediate container 7f22e7927ffbStep 10/12 : RUN chmod +x /tomcat/bin/*.sh ---&gt; Running in 163f103fcc0a ---&gt; da593ceeaa49Removing intermediate container 163f103fcc0aStep 11/12 : EXPOSE 8080 ---&gt; Running in d66d686928fe ---&gt; e2d7f915335aRemoving intermediate container d66d686928feStep 12/12 : CMD /run.sh ---&gt; Running in a7f9d1e9c9a0 ---&gt; a21030de3aacRemoving intermediate container a7f9d1e9c9a0Successfully built a21030de3aac 构建完成后，就可以启动容器啦 启动容器我们利用docker run来新建并启动容器，这个命令有很多参数，-d: 后台运行容器，并返回容器ID；-p: 端口映射，格式为：主机(宿主)端口:容器端口 1docker run -d -p 11001:8080 tomcat:test 然后使用 docker ps 命令查看正在运行的容器，如下图所示： 开启端口如果让外网访问的话，需要开放11001端口，在CentOS7中，可以利用firewall-cmd来开放端口 123456#开放11001端口 permanent为永久开放firewall-cmd --zone=public --add-port=11001/tcp --permanent#重新读取配置firewall-cmd --reload#查看全部开放端口firewall-cmd --list-all 接下来就可在浏览器中看到Tomcat界面了，大功告成！ 镜像保存为本地离线文件将docker image保存为离线的本地文件，执行docker save image_name &gt; ./save.tar或者 docker save -o filepath image_name 1234567[root@VM_0_6_centos docker-tocmat]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtomcat test a21030de3aac 2 hours ago 593 MBregistry.cn-hangzhou.aliyuncs.com/repos_zyl/centos 0.0.1 e1e65df66640 19 months ago 192 MB[root@VM_0_6_centos docker-tocmat]# docker save a21030de3aac &gt; ./up_tomcat.tar[root@VM_0_6_centos docker-tocmat]# lsDockerfile jdk run.sh tomcat up_tomcat.tar 其他操作 停止容器 1docker stop tomcat:test 启动容器 1docker start tomcat:test 删除容器 删除一个容器：1docker rm 278636f577a6 停用全部运行中的容器: 1docker stop $(docker ps -q) 删除全部容器： 1docker rm $(docker ps -aq) 一条命令实现停用并删除容器： 1docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq) 删除镜像 删除镜像需要先删除使用该镜像的容器，然后再删除镜像 1docker rmi 3ae3626adcfa 参考 https://www.jianshu.com/p/369e75f6303b https://www.cnblogs.com/zhouyalei/p/6390963.html http://www.dockerinfo.net/docker%e5%ae%b9%e5%99%a8-2]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashtable结构分析]]></title>
    <url>%2F2018%2F07%2F16%2FHashtable%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[哈希表（Hash Table，也叫散列表），是存储键值对（key-value）的数据结构，主要利用hash算法将key映射到表中，以便加快查找速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。对于数组而言，查找数据容易，但添加删除数据比较慢；对于链表来说，添加删除数据容易，但查找数据比较慢，所以哈希表结合数据和链表来实现数据快速的存取。 哈希表的实现主要需要解决两个问题，哈希函数和冲突解决。 哈希函数在哈希表内部，使用桶（bucket）来保存键值对，数组索引即为桶号，哈希函数决定了给定的键存于散列表的哪个桶中，例如下面的函数： 1index = f(key, array_size) 其中需要先通过key计算hash值，然后再利用算法计算出index，在维基百科中，有如下介绍： 12hash = hashfunc(key)index = hash % array_size 哈希函数和计算index的算法可以有很多种实现，但最终目的是能够均匀并独立地将所有的键散布在数组范围内。 冲突解决即使采用的哈希算法能够使键值均匀分布，但避免不了“碰撞”的出现，当两个不同的键值产生了相同值，这时就需要解决冲突。 解决冲突有很多种方法，比如拉链法和开地址法，这里主要分析拉链法的具体实现。 采用拉链法的哈希表，每个桶里都存放了一个链表。初始时所有链表均为空，当一个键被散列到一个桶时，这个键就成为相应桶中链表的首结点，之后若再有一个键被散列到这个桶（即发生碰撞），第二个键就会成为链表的第二个结点，以此类推。采用拉链法解决冲突的哈希表如下图所示： 具体实现对于哈希表而言，主要有增，删，获取操作，我们先来定义一个接口：12345678910public interface Map&lt;K,V&gt; &#123; public V put(K k,V v); public V get(K k); public V remove(K k); interface Entry&lt;K,V&gt;&#123; public K getKey(); public V getValue(); &#125;&#125; 在Map接口中，定义了三个方法put，get，remove三个方法，同时定义了一个内部接口Entry，用来表示key-value结构。 接下来我们就采用拉链法来实现上面的接口。首先定义一下常量，成员变量以及在类的构造函数初始化一些数据代码如下： 123456789101112131415161718192021222324252627282930// 默认大小static final int DEFAULT_INITIAL_CAPACITY = 16;// 默认负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;// 定义数组大小private int length;// 扩容标准 所使用的数组数量/数组长度 &gt; 0.75private float loadFactor;// 使用数组位置的总量private int useSize;// 定义Map 骨架 只要数组private Entry&lt;K, V&gt;[] table = null;public HashMapDemo() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;@SuppressWarnings("unchecked")public HashMapDemo(int length, float loadFactor) &#123; if (length &lt; 0) &#123; throw new IllegalArgumentException("参数不能为负数" + length); &#125; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) &#123; throw new IllegalArgumentException("扩容标准必须为大于0的数字" + length); &#125; this.length = length; this.loadFactor = loadFactor; this.table = (Entry&lt;K, V&gt;[])new Entry[length];&#125; 接下来下类的内存实现静态内存类Entry，由于采用了拉链法，所以需要用链表来存储具有相同的index的节点。代码如下： 12345678910111213141516171819static class Entry&lt;K, V&gt; implements Map.Entry&lt;K, V&gt; &#123; K k; V v; Entry&lt;K, V&gt; next; public Entry(K k,V v,Entry&lt;K, V&gt; next)&#123; this.k = k; this.v = v; this.next = next; &#125; public K getKey() &#123; return k; &#125; public V getValue() &#123; return v; &#125;&#125; hash算法那么如何实现hash算法呢？这个问题有点复杂，还是先看看jdk8中HashMap是如何实现的，下面是部分代码： 123456789101112131415161718192021222324/** * 用来通过自身数组的长度和key来确定存储位置 * @param k * @param length * @return */private int getIndex(K k, int length) &#123; // hashCode 与运算 int m = length - 1; int index = hash(k.hashCode()) &amp; m; // 三元运算符处理 return index &gt;= 0 ? index : -index;&#125;/** * jdk1.8中hashmap的hash算法 * @param hashCode * @return */private int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 从代码中可以看出，要获取索引位置需要以下步骤： 取 key 的 hashCode 值、高位运算、取模运算。 其中，key.hashCode()是Key自带的hashCode()方法，返回一个int类型的散列值。我们知道，32位带符号的int表值范围从-2147483648到2147483648。这样只要hash函数松散的话，一般是很难发生碰撞的，因为HashMap的初始容量只有16。但是这样的散列值我们是不能直接拿来用的。用之前需要对数组的长度取模运算。得到余数才是索引值。具体参看浅谈HashMap中的hash算法 快存将key-value数据存入到哈希表表中，首先需要判断是否需要扩容，这里需要利用负载因子(loadFactor)来判断，默认扩容两倍。然后利用哈希算法来获取索引位置index，判断当前位置是否有结点，如果没有结点，就将当前结点作为这个桶中链表的头结点；如果有节点，那么就将其放在链表的末尾。代码如下： 123456789101112131415161718192021/** * 快存 */@Overridepublic V put(K k, V v) &#123; if (useSize &gt; this.length * this.loadFactor) &#123; // 需要扩容 up2Size(); &#125; // 通过key来存储位置 int index = getIndex(k, table.length); Entry&lt;K,V&gt; entry = table[index]; if (entry == null) &#123; table[index] = new Entry&lt;K, V&gt;(k, v, null); &#125; else if (entry != null) &#123; table[index] = new Entry&lt;K, V&gt;(k, v, entry); &#125; useSize++; return table[index].getValue();&#125; 扩容代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 增大容量，这里扩容两倍 */@SuppressWarnings("unchecked")private void up2Size() &#123; Entry&lt;K, V&gt;[] newTable = (Entry&lt;K,V&gt;[])new Entry[2 * this.length]; // 原来数组有非常多的Entry对象，由于Entry对象散列，需要再次散列 againHash(newTable);&#125;/** * 存储的对象存储到新数组中（再次散列） * @param newTable */private void againHash(Entry&lt;K, V&gt;[] newTable) &#123; // 将数组里面的对象封装到List List&lt;Entry&lt;K, V&gt;&gt; entryList = new ArrayList&lt;Entry&lt;K, V&gt;&gt;(); for (int i = 0; i &lt; table.length; i++) &#123; if (table[i] == null) &#123; continue; &#125; foundEntryByNext(table[i], entryList); &#125; if (entryList.size() &gt; 0) &#123; useSize = 0; this.length = 2 * this.length; table = newTable; for (Entry&lt;K, V&gt; entry : entryList) &#123; if (entry.next != null) &#123; //形成链表关系取消掉 entry.next = null; &#125; put(entry.getKey(), entry.getValue()); &#125; &#125;&#125;/** * 寻找entry对象 * @param entry * @param entryList */private void foundEntryByNext(Entry&lt;K, V&gt; entry, List&lt;Entry&lt;K, V&gt;&gt; entryList) &#123; if (entry != null &amp;&amp; entry.next != null) &#123; // 说明entry对象已经形成链表结构 entryList.add(entry); // 需要递归 foundEntryByNext(entry.next, entryList); &#125; else &#123; entryList.add(entry); &#125;&#125; 快取从哈希表中根据key来取出元素比较简单，利用哈希算法计算出索引位置index，然后遍历链表即可。 12345678910111213141516171819202122/** * 快取 */@Overridepublic V get(K k) &#123; int index = getIndex(k, table.length); if (table[index] == null) &#123; throw new NullPointerException(); &#125; return findValueByEntryKey(k, table[index]);&#125;private V findValueByEntryKey(K k, Entry&lt;K, V&gt; entry) &#123; Entry&lt;K, V&gt; e = entry; while (e != null) &#123; if (k == e.getKey() || k.equals(e.getKey())) return e.getValue(); e = e.next; &#125; return null;&#125; 移除根据key将元素从哈希表中移除需要考虑以下几种情况： 该节点为链表头结点 该节点为链表中间节点 该节点为链表尾节点 然后按照上面的情况分别处理即可。 12345678910111213141516171819202122232425262728293031323334353637/** * 移除 * @param k */@Overridepublic V remove(K k) &#123; int index = getIndex(k, table.length); Entry&lt;K, V&gt; e = table[index]; Entry&lt;K, V&gt; prev = null; while (e != null &amp;&amp; (!(k == e.getKey() || (k != null &amp;&amp; k.equals(e.getKey()))))) &#123; prev = e; e = e.next; &#125; if (e == null) &#123; return null; &#125; Entry&lt;K, V&gt; next = e.next; if (prev != null &amp;&amp; next != null) &#123; prev.next = next; &#125; else if (prev != null &amp;&amp; next == null) &#123; prev.next = null; &#125; else if (prev == null &amp;&amp; next != null) &#123; // Node is the head table[index] = next; &#125; else &#123; // prev==null &amp;&amp; next==null table[index] = null; &#125; useSize--; return e.v;&#125; 参考Hash table维基百科散列表的基本原理与实现浅谈HashMap中的hash算法]]></content>
      <categories>
        <category>数据结构</category>
        <category>哈希表</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK动态代理实现原理]]></title>
    <url>%2F2018%2F07%2F10%2FJDK%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[平时接触动态代理比较多，例如Spring等框架如何使用了动态代理经常听到，本文主要介绍JDK动态代理的基本实现原理(JDK8版本)，当了解了这些实现细节后，再次使用动态代理就会十分容易和清楚，知其然也知其所以然。 动态代理Demo先来看一下利用JDK动态代理写的Demo，下面会根据这个Demo进行分析 首先定义一个接口 1234567public interface Calculator &#123; int add(int a, int b); int sub(int a, int b); int mul(int a, int b); int div(int a, int b);&#125; 然后是上面接口的实现类 123456789101112131415161718192021222324public class CalculatorImpl implements Calculator &#123; @Override public int add(int a, int b) &#123; System.out.println(a+b); return a+b; &#125; @Override public int sub(int a, int b) &#123; return a-b; &#125; @Override public int mul(int a, int b) &#123; return a*b; &#125; @Override public int div(int a, int b) &#123; return a/b; &#125;&#125; 现在有个需求，就是在每个方法执行前后都实现一段逻辑，这个时候就要用到JDK的动态代理了。 我们首先定义一个类实现InvocationHandler接口，将要代理的对象通过构造方法传入，并实现invoke方法。 12345678910111213141516171819202122232425262728293031323334public class MyProxyHandler implements InvocationHandler &#123; //要代理的对象 private Calculator target; public MyProxyHandler(Calculator h) &#123; this.target = h; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //获取参数 System.out.println("beginWith---方法的参数是--" + Arrays.asList(args)); before(); Object result = method.invoke(target,args); after(); return result; &#125; /** * 前置 */ public void before() &#123; System.out.println("before---"); &#125; /** * 后置 */ public void after() &#123; System.out.println("after---"); &#125;&#125; 最后我们利用JDK提供的Proxy类来实现我们想要的功能 12345678910111213141516/** * jdk动态代理测试 * @author mingshan * */public class Test &#123; public static void main(String[] args) &#123; Calculator target = new CalculatorImpl(); Calculator proxy = (Calculator) Proxy.newProxyInstance(Calculator.class.getClassLoader(), new Class&lt;?&gt;[]&#123;Calculator.class&#125;, new MyProxyHandler(target)); proxy.add(1, 2); &#125;&#125; 具体实现流程动态代理之所以被称为动态代理，那是因为代理类是在运行过程中被Java动态生成的，我们可以看到这个被生成的代理类，需要在运行运行配置加上-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true这个虚拟机参数，那么就会在当前项目com.sun.proxy包路径下生成$Proxy0.class这个class文件，其中文件名的数字是可变的。 代理类生成的过程主要包括两部分： 代理类字节码生成 把字节码通过传入的类加载器加载到虚拟机中 我们首先从Proxy类的newProxyInstance方法入手，开始分析实现流程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException&#123; // 检查空指针异常 Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); // 安全检查 final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; // 生成代理类 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125;&#125; newProxyInstance方法需要三个参数，分别是类加载器，接口类型的数组和自定义的InvocationHandler。首选会检测空指针异常和安全检查，然后调用getProxyClass0方法，getProxyClass0源码如下： 1234567891011private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException("interface limit exceeded"); &#125; // If the proxy class defined by the given loader implementing // the given interfaces exists, this will simply return the cached copy; // otherwise, it will create the proxy class via the ProxyClassFactory return proxyClassCache.get(loader, interfaces);&#125; 代码里面的注释很清楚，如果实现当前接口的代理类存在，直接从缓存中返回，如果不存在，则通过ProxyClassFactory来创建。这里可以明显看到有对interface接口数量的限制，不能超过65535。其中proxyClassCache具体初始化信息如下： 1proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); 其中创建代理类的具体逻辑是通过ProxyClassFactory的apply方法来创建的，ProxyClassFactory类中还包含代理类名称生成相关的两个静态常量，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// prefix for all proxy class namesprivate static final String proxyClassNamePrefix = "$Proxy";// next number to use for generation of unique proxy class namesprivate static final AtomicLong nextUniqueNumber = new AtomicLong();@Overridepublic Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + " is not visible from class loader"); &#125; /* * Verify that the Class object actually represents an * interface. */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + " is not an interface"); &#125; /* * Verify that this interface is not a duplicate. */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( "repeated interface: " + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? "" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( "non-public interfaces from different packages"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // if no non-public proxy interfaces, use com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + "."; &#125; /* * Choose a name for the proxy class to generate. */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Generate the specified proxy class. */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125;&#125; apply方法需要两个参数，类加载器和接口类型的数组。该方法包含验证类加载器和接口相关逻辑，包名的创建逻辑，调用ProxyGenerator. generateProxyClass生成代理类，把代理类字节码加载到JVM。 包名默认是com.sun.proxy，如果被代理类是 non-public proxy interface ，则用和被代理类接口一样的包名，类名默认是$Proxy 加上一个自增的整数值，如$Proxy0，$Proxy1。 包名类名准备好后，就是通过ProxyGenerator.generateProxyClass根据具体传入的接口创建代理字节码，-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true 这个VM参数就是在该方法起到作用，如果为true则保存字节码到磁盘。代理类中，所有的代理方法逻辑都一样都是调用invocationHander的invoke方法，这个我们可以看后面具体代理反编译结果。 把字节码通过传入的类加载器加载到JVM中: defineClass0(loader, proxyName,proxyClassFile, 0, proxyClassFile.length);。 我们继续来看看generateProxyClass方法是如何实现的，下面是该类的源码 123456789101112131415161718192021222324252627282930public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 生成代理类字节码文件的真正方法 final byte[] var4 = var3.generateClassFile(); // 保存文件操作 if (saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if (var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar)); Files.createDirectories(var3); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + ".class"); &#125; else &#123; var2 = Paths.get(var0 + ".class"); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError("I/O exception saving generated file: " + var4x); &#125; &#125; &#125;); &#125; return var4;&#125; 在generateProxyClass方法中，通过调用ProxyGenerator类的generateClassFile方法，来生成代理类字节码文件，然后保存文件。 接下来我们看看generateClassFile方法干了些什么，下面是该方法的源码（方法有点长~）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121private byte[] generateClassFile() &#123; // addProxyMethod系列方法就是将接口的方法和Object的hashCode,equals,toString方法添加到代理方法Map(proxyMethods), // 其中方法签名作为key,proxyMethod作为value // 后面经过反编译生成的代理类看出，hashCode，equals，toString这三个方法相当于从Object拿过来， // m0 = Class.forName("java.lang.Object").getMethod("hashCode", new Class[0]); this.addProxyMethod(hashCodeMethod, Object.class); this.addProxyMethod(equalsMethod, Object.class); this.addProxyMethod(toStringMethod, Object.class); Class[] var1 = this.interfaces; int var2 = var1.length; int var3; Class var4; // 获得所有接口中的所有方法，并将方法添加到代理方法中 for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; Method[] var5 = var4.getMethods(); int var6 = var5.length; for(int var7 = 0; var7 &lt; var6; ++var7) &#123; Method var8 = var5[var7]; this.addProxyMethod(var8, var4); &#125; &#125; // 迭代存储在map中的ProxyMethod Iterator var11 = this.proxyMethods.values().iterator(); List var12; while(var11.hasNext()) &#123; var12 = (List)var11.next(); checkReturnTypes(var12); &#125; Iterator var15; try &#123; // 生成代理类的构造函数 this.methods.add(this.generateConstructor()); var11 = this.proxyMethods.values().iterator(); while(var11.hasNext()) &#123; var12 = (List)var11.next(); var15 = var12.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.ProxyMethod var16 = (ProxyGenerator.ProxyMethod)var15.next(); // 向代理类添加字段 // 将代理字段声明为Method，10为ACC_PRIVATE和ACC_STATAIC的与运算，表示该字段的修饰符为private static // 所以代理类的字段都是private static Method XXX this.fields.add(new ProxyGenerator.FieldInfo(var16.methodFieldName, "Ljava/lang/reflect/Method;", 10)); // 向代理类添加方法 this.methods.add(var16.generateMethod()); &#125; &#125; // 为代理类生成静态代码块，对一些字段进行初始化 this.methods.add(this.generateStaticInitializer()); &#125; catch (IOException var10) &#123; throw new InternalError("unexpected I/O Exception", var10); &#125; // 限制方法和字段数量 if (this.methods.size() &gt; 65535) &#123; throw new IllegalArgumentException("method limit exceeded"); &#125; else if (this.fields.size() &gt; 65535) &#123; throw new IllegalArgumentException("field limit exceeded"); &#125; else &#123; this.cp.getClass(dotToSlash(this.className)); this.cp.getClass("java/lang/reflect/Proxy"); var1 = this.interfaces; var2 = var1.length; for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; this.cp.getClass(dotToSlash(var4.getName())); &#125; this.cp.setReadOnly(); ByteArrayOutputStream var13 = new ByteArrayOutputStream(); DataOutputStream var14 = new DataOutputStream(var13); try &#123; var14.writeInt(-889275714); var14.writeShort(0); var14.writeShort(49); this.cp.write(var14); var14.writeShort(this.accessFlags); var14.writeShort(this.cp.getClass(dotToSlash(this.className))); var14.writeShort(this.cp.getClass("java/lang/reflect/Proxy")); var14.writeShort(this.interfaces.length); Class[] var17 = this.interfaces; int var18 = var17.length; for(int var19 = 0; var19 &lt; var18; ++var19) &#123; Class var22 = var17[var19]; var14.writeShort(this.cp.getClass(dotToSlash(var22.getName()))); &#125; var14.writeShort(this.fields.size()); var15 = this.fields.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.FieldInfo var20 = (ProxyGenerator.FieldInfo)var15.next(); var20.write(var14); &#125; var14.writeShort(this.methods.size()); var15 = this.methods.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.MethodInfo var21 = (ProxyGenerator.MethodInfo)var15.next(); var21.write(var14); &#125; var14.writeShort(0); return var13.toByteArray(); &#125; catch (IOException var9) &#123; throw new InternalError("unexpected I/O Exception", var9); &#125; &#125;&#125; 那么自定义的InvocationHandler是如何在代理中使用的呢？ 在上面的方法中向代理类添加方法调用了generateMethod()方法，所以这个添加方法的步骤就是在generateMethod()方法中实现的。由于这个方法太长，这里就不贴全部代码了，方法里面有一段代码如下： 1var9.writeShort(ProxyGenerator.this.cp.getFieldRef("java/lang/reflect/Proxy", "h", "Ljava/lang/reflect/InvocationHandler;")); 原来在代理方法中通过Proxy类引用了自定义InvocationHandler，由于通过Proxy的newProxyInstance方法将InvocationHandler传入，生成的代理类通过继承Proxy类，拿到InvocationHandler，最后调用invoke方法来实现。 明白了JDK动态代理的大致流程，让我们来反编译下生成的代理类，反编译后的$Proxy0.java的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package com.sun.proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;import me.mingshan.dy.Calculator;public final class $Proxy0 extends Proxy implements Calculator &#123; private static Method m1; private static Method m2; private static Method m5; private static Method m3; private static Method m4; private static Method m6; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return ((Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;)).booleanValue(); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int mul(int var1, int var2) throws &#123; try &#123; return ((Integer)super.h.invoke(this, m5, new Object[]&#123;Integer.valueOf(var1), Integer.valueOf(var2)&#125;)).intValue(); &#125; catch (RuntimeException | Error var4) &#123; throw var4; &#125; catch (Throwable var5) &#123; throw new UndeclaredThrowableException(var5); &#125; &#125; public final int add(int var1, int var2) throws &#123; try &#123; return ((Integer)super.h.invoke(this, m3, new Object[]&#123;Integer.valueOf(var1), Integer.valueOf(var2)&#125;)).intValue(); &#125; catch (RuntimeException | Error var4) &#123; throw var4; &#125; catch (Throwable var5) &#123; throw new UndeclaredThrowableException(var5); &#125; &#125; public final int sub(int var1, int var2) throws &#123; try &#123; return ((Integer)super.h.invoke(this, m4, new Object[]&#123;Integer.valueOf(var1), Integer.valueOf(var2)&#125;)).intValue(); &#125; catch (RuntimeException | Error var4) &#123; throw var4; &#125; catch (Throwable var5) &#123; throw new UndeclaredThrowableException(var5); &#125; &#125; public final int div(int var1, int var2) throws &#123; try &#123; return ((Integer)super.h.invoke(this, m6, new Object[]&#123;Integer.valueOf(var1), Integer.valueOf(var2)&#125;)).intValue(); &#125; catch (RuntimeException | Error var4) &#123; throw var4; &#125; catch (Throwable var5) &#123; throw new UndeclaredThrowableException(var5); &#125; &#125; public final int hashCode() throws &#123; try &#123; return ((Integer)super.h.invoke(this, m0, (Object[])null)).intValue(); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, new Class[]&#123;Class.forName(&quot;java.lang.Object&quot;)&#125;); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;, new Class[0]); m5 = Class.forName(&quot;me.mingshan.dy.Calculator&quot;).getMethod(&quot;mul&quot;, new Class[]&#123;Integer.TYPE, Integer.TYPE&#125;); m3 = Class.forName(&quot;me.mingshan.dy.Calculator&quot;).getMethod(&quot;add&quot;, new Class[]&#123;Integer.TYPE, Integer.TYPE&#125;); m4 = Class.forName(&quot;me.mingshan.dy.Calculator&quot;).getMethod(&quot;sub&quot;, new Class[]&#123;Integer.TYPE, Integer.TYPE&#125;); m6 = Class.forName(&quot;me.mingshan.dy.Calculator&quot;).getMethod(&quot;div&quot;, new Class[]&#123;Integer.TYPE, Integer.TYPE&#125;); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 代理类的结构大致如下: 静态字段：被代理的接口所有方法都有一个对应的静态方法变量； 静态块：主要是通过反射初始化静态方法变量； 具体每个代理方法：逻辑都差不多就是h.invoke，主要是调用我们自定义的InvocatinoHandler逻辑，触发目标对象target上对应的方法; 构造函数：从这里传入我们InvocationHandler逻辑 参考：JDK动态代理详解深度剖析JDK动态代理机制]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IllegalMonitorStateException异常分析]]></title>
    <url>%2F2018%2F07%2F03%2FIllegalMonitorStateException%E5%BC%82%E5%B8%B8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[当调用wait()， notify()等相关方法时，可能会产生这个异常，那么这个异常是什么意思呢？ 抛出该异常原因:在Java中，每一个对象（Object/Class）都有一个监视器，当在同步代码块中，当前线程不是此监视器的所有者，也就是要在当前线程锁定对象，才能用锁定的对象此行这些方法，需要用到synchronized ，锁定什么对象就用什么对象来执行notify(), notifyAll(),wait(), wait(long), wait(long, int)操作，否则就会报IllegalMonitorStateException异常，原因异常。 下面这段代码就会抛出IllegalMonitorStateException异常，原因就是调用wait需要当前对象的监视器。 1234567891011121314151617public class ThreadTest implements Runnable &#123; private int i = 0; public synchronized void run() &#123; try &#123; ThreadTest.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + ":" + i); &#125; public static void main(String[] args) &#123; new Thread(new ThreadTest()).start(); &#125;&#125; 所以对于synchronized的使用来说，通常这样使用 123synchronized(x) &#123; x.notify();&#125; 具体对于不同的监视对象而言，可以有以下几种考虑： 锁定方法所对应的对象实例 1234public synchronized void work() &#123; this.notify(); // 或者直接写notify(); &#125; 类锁 12345public void work() &#123; synchronized(xx.class) &#123; xx.notify(); &#125;&#125; 锁定其他对象 12345678public Class Test&#123; public Object lock = new Object(); public static void method（）&#123; synchronized (lock) &#123; lock.notify(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>IllegalMonitorStateException</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解ThreadLocal]]></title>
    <url>%2F2018%2F07%2F01%2F%E7%90%86%E8%A7%A3ThreadLocal%2F</url>
    <content type="text"><![CDATA[记得去年学习Spring MVC的时候自己学着写了一个小小的框架，用了一个AppContext来表示应用上下文，每个请求都应该有各自独立的AppContext，里面可以存储一些数据，比如数据库连接Connection等，此时考虑数据库的事务问题，即在一个线程内，一个事务的多个操作拿到的是一个Connection，该如何实现呢？此时就需要使用ThreadLocal来解决。 ThreadLocal介绍ThreadLocal能干啥？ ThreadLocal是基于线程的一个本地变量的支持类，用户可以将对象与线程绑定，每一个线程都拥有一个自己的对象，例如对于上面的需求来说，可以将AppContext存入到ThreadLocal，代码如下： 123456789101112131415161718192021222324252627public class AppContext &#123; private static ThreadLocal&lt;AppContext&gt; appContextMap = new ThreadLocal&lt;AppContext&gt;(); private Map&lt;String, Object&gt; objects = new HashMap&lt;String, Object&gt;(); private AppContext() &#123;&#125;; // 部分代码省略 public void clear() &#123; AppContext context = appContextMap.get(); if (context != null) &#123; context.objects.clear(); &#125; context = null; &#125; public static AppContext getAppContext() &#123; AppContext appContext = appContextMap.get(); if (appContext == null) &#123; appContext = new AppContext(); appContextMap.set(appContext); &#125; return appContextMap.get(); &#125;&#125; 对于数据库的Connection，可以有以下实现 1234567891011121314151617public Class ConnectionManager &#123; // 创建一个私有静态的并且是与事务相关联的局部线程变量 private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;; public static Connection getConnection() &#123; // 获得线程变量connectionHolder的值conn Connection conn = connectionHolder.get(); if (conn == null)&#123; // 如果连接为空，则创建连接，另一个工具类，创建连接 conn = DbUtil.getConnection(); // 将局部变量connectionHolder的值设置为conn connectionHolder.set(conn); &#125; return conn; &#125; ｝ ThreadLocal原理分析ThreadLocal有如下成员变量和方法，如下图所示 其中经常用到的是以下几个方法： 1234public T get() &#123; &#125;public void set(T value) &#123; &#125;public void remove() &#123; &#125;protected T initialValue() &#123; &#125; 由于ThreadLocal里面需要存值和取值，又需要与线程相关，那么数据存在哪里，用哪种数据结构呢？由于Map可以存储很多类型，这里又不需要对外提供服务，所以这里就用了静态内部类的Map来搞存储，来存储真实的变量实例。 get()流程那么， ThreadLocal是如何工作的呢？我们先从get方法看起，下面是get方法的源码 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 首先获得当前线程，然后通过getMap(t)方法获取到一个map，map的类型为ThreadLocalMap。接下来根据从map中获取Entry，注意这里获取键值对传进去的是this，而不是当前线程t。如果获取成功，则返回value值。如果map为空，则调用setInitialValue方法返回value。 getMap()方法是如何获取到ThreadLocalMap的呢？来看看源码 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 发现是直接获取当前线程的threadLocals成员变量，那么接下来就到Thread类里面去看一下 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 实际上就是ThreadLocalMap，这个类型是ThreadLocal类的一个内部类，我们来看看ThreadLocalMap内部的Entry类，源码如下： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承自WeakReference，这里弱引用为Map的key，也就是ThreadLocal，弱引用就是只要JVM垃圾回收器发现了它，就会将之回收。 回到get()方法， 如果通过getMap()方法获取的map为空，就会调用setInitialValue() 方法，下面是该方法的源码 12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 首先调用initialValue() 方法进行初始化value，默认为null，接下来获取当前线程，获取map，判断map是否为空，不为空将ThreadLocal类的对象为key，设定value，为空则创建map，调用createMap(t, value)方法，createMap代码如下： 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; set(T value)流程接下来看看set方法如何实现的，下面是源码： 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 首先获取当前线程，然后获取map，判断map是否为空，不为空将ThreadLocal类的对象为key，设定value，为空则创建map，调用createMap(t, value)方法。 至此，我们就可以知道大致知道ThreadLocal的工作流程： Thread类中有一个成员变量属于ThreadLocalMap类(一个定义在ThreadLocal类中的内部类)，它是一个Map，它的key是ThreadLocal实例对象。 当为ThreadLocal类的对象set值时，首先获得当前线程的ThreadLocalMap类属性，然后以ThreadLocal类的对象为key，设定value。get值时则类似。 一个线程多个ThreadLocal，如何区分？既然ThreadLocal内部用map存储数据，一个线程可以对应多个ThreadLocal对象，那么这些ThreadLocal对象是如何区分的呢？上面只是大致分析了ThreadLocal的工作原理，并未涉及ThreadLocalMap的存值和取值，接下来我们继续来看源码 1234567891011121314151617181920212223242526272829303132/** * ThreadLocals rely on per-thread linear-probe hash maps attached * to each thread (Thread.threadLocals and * inheritableThreadLocals). The ThreadLocal objects act as keys, * searched via threadLocalHashCode. This is a custom hash code * (useful only within ThreadLocalMaps) that eliminates collisions * in the common case where consecutively constructed ThreadLocals * are used by the same threads, while remaining well-behaved in * less common cases. */private final int threadLocalHashCode = nextHashCode();/** * The next hash code to be given out. Updated atomically. Starts at * zero. */private static AtomicInteger nextHashCode = new AtomicInteger();/** * The difference between successively generated hash codes - turns * implicit sequential thread-local IDs into near-optimally spread * multiplicative hash values for power-of-two-sized tables. */private static final int HASH_INCREMENT = 0x61c88647;/** * Returns the next hash code. */private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; 在ThreadLocal类内部定义了一个final的变量threadLocalHashCode，这个变量是干什么的？看注释，在ThreadLocalMap存储数据时，ThreadLocal对象作为key，通过threadLocalHashCode进行搜索，threadLocalHashCode通过原子类AtomicInteger，提供原子操作，由于nextHashCode为类变量，保证每次生成的hashCode都不一致，每次生成hashCode都会有HASH_INCREMENT的差值。threadLocalHashCode会在ThreadLocalMap中用到，下面继续分析。 前面分析get()流程，对于如何从ThreadLocalMap取数据并未提及，现在看看源码如何实现的： 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 通过调用ThreadLocalMap的getEntry方法，传入当前ThreadLocal对象，然后获取ThreadLocal的threadLocalHashCode， 然后通过位运算与(&amp;) 将 threadLocalHashCode和ThreadLocal内部存储数据的table的长度减一进行位运算得到i，利用i在table中直接进行搜索。 在ThreadLocalMap如何存值？下面看ThreadLocalMap.set()源码 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 在ThreadLocalMap.set()方法中，传入当前ThreadLocal对象和要存的值，然后通过位运算与(&amp;) 将 threadLocalHashCode和ThreadLocal内部存储数据的table的长度减一进行位运算得到i，这个i在get()方法已经见过了，完全一样（不一样就出问题啦），接下来开始遍历table，判断有没有相同的key等处理，其实最核心的就是你得去new 一个entry然后设置到table数组中，就是下面这句： 1tab[i] = new Entry(key, value); ThreadLocal会有内存泄露？看了好多博客，里面提到ThreadLocal会有内存泄露问题，因为从ThreadLocalMap的设计来看，如下图，key被设计成弱引用，一旦JVM进行GC时，这个key就没了，那么与key对应的value还存在ThreadLocalMap，ThreadLocalMap与Entry存在着强引用，GC无法回收，造成内存泄露。 当然，这些都是分析出来的，既然我们考虑到了，那么Josh Bloch 和 Doug Lea肯定也为我们考虑过了，所以这个问题在源码中已经解决了，下面来看看相关源码 在ThreadLocalMap.set()方法中，如果key为null，此时会调用 replaceStaleEntry()方法，在这个方法中进行处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // Back up to check for prior stale entry in current run. // We clean out whole runs at a time to avoid continual // incremental rehashing due to garbage collector freeing // up refs in bunches (i.e., whenever the collector runs). int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // Find either the key or trailing null slot of run, whichever // occurs first for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // If we find key, then we need to swap it // with the stale entry to maintain hash table order. // The newly stale slot, or any other stale slot // encountered above it, can then be sent to expungeStaleEntry // to remove or rehash all of the other entries in run. if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // Start expunge at preceding stale entry if it exists if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // If key not found, put new entry in stale slot tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 其中我们可以看到这段代码： 12// If key not found, put new entry in stale slottab[staleSlot].value = null; 如果key找不到，那么就将value置为null，help GC。这样问题解决。 当然在resize()方法中也有同样的操作，总之都会进行处理的。 最后，我们可以调用remove()方法将相关数据移除，这个肯定就不会有内存泄露啦。 参考：https://www.cnblogs.com/xzwblog/p/7227509.html#_label0 https://www.jianshu.com/p/ee8c9dccc953 https://mp.weixin.qq.com/s?__biz=MzA5MzQ2NTY0OA==&amp;mid=2650796401&amp;idx=1&amp;sn=61f2d19bfb0e34c08206c6b31a1c2dd1&amp;chksm=88562c2ebf21a5383ace3f52f336db9b53a714bb37d5f97a9d5746b43b6a3d30be113aca082a&amp;mpshare=1&amp;scene=23&amp;srcid=1212TdJMnkHNCPTwVsPKSuao#rd]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之装饰模式]]></title>
    <url>%2F2018%2F06%2F27%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰模式作为常用的设计模式用到很多，比如在Java中，io包下的很多类就是典型的装饰者模式的体现，如下代码： 1234new BufferedOutputStream(OutputStream out)new BufferedInputStream(InputStream in);new PrintWriter(OutputStream out)new FilterReader(Reader in); 那么，什么是装饰模式呢？ 在实际应用中我们可能会有这样的需求，需要动态地为一个类增加一些功能，这些功能动态地撤销，继承虽然也可以对类进行功能扩展，但是静态的，为了扩展性和动态性，就需要引入装饰模式。 装饰模式的定义是： 动态地给一些对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更加灵活。 装饰模式的通用类图如下图所示： 在类图中，有四个角色需要说明： 抽象构件（Component） 给出一个抽象的接口，用以规范准备接收附加责任的对象。 具体构件（ConcreteComponent） ConcreteComponent是最核心、最原始、最基本的接口或抽象类的实现，要装饰的就是它。 装饰角色（Decorator） 有一个构件（Conponent）对象的实例，并定义一个和抽象构件一致的接口。 具体装饰角色（ConcreteDecorator） 具体的装饰类，要增加的功能当然要在这里写啦。 具体代码实现: 抽象构件: 123456789/** * 抽象构建 * * @author mingshan * */public abstract class Component &#123; public abstract void operate();&#125; 具体构件: 1234567891011121314/** * 具体构件 * * @author mingshan * */public class ConcreteComponent extends Component &#123; @Override public void operate() &#123; System.out.println("do something"); &#125;&#125; 装饰角色, 持有一个抽象构件的引用 1234567891011121314151617181920/** * 抽象装饰者 * * @author mingshan * */public class Decorator extends Component &#123; private Component component; public Decorator(Component component) &#123; super(); this.component = component; &#125; @Override public void operate() &#123; this.component.operate(); &#125;&#125; 具体装饰角色 1234567891011121314151617181920212223242526272829303132/** * 装饰者1 * * @author mingshan * */public class ConcreteDecorator1 extends Decorator &#123; /** * 定义被修饰者 * @param component */ public ConcreteDecorator1(Component component) &#123; super(component); &#125; /** * 定义自己的修饰方法 */ private void method1() &#123; System.out.println("decorator A"); &#125; /** * 重写父类的方法 */ @Override public void operate() &#123; this.method1(); super.operate(); &#125;&#125; 测试一下： 1234567891011121314151617/** * 测试 * * @author mingshan * */public class Test &#123; public static void main(String[] args) &#123; Component component = new ConcreteComponent(); // 第一次装饰 component = new ConcreteDecorator1(component); // 第二次装饰 component = new ConcreteDecorator2(component); component.operate(); &#125;&#125; 代码参考： https://github.com/mstao/java-explore/tree/master/DesignPattern/src/pers/han/decorator]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>装饰模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之适配器模式]]></title>
    <url>%2F2018%2F06%2F25%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在我们日常生活中可以看到许多例子，例如我们的手机需要用充电器来充电，因为220v电压手机是承受不住的；笔记本电脑连接投影仪可以是HDMI，需要转接头等等例子，从这些例子中我们可以发现目标对象与源对象无法直接交互，需要一个中间层来作为一个桥梁达到让两者完美交互的效果，从这种就可以看到适配器模式的影子了。 那么什么是适配器模式呢? 将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 适配器包含类适配器和对象适配器，类适配器是类间继承，对象适配器是类的关联关系，这是两者的区别。 我们先来看看适配器模式的角色 Target目标角色 该角色定义把其他类转化为何种接口，也就是我们最终期望的接口，需要Adapter实现该接口 Adaptee源角色 想把谁转换为目标角色，此时就是源角色 Adapter适配器角色 适配器模式的核心角色，它的职责非常简单，将源角色转化为目标角色 类适配器模式通过继承来实现适配器模式，由于Java是属于单继承，所以这个使用限制很大。 Adaptee源角色，里面包含原来的业务逻辑 123456789101112131415/** * 适配器源角色 * * @author mingshan * */public class Adaptee &#123; /** * 原有的业务逻辑 */ public void doSomething() &#123; System.out.println("源角色 do something。。。"); &#125;&#125; Target目标角色， 包含现有的业务逻辑 1234567891011121314151617181920212223242526272829/** * 适配器目标角色 * * @author mingshan * */public interface Target &#123; /** * 目标角色有自己的方法 */ void request();&#125;/** * 目标角色实现类， 现有的业务逻辑 * * @author mingshan * */public class ConcreteTarget implements Target &#123; @Override public void request() &#123; System.out.println("xxxxxxxxxxxxxxxxxx"); &#125;&#125; 适配器角色，需要继承源角色，拿到其里面的方法，然后实现目标角色接口，让源角色与目标角色进行交互 1234567891011121314/** * 适配器角色 * * @author mingshan * */public class Adapter extends Adaptee implements Target &#123; @Override public void request() &#123; super.doSomething(); &#125;&#125; 测试一下 1234567891011121314151617/** * 类适配器 Test * * @author mingshan * */public class Client &#123; public static void main(String[] args) &#123; // 原有的业务逻辑 Target target = new ConcreteTarget(); target.request(); // 现在增加了适配器角色后的业务逻辑 Target target2 = new Adapter(); target2.request(); &#125;&#125; 对象适配器模式对象适配器是通过类的关联关系来进行的，是为了解决类适配器模式的问题而出现的，它比类适配器模式灵活，扩展性强，实际运用的比较多。 这里只解释一些Adapter适配器角色的实现，其他的和类适配器模式一致。 通过构造器将两个源角色传递进来，实现Target接口，然后就可以进行交互啦 1234567891011121314151617181920212223/** * 适配器角色 * * @author mingshan * */public class Adapter implements Target &#123; private Adaptee1 adaptee1; private Adaptee2 adaptee2; public Adapter(Adaptee1 adaptee1, Adaptee2 adaptee2) &#123; this.adaptee1 = adaptee1; this.adaptee2 = adaptee2; &#125; @Override public void request() &#123; adaptee1.doSomething(); adaptee2.doSomething(); &#125; &#125; 代码参考https://github.com/mstao/java-explore/tree/master/DesignPattern/src/pers/han/adapter]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>适配器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[离人]]></title>
    <url>%2F2018%2F06%2F22%2F%E7%A6%BB%E4%BA%BA%2F</url>
    <content type="text"><![CDATA[好久不写文章，只因这段时间太忙了，忙到忘记离别的日子已经逼在眼前，倒让人措手不及。当这些繁琐的流程到了末尾，离别的日子真是要到来了。 大学是我目前人生中最充实的时光，回想以前的上学时代，也真让人怀念。十年回首，可喜可悲可叹其实现在也没有多深的记忆了，也或许都释怀了吧。释怀这个词不怎么靠谱，哪里有什么释怀不释怀的，只不过心里能够接受事情的好与坏，不需要过多纠结；明白人总是聚少离多，那些离开的人，可能一辈子也不会再见了。人因为情感变得复杂，也变得有趣。 最近一直在看梁晓声的《中国人的日常》，印象十分深刻。他谈及自己的初恋，感觉充满一种令人羡慕的稚气与甜蜜，或许是那个时代特有的那种情感，也或许是每个人在经历初恋时都会有的这种感觉。稚气地认为，各自的心灵从此有了依靠，被自己感动，亦被对方感动。在那个年代，爱不可声张，甚至不敢承认，这对于热恋中的人来说是有多么压抑和煎熬。我们都向往纯真，向往无邪，当你向往这些的时候，说明这些早已远离于你，这些也只是虚幻想象的样子，真实早已消失。 他在谈及在他年幼时遇到改变其一生的启蒙恩师，这是何等幸运。在人生启蒙时代能遇到为他们人生指明道路之人，没有因为一时错念而浪费自己的人生。普通人千千万万，并不是每个人都会遇到指点迷津之人，在混沌的日子里，在无可奈何的岁月中，怎么做到顿悟自我，不浪费自己的生命呢？对于年轻人来说，最浪费时间的事情就是给其讲经验、大道理，讲一万句不如自己去摔一跤，不如自己去尝试一下，眼泪教你做人，后悔帮你成长，疼痛才是人生之师。人生该走的弯路，其实一米也少不了。 大学让人成长不少，遇到了这么多有趣的人，十分不寂寞。人生遇到了每一个人，其实都有缘分，缘分大也罢，小也罢，都不怎么重要。毕竟在人生漫漫长河中，他们都是那一朵朵的浪花，这是多么的有趣和富有生气，倘若平静死水般，该是多么的无聊与苍白。人生不如意之事七八九，苦事。终归还能与人言一二三，幸事。感谢能遇到一群能一起喝酒玩乐、酒后畅谈之舍友们，共同成长，希望再见如故。 感慨这么多，还是说句俗话，希望各位万事大吉，天天吃鸡(￣▽￣)／ 放两张照片吧，以此纪念我的大学。 记于2018/6/22]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安裝Redis遇到问题及解决]]></title>
    <url>%2F2018%2F05%2F23%2FCentOS7%E5%AE%89%E8%A3%9DRedis%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[前段时间我在我的CentOS7服务器上安装了Redis，遇到了一些问题忘记记录下来了ヽ(￣▽￣)ﾉ，而且我参考网上的教程配置一些脚本的时候发现有错误，根据我对shell的简单理解会介绍一下，毕竟这个东西很常用。 安装Redis首先在/usr/local目录下创建services 文件夹和其子文件redis,然后进入该文件夹。 下载redis可以通过wget，我这里下载的是redis-4.0.2版本 1wget http://download.redis.io/releases/redis-4.0.2.tar.gz 将Redis下载到该文件夹下后，将压缩文件解压 123cd /usr/local/services/redistar -xzvf redis-4.0.2.tar.gz 进入到解压后的文件夹，进行编译即可 123cd /usr/local/services/redis/redis-4.0.2make 编译完后，我们需要将redis-cli，redis-server，redis.conf拷贝到一个单独的文件夹，这里我们在/usr/local/services/redis 文件夹下新建一个文件夹redisroot 1mkdir -p /usr/local/services/redis/redisroot 然后将编译后的redis-cli，redis-server，redis.conf拷贝到redisroot文件夹下 12345cp /usr/local/services/redis/redis-4.0.2/src/redis-server /usr/local/services/redis/redisrootcp /usr/local/services/redis/redis-4.0.2/src/redis-cli /usr/local/services/redis/redisrootcp /usr/local/services/redis/redis-4.0.2/redis.conf /usr/local/services/redis/redisroot 拷贝完后的文件夹结构如下： 编辑配置文件编辑Redis配置文件 进入到redisroot文件夹，输入下列命令进入编辑模式 1vim redis.conf 然后修改以下配置： 在bind 127.0.0.1前加“#”将其注释掉 默认为保护模式，把 protected-mode yes 改为 protected-mode no 默认为不守护进程模式，把daemonize no 改为daemonize yes 将 requirepass foobared前的“#”去掉，密码改为你想要设置的密码 设置完后，ESC切换模式后输入:wq!保存退出 编辑Redis开机启动脚本输入以下命令编辑脚本 1vim /etc/init.d/redis 打开后在这个文件里添加如下脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/bin/sh# chkconfig: 2345 80 90# description: Start and Stop redis#PATH=/usr/local/bin:/sbin:/usr/bin:/binREDISPORT=6379EXEC=/usr/local/services/redis/redisroot/redis-server REDIS_CLI=/usr/local/services/redis/redisroot/redis-cli PIDFILE=/var/run/redis_6379.pidCONF="/usr/local/services/redis/redisroot/redis.conf" RESDISPASSWORD=123456case "$1" in start) if [ -f $PIDFILE ] then echo "$PIDFILE exists, process is already running or crashed" else echo "Starting Redis server..." $EXEC $CONF fi if [ "$?"="0" ] then echo "Redis is running..." fi ;; stop) if [ ! -f $PIDFILE ] then echo "$PIDFILE does not exist, process is not running" else PID=$(cat $PIDFILE) echo "Stopping ..." $CLIEXEC -a $RESDISPASSWORD -p$REDISPORT shutdown while [ -x $&#123;PIDFILE&#125; ] do echo "Waiting for Redis to shutdown ..." sleep 1 done echo "Redis stopped" fi ;; restart|force-reload) $&#123;0&#125; stop $&#123;0&#125; start ;; *) echo "Usage: /etc/init.d/redis &#123;start|stop|restart|force-reload&#125;" &gt;&amp;2 exit 1esac 脚本中声明的路径常量需要根据自己的安装路径进行配置。 上面这个脚本是我参考网上的，但网上的有错误，比如我设置了Redis的密码，那么在执行停止命令时是需要验证密码的，所以要这样写$CLIEXEC -a $RESDISPASSWORD -p$REDISPORT shutdown。 后续配置下面的一些操作是从网上拷贝的，为后续配置Redis，基本相同 添加开机启动服务编辑/etc/rc.local 1vim /etc/rc.local 增加启动代码 1service redis start 编辑后的配置文件如下： 设置权限1chmod 755 /etc/init.d/redis 注册系统服务1chkconfig --add redis 测试redis服务启动服务 1service redis start 启动日志如下： 123456[root@VM_37_72_centos redisroot]# service redis startStarting Redis server...21416:C 23 May 00:24:19.666 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo21416:C 23 May 00:24:19.666 # Redis version=4.0.2, bits=64, commit=00000000, modified=0, pid=21416, just started21416:C 23 May 00:24:19.666 # Configuration loadedRedis is running... 停止服务 1service redis stop 停止日志如下： 123[root@VM_37_72_centos redisroot]# service redis stopStopping ...Redis stopped 创建redis命令软连接在linux下很多地方都需要软连接，软连接其实就是windows的快捷方式。 1ln -s /usr/local/services/redis/redisroot/redis-cli /usr/bin/redis 测试Redis最后可以直接进行测试了 OK, 大功告成。 后记其实这些命令教程啊网上都有，不过有些是错误的，只有自己完完全全测试过一遍后才知道哪些有问题，同时会对Redis有个基本的了解吧，平时都在用Windows，相对来说有些傻瓜式，多敲些Linux命令还是有益处的，哈哈(～￣▽￣)～ 参考https://blog.csdn.net/lc1010078424/article/details/78295482]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 搭建 Zookeeper-3.4.10 单机服务]]></title>
    <url>%2F2018%2F05%2F12%2FCentOS7%20%E6%90%AD%E5%BB%BA%20Zookeeper-3.4.10%20%E5%8D%95%E6%9C%BA%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[由于项目用到了Dubbo,而Dubbo的服务的注册与发现我用了Zookeeper，所以我在部署Dubbo服务的时候，就必须安装Zookeeper,本文记录下我在CentOS7 搭建 Zookeeper-3.4.10 单机服务的过程。 Zookeeper的安装 下载Zookeeper 下载最新版本的ZooKeeper，这里有两个镜像可以选择 清华镜像:https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/ 阿里镜像:https://mirrors.aliyun.com/apache/zookeeper/ 我就选择阿里镜像进行安装。 首先在/usr/local目录下创建services 文件夹和其子文件zookeeper,然后进入该文件夹，最后用wget进行下载 12345mkdir -p /usr/local/services/zookeepercd /usr/local/services/zookeeperwget --no-check-certificate https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz 提取tar文件 接下来解压zookeeper-3.4.10.tar.gz， 首先进入到该文件夹, 然后进行解压 12345cd /usr/local/services/zookeepertar -zxf zookeeper-3.4.10.tar.gzcd zookeeper-3.4.10 进入到解压后的文件夹后，创建data文件夹 用于存储数据文件 1mkdir data 创建logs文件夹 用于存储日志 1mkdir logs 创建配置文件 使用命令 vim conf/zoo.cfg 创建配置文件并打开, 其实该文件夹下有了一个zoo_sample.cfg示例配置文件，我们还是新创建一个吧。 编辑内容如下： 1234567tickTime = 2000dataDir = /usr/local/services/zookeeper/zookeeper-3.4.10/datadataLogDir = /usr/local/services/zookeeper/zookeeper-3.4.10/logstickTime = 2000clientPort = 2181initLimit = 5syncLimit = 2 Zookeeper服务 启动服务 1/usr/local/services/zookeeper/zookeeper-3.4.10/bin/zkServer.sh start 连接服务 1/usr/local/services/zookeeper/zookeeper-3.4.10/bin/zkCli.sh 查看服务状态 1/usr/local/services/zookeeper/zookeeper-3.4.10/bin/zkServer.sh status 停止服务 1/usr/local/services/zookeeper/zookeeper-3.4.10/bin/zkServer.sh stop 参考：https://segmentfault.com/a/1190000010791627]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用WebMagic来爬取ZZULI的通知]]></title>
    <url>%2F2018%2F05%2F08%2F%E5%88%A9%E7%94%A8WebMagic%E6%9D%A5%E7%88%AC%E5%8F%96ZZULI%E7%9A%84%E9%80%9A%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[WebMagic介绍WebMagic是一个开源的Java垂直爬虫框架，目标是简化爬虫的开发流程，让开发者专注于逻辑功能的开发。最近项目有需求爬取某些网站的信息，考虑到WebMagic的爬虫实现十分精简和扩展性很高，所以爬虫模块就采用了WebMagic来爬取网站的一些信息。 WebMagic的结构分为Downloader、PageProcessor、Scheduler、Pipeline四大组件，并由Spider将它们彼此组织起来。这四大组件对应爬虫生命周期中的下载、处理、管理和持久化等功能。WebMagic的总体架构图如下： 从上面的架构图中可以看出，我们在下载完页面后需要自己定义规则来抽取信息和发现链接，同时控制爬虫爬取深度，所以需要自定义PageProcessor来进行以上操作。而通过定制Pipeline，我们还可以实现保存结果到文件、数据库等一系列功能，所以我们可以根据自己的需求来自定义Pipeline。 爬虫实现示例介绍通过上面的分析，我们就可以来爬取特定页面的信息了。本次爬取的网站是http://www.zzuli.edu.cn/s/12/t/1006/p/22/i/13/list.htm，我们需要爬取的页面主要是列表+详情的基本页面组合，有一个列表页，这个列表页以分页的形式展现，我们可以遍历这些分页找到所有目标页面。我们要从通知的详细界面，来抓取通知的标题、内容、日期等信息，也要从列表页抓取的链接等信息，从而获取这个通知的所有文章。 列表页 列表页的格式如：1http://www.zzuli.edu.cn/s/12/t/1006/p/22/i/13/list.htm 其中i后面的13是可变的，根据上一页和下一页的切换来改变这一个数字，页面如下： 详细页详细页的格式如下： 12http://www.zzuli.edu.cn/s/12/t/1006/e8/ff/info190719.htmhttp://www.zzuli.edu.cn/s/12/t/1006/e5/65/info189797.htm 通过观察这两个url，可以发现1006后面的都是可以变的，所以可以根据这个来写正则抽取链接。 详细页页面如下： 发现通知URL在这个爬虫需求中，我们需要知道这些详细通知的URL，所以如何抽取这些URL显得很重要，事实也是如此，也是我们要实现爬虫的第一步。我们可以先考虑用以下正则表达式1http://www\\.zzuli\\.edu\\.cn/s/12/t/1006/\\w+/\\w+/info\\d+\\.htm 来过滤通知的详细界面，但这样未免太过宽泛，爬取效率也比较低，此时考虑到列表页中含有通知的详细界面的URL，所以我们必须从列表页中指定的区域获取URL。 在这里，我们使用xpath //table[@id=\”newslist\”]选中所有区域，再使用links()获取所有链接，最后再使用正则表达式http://www\\.zzuli\\.edu\\.cn/s/12/t/1006/\\w+/\\w+/info\\d+\\.htm， 对URL进行过滤，去掉一些其他无用的链接。于是，我们可以这样写： 1page.addTargetRequests(page.getHtml().xpath(&quot;//table[@id=\&quot;newslist\&quot;]&quot;).links().regex(URL_POST).all()); 同时，我们需要把所有找到的列表页也加到待下载的URL中去： 1page.addTargetRequests(page.getHtml().links().regex(URL_LIST).all()); 抽取内容抽取页面所需要的信息对于爬虫应用来说是关键的一步，同时也是比较简单的，因为我们可以用xpath来解析html，定义好抽取表达式就可以了。 1234page.putField("title", page.getHtml().xpath("//h1[@class='arti-title']/text()"));page.putField("content", page.getHtml().xpath("//div[@class='read']"));page.putField("date", page.getHtml().xpath("//div[@class='arti-metas']/table/tbody/tr/td[3]/span/text()").replace("日期：", "")); 列表页和详细页我们可以定义几个常量来定义列表页和详细页的URL： 12345private static final String DOMAIN = "http://www\\.zzuli\\.edu\\.cn";private static final String URL_LIST = DOMAIN + "/s/12/t/1006/p/22/i/\\d+/list\\.htm";private static final String URL_POST = DOMAIN + "/s/12/t/1006/\\w+/\\w+/info\\d+\\.htm"; 我们可以根据URL_LIST和URL_POST来区别列表页和详细页的抽取。 保存信息我们可以自定义Pipeline来将抽取的结果保存在想要的地方，这里我直接将标题、内容、日期等信息封装为实体，然后放到List中，便于后续处理，代码如下： 1234567891011121314151617181920/** * 自定义Pipeline，用来处理爬到的数据 * * @author mingshan * */public class NoticePipeline implements Pipeline &#123; public void process(ResultItems resultItems, Task task) &#123; Notice notice = null; try &#123; notice = new Notice(resultItems.getAll()); notice.setLink(resultItems.getRequest().getUrl()); &#125; catch (Exception e) &#123; return ; &#125; NoticeList.addNotice(notice); &#125;&#125; 总结通过以上的爬虫的实现，我们主要根据列表页来抽取所需要的通知详细页的URL，然后通过xpath来解析页面，获取特定的信息。如此简洁的逻辑和代码得益于WebMagic框架良好的封装，同时扩展性很强，推荐大家使用。 参考主要参考WebMagic的官方文档和samples。 http://webmagic.io/docs/zh/]]></content>
      <categories>
        <category>爬虫</category>
        <category>WebMagic</category>
      </categories>
      <tags>
        <tag>WebMagic</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Linux(CentOS)下重置MySQL根(Root)密码]]></title>
    <url>%2F2018%2F05%2F05%2F%E5%9C%A8Linux(CentOS)%E4%B8%8B%E9%87%8D%E7%BD%AEMySQL%E6%A0%B9(Root)%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[我的CentOS服务器的mysql密码忘了，记录一下如何重置mysql的root密码 下面是操作步骤： 首先输入“service mysqld status”查看当前mysql服务状态。 输入“killall -TERM mysqld”命令停止所有的mysqld进程。 输入“service mysqld stop”命令停止mysqld服务。 输入“mysqld_safe –skip-grant-tables &amp;”命令以无密码方式进入MySQL安全模式。 输入“mysql -u root”并按回车键即可。 输入“use mysql;”挂载数据库。(注意：请勿忘记在最后输入分号（;）) 输入”update user set password=password(“admin”) where user=’root’;”将Root密码修改为admin。 输入”flush privileges;”更新权限。 输入“quit”并按回车键退出。(注意：此处不需输入分号。) 输入”service mysqld restart”重启mysqld服务。 输入“mysql -u root -p”并按回车键提示输入密码。 输入新密码admin并按回车键，提示已经成功登录。 下面是所有步骤运行截图：]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解GC日志]]></title>
    <url>%2F2018%2F04%2F17%2F%E7%90%86%E8%A7%A3GC%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[输出GC日志通过阅读GC日志，我们可以了解Java虚拟机内存分配与回收策略。先来看一个简单的示例。 下面是GC日志： 12345678910110.115: [GC (System.gc()) [PSYoungGen: 3020K-&gt;600K(38400K)] 3020K-&gt;608K(125952K), 0.0012295 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 0.117: [Full GC (System.gc()) [PSYoungGen: 600K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;554K(87552K)] 608K-&gt;554K(125952K), [Metaspace: 2773K-&gt;2773K(1056768K)], 0.0060759 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap PSYoungGen total 38400K, used 333K [0x00000000d5f00000, 0x00000000d8980000, 0x0000000100000000) eden space 33280K, 1% used [0x00000000d5f00000,0x00000000d5f534a8,0x00000000d7f80000) from space 5120K, 0% used [0x00000000d7f80000,0x00000000d7f80000,0x00000000d8480000) to space 5120K, 0% used [0x00000000d8480000,0x00000000d8480000,0x00000000d8980000) ParOldGen total 87552K, used 554K [0x0000000081c00000, 0x0000000087180000, 0x00000000d5f00000) object space 87552K, 0% used [0x0000000081c00000,0x0000000081c8aab8,0x0000000087180000) Metaspace used 2779K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K 上面的GC日志是由下面的Java代码产生的： 12345678910111213141516/** * GC 日志 * @author mingshan * */public class GCLogDemo &#123; public static void main(String[] args) &#123; int _1m = 1024 * 1024; byte[] data = new byte[_1m]; // 将data置为null即让它成为垃圾 data = null; // 通知垃圾回收器回收垃圾（help gc） System.gc(); &#125;&#125; 在Eclipse中以运行配置方式运行上面的代码，并设置VM参数： 12-XX:+PrintGCTimeStamps-XX:+PrintGCDetails GC日志说明：先看这两行GC日志 120.115: [GC (System.gc()) [PSYoungGen: 3020K-&gt;600K(38400K)] 3020K-&gt;608K(125952K), 0.0012295 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 0.117: [Full GC (System.gc()) [PSYoungGen: 600K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;554K(87552K)] 608K-&gt;554K(125952K), [Metaspace: 2773K-&gt;2773K(1056768K)], 0.0060759 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 通过观察这两行日志发现，它们的格式相同，下面是对其格式的描述： GC发生时间: [垃圾收集停顿类型: [GC发生区域: GC前该内存区域已使用容量 -&gt; GC后该内存区域已使用容量(该内存区域总容量)] 该内存区域GC所占用的时间] GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量(Java堆总容量)] [user表示用户态消耗的CPU时间，sys表示内核态消耗的CPU时间，real表示操作从开始到结束所经过的墙钟时间]。 GC日志解读最前面的数字“0.115:”和“0.117:”代表GC发生的时间，是从Java虚拟机启动以来经过的秒数。 GC日志开头的”[GC” 和”[Full GC”说明这个GC的停顿类型，而不是用来判断是新生代GC还是老年代GC，其中“[Full GC”说明发生了Stop-The-World。这里出现了“(System.gc())”，说明是调用了System.gc()方法所触发的搜集。 接下来的“[PSYoungGen:”代表GC发生的区域，而且这里显示的区域名称与使用的GC收集器名称密切相关。PSYoungGen，表示新生代使用的是多线程垃圾收集器Parallel Scavenge。 方括号内部的“3020K-&gt;600K(38400K)”代表“GC前该内存区域已使用容量 -&gt; GC后该内存区域已使用容量(该内存区域总容量)”。而在方括号外面的“3020K-&gt;608K(125952K)”表示”该内存区域GC所占用的时间] GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量(Java堆总容量)”。 再往后的“0.0012295 secs”代表该内存区域GC所占用的时间，单位为秒。后面的“[Times: user=0.00 sys=0.00, real=0.00 secs] ”为具体的时间信息。其中user表示用户态消耗的CPU时间，sys表示内核态消耗的CPU时间，real表示操作从开始到结束所经过的墙钟时间（Wall Clock Time）。钟时间包括各种非运算的等待耗时，如IO等待、线程阻塞。CPU时间不包括等待时间，当系统有多核或者多个CPU时，多线程操作会叠加这些CPU时间，所以user或sys时间会超过real时间。 堆详细信息解读：下面是堆详细信息的日志： 123456789Heap PSYoungGen total 38400K, used 333K [0x00000000d5f00000, 0x00000000d8980000, 0x0000000100000000) eden space 33280K, 1% used [0x00000000d5f00000,0x00000000d5f534a8,0x00000000d7f80000) from space 5120K, 0% used [0x00000000d7f80000,0x00000000d7f80000,0x00000000d8480000) to space 5120K, 0% used [0x00000000d8480000,0x00000000d8480000,0x00000000d8980000) ParOldGen total 87552K, used 554K [0x0000000081c00000, 0x0000000087180000, 0x00000000d5f00000) object space 87552K, 0% used [0x0000000081c00000,0x0000000081c8aab8,0x0000000087180000) Metaspace used 2779K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K 先了解下Java memory划分： Java memory主要分heap memory 和 non-heap memory，如下图： 第一行为新生代的大小，大小为38400K。而新生代又分为三个区域分别叫Eden，和俩个Survivor spaces。Eden用来存放新的对象，Survivor spaces用于 新对象 升级到 Tenured area时的 拷贝。默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，即： Eden = 8/10 的新生代空间大小，from = to = 1/10 的新生代空间大小。 默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。 ParOldGen 为老年代，大小为87552K，大约为PSYoungGen内存大小的2倍。 从JDK8开始，永久代(PermGen)的概念被废弃掉了，取而代之的是一个称为Metaspace的存储空间。Metaspace与PermGen之间最大的区别在于：Metaspace并不在虚拟机中，而是使用本地内存。 参考 深入理解Java虚拟机：JVM高级特性与最佳实践（第2版） https://segmentfault.com/a/1190000012577387]]></content>
      <categories>
        <category>JVM</category>
        <category>GC</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git合并多个commit]]></title>
    <url>%2F2018%2F03%2F26%2FGit%E5%90%88%E5%B9%B6%E5%A4%9A%E4%B8%AAcommit%2F</url>
    <content type="text"><![CDATA[在我们做新功能的时候，我们可能需要自己新建一个分支，然后在这个分支上开发，由于功能复杂或者功能点很多，或者每改动一个重要的地方都要进行提交一次，这样自己在测试开发时方便回滚等操作，会产生多个临时的commit，这些临时commit其实才是一个功能点，在向团队开发分支合并代码的时候，我们为了避免太多的 commit 而造成版本控制的混乱，通常我们推荐将这些 commit 合并成一个。 1. git log查看提交记录 首先我们利用git log查看当前分支提交的历史，最近提交在最上面，如下： 1234567commit 2d6454c942f3961ad351caf145bedf29c4d3743ccommit d059f47fd7ab863353cd98fb29c98ceb1fe97845commit 951522a48081b8ab4a529fee706d94c8fe3b16c8commit 1d85c5a75128b6127de90b9db367dc9d67bdd17a 2. git rebase 这里用到了git rebase命令，这个命令主要用于更新代码和合并commit。假设你本地和服务器目前是同步的，然后你本地做了几次commit，其他人向服务器推送了commit。如果你希望同步服务器的commit，但是本地的commit又不想push到服务器的时候(比如你开发完某个功能，可能需要5个commit)。先fetch，然后rebase服务器的代码。 这里想要合并 1~2的commit，有两种方式 从HEAD开始往后合并两次提交 1git rebase -i HEAD~2 指定要合并的commit之前的版本号 1git rebase -i 951522a 此时951522a这个commit不参与合并 3. 选取要合并的提交 当输入完以上两个命令会弹出一个文本文件，内容前几行如下： 12pick d059f47 add test.txtpick 2d6454c Update test.txt 此时将第二个pick改为squash或者s,之后保存并关闭文本编辑窗口即可。改完之后文本内容如下： 12p d059f47 add test.txts 2d6454c Update test.txt 保存后会弹出一个新文件，前面是你刚才要合并的两条 commit message，然后将这两条commit message删除，然后重新设置新的message，保存退出，如下： 12345# This is a combination of 2 commits.# This is the commit message #2:Add and update test.txt 最后就可以发现两条commit message 已经合并为一条了 1234567891011121314151617commit 9fff5fa09e09836ff2c535486ced2a66f8e4c19aAuthor: Juntao Han &lt;499445428@qq.com&gt;Date: Mon Mar 26 21:24:47 2018 +0800 Add and update test.txtcommit 951522a48081b8ab4a529fee706d94c8fe3b16c8Author: Juntao Han &lt;499445428@qq.com&gt;Date: Mon Mar 26 21:03:29 2018 +0800 update .gitignorecommit 1d85c5a75128b6127de90b9db367dc9d67bdd17aAuthor: Juntao Han &lt;499445428@qq.com&gt;Date: Mon Mar 26 20:59:13 2018 +0800 :octocat: Added .gitattributes &amp; .gitignore files 接下来推送到git服务器就好了]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>rebase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于git reabse的使用]]></title>
    <url>%2F2018%2F03%2F15%2F%E5%85%B3%E4%BA%8Egit%20reabse%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[由于在工作中用到了git rebase命令，所以记录一下。 比如当前在location-scan 分支做一个新功能，当新功能做完了，然后发pull request请求合并到develop分支，但在你提交pull request 之前，有人改动了develop分支的代码，导致你的代码与develop分支的代码发生了冲突， 由于有冲突，需要从develop分支将代码拉到location-scan 分支，进行代码的合并，然后再进行提交，此时的提交没有合并过的痕迹，所以此时我们就需要用到了git rebase命令了，具体的使用的流程： 拉取远程develop分支代码，并与当前分支的代码合并 1git fetch 1git rebase origin/develop 添加代码到暂存区 1git add . 如果让git继续应用(apply)余下的补丁，那么就用–continue参数 1git rebase --continue 如果想让git放弃此次合并，那么就用–abort参数来终止rebase的动作 1git rebase --abort 如果你想多次的提交都有第一次的提交合并，那么就用–amend参数 1git commit --amend (合并commit) 如果需要 将文件从暂存区取消，那么执行以下命令 1git reset HEAD &lt;file&gt;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>rebase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之Builder模式]]></title>
    <url>%2F2018%2F03%2F09%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BBuilder%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[当我们在创建对象的时候，如果对象需要很多的参数，并且有些参数是可选的，有些是必选的，有的可能默认值，这个时候如果我们用构造器传参或者通过set方法进行属性值设置，那么这样就有很大的问题，比如别人在创建这个对象的时候，并不知道需要传哪些参数，哪些参数是必须传值的，而且调用也不方便，所有我们就可以用到Builder模式，这里就是所谓的链式调用。在Effective Java书中， 第2条就是遇到到多个构造器时要考虑用构造器，里面讲的比较详细。 比如我们想这样创建一个对象 12345new User.Builder("Walker", "Han") .age(20) .phone("123456789") .address("166号") .build(); 此时我们需要在User类中创建一个内部类Builder，该类用来创建User对象，通过上面的代码我们发现，可以连续调用属性的方法进行传参，这就要求每次调用后都要返回当前对象，这样才能连续调用，下面是代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 链式调用 * @author mingshan * */public class User &#123; private final String firstName; // 必传参数 private final String lastName; // 必传参数 private int age; // 可选参数 private String phone; // 可选参数 private String address; // 可选参数 private User(Builder builder) &#123; this.firstName = builder.firstName; this.lastName = builder.lastName; this.age = builder.age; this.phone = builder.phone; this.address = builder.address; &#125; @Override public String toString() &#123; return "User [firstName=" + firstName + ", lastName=" + lastName + ", age=" + age + ", phone=" + phone + ", address=" + address + "]"; &#125; public static class Builder &#123; private final String firstName; private final String lastName; private int age; private String phone; private String address; public Builder(String firstName, String lastName) &#123; this.firstName = firstName; this.lastName = lastName; &#125; public Builder age(int age) &#123; this.age = age; return this; &#125; public Builder phone(String phone) &#123; this.phone = phone; return this; &#125; public Builder address(String address) &#123; this.address = address; return this; &#125; public User build() &#123; return new User(this); &#125; &#125;&#125; 然后就可以像上面的方式进行调用了。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>Builder模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux搭建Java Web环境(JDK8, Tomcat8.5, Nginx)]]></title>
    <url>%2F2018%2F01%2F01%2FLinux%E6%90%AD%E5%BB%BAJava%20Web%E7%8E%AF%E5%A2%83(JDK8%2C%20Tomcat8.5%2C%20Nginx)%2F</url>
    <content type="text"><![CDATA[安装JDK首先下载jdk-8u172-linux-x64.tar.gz，然后上传到服务器/usr/local/java目录 解压jdk-8u172-linux-x64.tar.gz 1tar -zxvf jdk-8u172-linux-x64.tar.gz 设置环境变量 1vim /etc/profile 在最前面添加： 1234export JAVA_HOME=/usr/local/java/jdk1.8.0_172 export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 输入:wq!保存退出 执行profile文件 1source /etc/profile 这样可以使配置不用重启即可立即生效。 检查新安装的jdk 1java -version 显示 123java version &quot;1.8.0_172&quot;Java(TM) SE Runtime Environment (build 1.8.0_172-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode) 安装Tomcat8.5下载tomcat到/usr/local/tomcat 1$ wget http://redrockdigimark.com/apachemirror/tomcat/tomcat-8/v8.5.23/bin/apache-tomcat-8.5.23.tar.gz 解压： 1tar -zxvf apache-tomcat-8.5.23.tar.gz 启动： 1sh startup.sh 安装Nginx开始前，请确认gcc g++开发类库是否装好，默认已经安装。 centos平台编译环境使用如下指令 安装make： 1yum -y install gcc automake autoconf libtool make 安装g++: 1yum install gcc gcc-c++ 下面正式开始安装 选择安装目录 1cd /usr/local/nignx 安装PCRE库 1234567cd /usr/local/nignxwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.39.tar.gz tar -zxvf pcre-8.39.tar.gzcd pcre-8.39./configuremakemake install 安装zlib库 12345678cd /usr/local/nignx wget http://zlib.net/zlib-1.2.11.tar.gztar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11./configuremakemake install 安装openssl 123cd /usr/local/nignxwget https://www.openssl.org/source/openssl-1.0.1t.tar.gztar -zxvf openssl-1.0.1t.tar.gz 启动nginx 1/usr/local/nginx/sbin/nginx 查看进程 1ps -ef|grep nginx 其他命令 123nginx -s reload ：修改配置后重新加载生效nginx -s reopen ：重新打开日志文件nginx -t -c /usr/local/nginx/conf/nginx.conf 测试nginx配置文件是否正确 firewalld的基本使用 启动： systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 查看firewall是否运行 1systemctl status firewalld.service 添加开放端口 1firewall-cmd --zone=public --add-port=80/tcp --permanent （--permanent永久生效，没有此参数重启后失效） 查看所有打开的端口： 1firewall-cmd --zone=public --list-ports 更新防火墙规则： 1firewall-cmd --reload]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[忽然之间]]></title>
    <url>%2F2017%2F12%2F24%2F%E5%BF%BD%E7%84%B6%E4%B9%8B%E9%97%B4%2F</url>
    <content type="text"><![CDATA[不知不觉，发现时间过得好快，出来实习的时间已经过去了大半年，毕业的日子马上就要来了，2017即将消逝，有必要写些什么。 从今年七月份开始就开始实习，感觉实习阶段对于刚踏入编程这个行业的人来说还是很重要的，因为这一年会让你知道你擅长哪个领域，应该深钻哪门编程语言(或许)，但并不是每个人都是如此，至少我不是，因为我实习主要用的语言并不是我喜欢的语言，对于一个自己不喜欢的语言当然不愿意花费过多的时间在上面，因为人的精力是有限的。随着编程的逐渐深入，会发现想要学好一门语言不是那么容易的，如果认为一门语言就简单使用语法和库，那么未免也太浅薄了。就拿我喜欢用的Java来说吧，才开始可能感觉会一些API和常用的框架就能做些东西，并不需要一些多么高深的东西，数据结构基本用不上，而且好用的工具一抓一大把，感觉编程是比较容易的，但事实上是这样的吗？显示不是，当你不满足于仅使用API和框架的时候，还想了解这些API的源码和框架的设计实现原理，你会发现许多问题都会迎面而来，而且大部分都是老问题，比如你想看集合的源码，想知道ArrayList和HashMap到底是怎么实现的，数据在其内部是如何进行存储的，这时候数据结构就派上用场了，如果你想自己造个轮子，也实现一把HashMap，你就需要对HashMap的数据结构了如指掌，这样的话当你再次使用HashMap的时候，其结构和实现原理就会在你大脑里飞转，想忘也忘不了。 对于我这种初学者来说，深知自己学会造轮子的重要性，虽然说自己写的基本上没有现成的轮子好使，但这些轮子并不代表对你没用，反而作用很大。比如我看了Java的并发包的ArrayBlockingQueue的源码，那么我自己试试能不能写个功能差不多的类呢，如果实现原理知道的话，那么基本功能还是可以写出来的。这个时候还有一件非常重要的事需要考虑，那就是学习源码优秀的代码结构和设计，设计模式是必不可少的，只有掌握了这些，才能深刻的明白写代码是怎么一回事，现在算是初级小码农( ¨̮ ) 一晃眼从初中到大学毕业差不多十年过去了，时间还真是个无情的猎手，猎杀着世间容易消失的一切，那些存在着，消失的，以及后悔不后悔着的，或许都溶于自己的内心，再也看不到以前的样子了。 忽然之间，天昏地暗。最后发现孤独的还是自己，痛苦和快乐着的还是自己。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉搜索树结构分析]]></title>
    <url>%2F2017%2F12%2F24%2F%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[二叉查找树（Binary Search Tree），（又：二叉搜索树，二叉排序树），它具有以下特点： 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 下面是一个二叉查找树的示例： 基本操作既然二叉查找树也属于二叉树，那么二叉树的基本操作二叉查找树也需要实现，下面是基本操作 查找结点 插入结点 删除结点 我们先写个接口来定义要实现这些操作，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839/** * 树的接口 * @author mingshan * */public interface Tree&lt;E&gt; &#123; /** * 插入操作 * @param value * @return 插入成功 ，返回 &#123;@true&#125;，否则返回&#123;@false&#125; */ boolean add(E value); /** * 移除 * @param value * @return 移除的元素 */ E remove(E value); /** * 清空二叉树 */ void clear(); /** * 判断二叉树中是否有此元素 * @param value * @return 如果包含，返回&#123;@true&#125;，否则返回&#123;@false&#125; */ boolean contains(E value); /** * 获取二叉树中结点的数量 * @return 二叉树中结点的数量 */ int size();&#125; 下面来依次实现。 初始化先在类中定义二叉查找树的根结点和结点数量的成员变量。然后定义一个静态内部类Node来表示结点，代码如下： 12345678910111213141516171819202122// 根结点private Node&lt;E&gt; root;// 二叉树结点数量private int size;private static class Node&lt;E extends Comparable&lt;E&gt;&gt; &#123; E item; Node&lt;E&gt; parent; Node&lt;E&gt; left; Node&lt;E&gt; right; public Node (Node&lt;E&gt; parent, E item) &#123; this.parent = parent; this.item = item; &#125; @Override public String toString() &#123; return "item=" + item + " parent=" + ((parent != null) ? parent.item : "NULL") + " left=" + ((left != null) ? left.item : "NULL") + " right=" + ((right != null) ? right.item : "NULL"); &#125;&#125; 查找结点这里采用先序遍历二叉查找树，先访问根结点，然后遍历左子树，最后遍历右子树。这里的泛型参数需要继承Comparable，然后我们就可以利用其compareTo方法来比较结点的值然后进行搜索即可。代码如下： 1234567891011121314151617181920212223242526272829@Overridepublic boolean contains(E value) &#123; // 先序遍历二叉树 Node&lt;E&gt; node = root; if (root.item.compareTo(value) == 0) &#123; return true; &#125; while (node != null) &#123; // 如果当前值比父节点的值小 if (node.item.compareTo(value) &gt; 0) &#123; // 此时应该从父节点的左子树进行搜索 if (node.left != null &amp;&amp; (node.left.item.compareTo(value) == 0)) &#123; return true; &#125; node = node.left; &#125; else &#123; // 如果当前结点的值比父结点的值大，说明应该从父节点的右子树搜索 // 并且新结点作为叶子结点，其父节点的右子结点应为null if (node.right != null &amp;&amp; (node.right.item.compareTo(value) == 0)) &#123; return true; &#125; node = node.right; &#125; &#125; return false;&#125; 插入结点根据二叉搜索树的特征，若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值。而且新插入的结点必为叶子结点，所以只需遍历到当前符合上面要求的结点，然后将其为空的左子结点或者右子结点指向当前的新节点，最后将新结点的父结点指向当前结点。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Overridepublic boolean add(E value) &#123; Node&lt;E&gt; node = addNode(value); return (node != null);&#125;private Node&lt;E&gt; addNode(E value) &#123; // 生成新结点 Node&lt;E&gt; newNode = new Node&lt;E&gt;(null, value); // 如果根结点不存在 if (root == null) &#123; root = newNode; size++; return newNode; &#125; Node&lt;E&gt; node = root; // 按照先序进行遍历二叉树 while (node != null) &#123; // 如过新结点的值比父节点的值小 if (node.item.compareTo(newNode.item) &gt; 0) &#123; // 此时应该从父节点的左子树进行搜索 // 并且新结点作为叶子结点，其父节点的左子结点应为null if (node.left == null) &#123; node.left = newNode; newNode.parent = node; size++; return newNode; &#125; node = node.left; &#125; else &#123; // 如果当前结点的值比父结点的值大，说明应该从父节点的右子树搜索 // 并且新结点作为叶子结点，其父节点的右子结点应为null if (node.right == null) &#123; node.right = newNode; newNode.parent = node; size++; return newNode; &#125; node = node.right; &#125; &#125; return newNode;&#125; 删除结点删除结点是操作中最为复杂的，分下面几种情况考虑： 要删除的结点为叶子结点，没有左右子节点 要删除的结点只有左子结点(树)或者右子结点(树) 要删除的结点左右结点(树)都有 下面这幅图代表这几种操作示例： 其中第一幅图代表要删除的结点只有右子结点(树)，只需将该结点的父结点指向该结点的右子结点，但要判断当前结点是其父结点的子左结点还是右子结点，然后对应指向当前结点的子结点即可；图二代表要删除的结点只有左子结点(树)，原理是一样的；图三是代表要删除的结点左右结点(树)都有，此时需要找出其右子树中的最小值代替该节点上的值，然后删除其右子树上的最小值。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293@Overridepublic E remove(E value) &#123; Node&lt;E&gt; node = this.removeValue(value); return (node != null ? node.item : null);&#125;private Node&lt;E&gt; removeValue(E value) &#123; Node&lt;E&gt; curr = this.getNode(value); if (curr != null) &#123; curr = removeNode(curr); &#125; return curr;&#125;/** * 删除结点，分下面几种情况考虑 * &lt;ul&gt; * &lt;li&gt;要删除的结点为叶子结点，没有左右子节点&lt;/li&gt; * &lt;li&gt;要删除的结点只有左子结点(树)或者右子结点(树)&lt;/li&gt; * &lt;li&gt;要删除的结点左右结点(树)都有&lt;/li&gt; * &lt;/ul&gt; * @param nodeToRemoved * @return 删除的结点 */private Node&lt;E&gt; removeNode(Node&lt;E&gt; nodeToRemoved) &#123; // 判断当前节点是否为叶子结点（叶子结点的特点是没有子结点） // 直接删除叶子结点 if (nodeToRemoved.left == null &amp;&amp; nodeToRemoved.right == null) &#123; // 判断该二叉树是否只有根结点一个结点 if (nodeToRemoved == root) &#123; root = null; return root; &#125; // 如果二叉树不是只有根结点一个结点，那么当前要删除的结点一定有父结点 Node&lt;E&gt; targetParent = nodeToRemoved.parent; // 判断当前结点是其父结点的左子结点还是右子结点 if (targetParent.left.item.compareTo(nodeToRemoved.item) == 0) &#123; // 如果当前结点是其父结点的左子结点 targetParent.left = null; &#125; else if (targetParent.right.item.compareTo(nodeToRemoved.item) == 0)&#123; // 如果当前结点是其父结点的右子结点 targetParent.right = null; &#125; else &#123; // 此时二叉树有问题 return null; &#125; &#125; else if (nodeToRemoved.left != null &amp;&amp; nodeToRemoved.right != null) &#123; // 要删除的结点左右结点(树)都有 // 此时结点的左右子结点(树)都有，用其右子树中的最小值代替该节点上的值,删除其右子树上的最小值 // 所以此时需要先找出其右子树的最小值 Node&lt;E&gt; minNode = findMinNode(nodeToRemoved); // 将当前要删除结点的值替换为其子树的最小节点 nodeToRemoved.item = minNode.item; // 删除找到的最小节点 removeNode(minNode); &#125; else &#123; // 要删除的结点只有左子结点(树)或者右子结点(树) // 此时需要将该结点的子结点(树)指向该结点(树)的父结点 Node&lt;E&gt; targetLeft = nodeToRemoved.left; Node&lt;E&gt; targetRight = nodeToRemoved.right; Node&lt;E&gt; targetParent = nodeToRemoved.parent; // 判断当前要删除的结点是其父结点的左结点还是右结点 if (targetParent.left.item.compareTo(nodeToRemoved.item) == 0) &#123; // 左 if (targetLeft != null) &#123; targetParent.left = targetLeft; targetLeft.parent = targetParent; targetLeft = null; &#125; if (targetRight != null) &#123; targetParent.left = targetRight; targetRight.parent = targetParent; targetRight = null; &#125; &#125; else if (targetParent.right.item.compareTo(nodeToRemoved.item) == 0) &#123; // 右 if (targetLeft != null) &#123; targetParent.right = targetLeft; targetLeft.parent = targetParent; targetLeft = null; &#125; if (targetRight != null) &#123; targetParent.right = targetRight; targetRight.parent = targetParent; targetRight = null; &#125; &#125; &#125; size--; return nodeToRemoved;&#125; 我们需要通过传入的值来获取二叉树的结点，此时调用函数getNode，代码如下： 12345678910111213141516171819/** * 通过传入的值来搜索结点 * @param value 传入的值 * @return 结点 */private Node&lt;E&gt; getNode(E value) &#123; Node&lt;E&gt; node = root; while (node != null &amp;&amp; node.item != null) &#123; if (node.item.compareTo(value) &gt; 0) &#123; node = node.left; &#125; else if (node.item.compareTo(value) &lt; 0) &#123; node = node.right; &#125; else &#123; return node; &#125; &#125; return null;&#125; 在要删除的结点左右结点(树)都有的情况下，我们需要查找其右子树中的最小值，此时我们考虑到如果为最小结点，那么该结点必然没有左子树(结点)，所以可以选择递归进行遍历，代码如下： 12345678910111213141516/** * 找到给定结点的子树的最小结点(值) * 此时应该考虑到如果为最小结点，那么该结点必然没有左子树(结点)，所以可以选择递归进行遍历 * @param nodeToRemoved * @return 给定结点的子树的最小结点(值) */private Node&lt;E&gt; findMinNode(Node&lt;E&gt; nodeToRemoved) &#123; if (nodeToRemoved == null) &#123; return null; &#125; if (nodeToRemoved.left == null) &#123; return nodeToRemoved; &#125; return findMinNode(nodeToRemoved.left);&#125; 打印我们需要将二叉树打印到控制台上，便于查看二叉树的结构，效果如下： 打印代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Overridepublic String toString() &#123; return TreePrinter.getString(this);&#125;protected static class TreePrinter &#123; public static &lt;T extends Comparable&lt;T&gt;&gt; String getString(BinarySearchTree&lt;T&gt; tree) &#123; if (tree.root == null) return "Tree has no nodes."; return getString(tree.root, "", true); &#125; private static &lt;E extends Comparable&lt;E&gt;&gt; String getString(Node&lt;E&gt; node, String prefix, boolean isTail) &#123; StringBuilder builder = new StringBuilder(); if (node.parent != null) &#123; String siteme = "left"; if (node.equals(node.parent.right)) siteme = "right"; builder.append(prefix + (isTail ? "└── " : "├── ") + "(" + siteme + ") " + node.item + "\n"); &#125; else &#123; builder.append(prefix + (isTail ? "└── " : "├── ") + node.item + "\n"); &#125; List&lt;Node&lt;E&gt;&gt; children = null; if (node.left != null || node.right != null) &#123; children = new ArrayList&lt;Node&lt;E&gt;&gt;(2); if (node.left != null) children.add(node.left); if (node.right != null) children.add(node.right); &#125; if (children != null) &#123; for (int i = 0; i &lt; children.size() - 1; i++) &#123; builder.append(getString(children.get(i), prefix + (isTail ? " " : "│ "), false)); &#125; if (children.size() &gt;= 1) &#123; builder.append(getString(children.get(children.size() - 1), prefix + (isTail ? " " : "│ "), true)); &#125; &#125; return builder.toString(); &#125;&#125; 源码地址本篇博客的代码地址： https://github.com/mstao/data-structures/blob/master/Tree/src/pers/mingshan/tree/BinarySearchTree.java 测试代码地址如下： https://github.com/mstao/data-structures/blob/master/Tree/src/pers/mingshan/tree/TreeTest.java]]></content>
      <categories>
        <category>数据结构</category>
        <category>二叉树</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>二叉搜索树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链式队列结构分析]]></title>
    <url>%2F2017%2F12%2F21%2F%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[链式队列介绍链式队列拥有队列的特性，只不过和顺序队列的区别是，顺序队列底层用的是数组存储元素，而链式队列用的是链表结构存储数据，也就是把一个元素和指向下个结点的指针封装成一个结点，这里称为Node，当队列为空，头指针与尾指针均指向头结点，只不过头结点为空结点，下面是链式队列的结构图 一个结点抽象成Node类，代码如下： 12345678private class Node &#123; private E data; private Node next; public Node(E data) &#123; this.data = data; &#125;&#125; 初始成员变量链式队列需要有个指向队首的指针，指向队尾的指针，这里把这两个均声明为Node类型，当然队列需要容量和统计队列内元素的个数，代码如下： 123456private final AtomicInteger size = new AtomicInteger();private final int capacity;// 队列的头结点private Node head;// 队列的尾结点private Node tail; 构造函数在构造函数中初始化队列，当队列为空时，头指针与尾指针均指向头结点，头结点不存储数据 123456789101112131415161718public LinkQueue() &#123; this(Integer.MAX_VALUE);&#125;public LinkQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; tail = head = new Node(null);&#125;public LinkQueue(E element) &#123; this(Integer.MAX_VALUE); // 初始Node，只有一个节点 Node newNode = new Node(element); head.next = newNode; tail = newNode; size.incrementAndGet();&#125; 基本操作入队链式队列也实现我们在顺序队列写好的接口，所以入队也有两种操作，抛异常和不抛异常，分别为add(E e)和offer(E e)，这里直接说offer方法，如果队列为空，让头结点指向新的节点，同时让为指针指向新节点，不为空直接正常入队即可，代码如下： 1234567891011121314151617181920212223242526@Overridepublic boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException(&quot;Queue full&quot;);&#125;@Overridepublic boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); if (size.get() == capacity) return false; Node newNode = new Node(e); if (head == null) &#123; head.next = newNode; tail = newNode; &#125; else &#123; tail.next = newNode; tail = newNode; &#125; size.incrementAndGet(); return true;&#125; 出队出队也是比较简单的，直接移除队首结点即可，让头结点指向下一个结点，代码如下： 1234567891011@Overridepublic E poll() &#123; if (!isEmpty()) &#123; Node node = head.next; head.next = node.next; size.decrementAndGet(); return node.data; &#125; return null;&#125; 清空队列清空队列是让除了头结点的结点全部清除掉，解除关联，代码如下： 123456@Overridepublic void clear() &#123; head.next = null; tail = null; size.set(0);&#125; 源码地址本篇博客源码地址： https://github.com/mstao/data-structures/blob/master/Queue/src/pers/mingshan/queue/LinkQueue.java]]></content>
      <categories>
        <category>数据结构</category>
        <category>队列</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[顺序队列结构分析]]></title>
    <url>%2F2017%2F12%2F20%2F%E9%A1%BA%E5%BA%8F%E9%98%9F%E5%88%97%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[队列介绍队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。队列中没有元素时，称为空队列。队列的特点是先进先出(FIFO)，下面是队列的结构图： 常用方法既然是队列，那么入队和出队操作是必不可少的，除此之外，还需要其他api，下面是Queue的接口： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 队列接口 * @author mingshan * * @param &lt;E&gt; */public interface Queue&lt;E&gt; &#123; /** * 添加元素， 如果没有可用的空间，抛出IllegalStateException异常 * @param e 将要添加的元素 * @return */ boolean add(E e); /** * 添加元素。成功时返回 true，如果当前没有可用的空间，则返回 false，不会抛异常 * @param e 将要添加的元素 * @return */ boolean offer(E e); /** * 获取并移除此队列的头部,如果队列为空，则返回null * @return 头部元素 */ E poll(); /** * 获取队列头部元素, 不移除头部元素 * @return 头部元素 */ E peek(); /** * 判断队列是否为空 * @return */ boolean isEmpty(); /** * 获取队列的长度 * @return 队列的长度 */ int size(); /** * 清空队列 */ void clear();&#125; 下面来看看这些方法如何实现，现在还不考虑锁的问题，java.util.concurrent.ArrayBlockingQueue这个类有具体的实现，有空分析分析这个类的源码。 构造函数和成员变量顺序队列默认把元素存到数组里，所以这里用数组来保存队列里的元素，代码如下： 1234567891011121314// 队列内部数组默认容量private static final int DEFAULT_SIZE = 10;// 队列内部数组的容量private int capacity;// 保存元素的数组private Object[] elements;// 指向队列头部private int head;// 指向队列尾部private int tail; 在构造函数里面初始化队列的大小 123456789101112131415161718192021222324252627282930313233343536373839/** * 默认构造函数初始化 */public ArrayQueue() &#123; capacity = DEFAULT_SIZE; elements = new Object[capacity];&#125;/** * 指定队列内部数组容量进行初始化 * @param capacity 指定容量 */public ArrayQueue(int capacity) &#123; this.capacity = capacity; elements = new Object[capacity];&#125;/** * 指定队列的第一个元素进行初始化 * @param e 队列的第一个元素 */public ArrayQueue(E e) &#123; this.capacity = DEFAULT_SIZE; elements = new Object[capacity]; elements[0] = e; tail++;&#125;/** * 指定队列的第一个元素和容量进行初始化 * @param e 队列的第一个元素 * @param capacity 队列内部数组容量 */public ArrayQueue(E e, int capacity) &#123; this.capacity = capacity; elements = new Object[capacity]; elements[0] = e; tail++;&#125; 入队在入队的时候，其实有两种选择，如果队列满的话，抛出异常，或者等待其他元素出队后再进行入队。 add(E e)add方法就是实现第一种，如果没有可用的空间，抛出IllegalStateException异常，代码如下： 1234567891011121314151617@Overridepublic boolean add(E e) &#123; if (e != null) &#123; // 获取当前的数组的长度 int oldLength = elements.length; // 如果原来数组的长度小于当前需要的长度，那么直接抛异常IllegalStateException if (oldLength &lt; tail + 1) &#123; throw new IllegalStateException("Queue full"); &#125; else &#123; elements[tail++] = e; &#125; &#125; else &#123; throw new NullPointerException(); &#125; return true;&#125; 先获取队列的大小，如果队列的大小小于当前需要的空间，那么直接抛异常IllegalStateException，否则正常入队。 offer(E e)入队操作。成功时返回 true，如果当前没有可用的空间，则返回 false，不会抛异常，由于这里没有用到锁，也就暂时不考虑等待入队了，代码如下： 1234567891011121314151617@Overridepublic boolean add(E e) &#123; if (e != null) &#123; // 获取当前的数组的长度 int oldLength = elements.length; // 如果原来数组的长度小于当前需要的长度，那么直接抛异常IllegalStateException if (oldLength &lt; tail + 1) &#123; throw new IllegalStateException("Queue full"); &#125; else &#123; elements[tail++] = e; &#125; &#125; else &#123; throw new NullPointerException(); &#125; return true;&#125; 出队poll()获取并移除此队列的头部,如果队列为空，则返回null，代码如下： 12345678910111213@SuppressWarnings("unchecked")@Overridepublic E poll() &#123; if (!isEmpty()) &#123; E value = (E) elements[head]; // 移除头部元素 elements[head] = null; head++; return value; &#125; return null;&#125; peek()获取队列头部元素, 不移除头部元素，代码如下： 123456789@SuppressWarnings("unchecked")@Overridepublic E peek() &#123; if (!isEmpty()) &#123; return (E) elements[head]; &#125; return null;&#125; 清空队列由于用数组存储队列元素，所以需要将底层数组清空 1234567@Overridepublic void clear() &#123; //将底层数组所有元素赋为null Arrays.fill(elements, null); head = 0; tail = 0;&#125; ###源码地址 本篇博客源码地址： https://github.com/mstao/data-structures/blob/master/Queue/src/pers/mingshan/queue/ArrayQueue.java]]></content>
      <categories>
        <category>数据结构</category>
        <category>队列</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful API风格基于Token的鉴权机制分析(与JWT结合)]]></title>
    <url>%2F2017%2F12%2F19%2FRESTful%20API%E9%A3%8E%E6%A0%BC%E5%9F%BA%E4%BA%8EToken%E7%9A%84%E9%89%B4%E6%9D%83%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90(%E4%B8%8EJWT%E7%BB%93%E5%90%88)%2F</url>
    <content type="text"><![CDATA[RESTful APIRESTful API是目前比较成熟的API设计理论，它通过统一的API接口来对外提供服务，这样对其他调用者来说比较友好，更加容易实现前后端分离。具体介绍和如何使用参考这篇文章RESTful API介绍与使用 遇到的问题在我们的项目中，仅仅使用RESTful API是远远不够的，因为RESTful API只提供JSON数据，没有了视图层，将视图渲染交给了前端，这就带来了许多问题。比如我们以前在写JSP界面的时候，会把数据放到request里面，把登录的用户信息放在session里面，因为jsp本质上也是servlet，所以可以在界面直接拿到这些数据，现在前后端一分离，怎样对用户的身份进行识别就是首要考虑的问题。 以前我们是通过session来进行对用户的身份验证，由于http协议是无状态的，所以我们需要在服务器端将用户的信息保存下来，这份登录信息会在响应时传递给浏览器，告诉其保存为cookie(Java中的jsessionid),以便下次请求时发送给我们的应用，这样我们的应用就能识别请求来自哪个用户了,这就是传统的基于session认证。 使用 Token 进行身份鉴权现在我们的API可能不只是在浏览器上调用，比如app等也需要调用，这是如果只用session的话就有局限性了，所以我们可以用 Token 进行身份鉴权，由于Token我们可以根据自己的需要进行自定义，只要API提供方和调用方约定好如何生成Token和解析token，更加轻量化，扩展性更强。 JWT(JSON Web Token)JWT 是JSON风格轻量级的授权和身份认证规范，可实现无状态、分布式的Web应用授权，JWT主要由三部分构成，由.进行连接 Header Payload Signature 所以完整的JWT如下面形式： 1xxxxx.yyyyy.zzzzz 真实的JWT长这样： 那么header，Payload和Signature分别代表什么呢？ headerheader主要包含两部分： Token的类型，这里是JWT 声明加密的算法 通常直接使用 HMAC SHA256 完整的header应该长这样： 1234&#123; "alg": "HS256", "typ": "JWT"&#125; 然后将头部进行Base64加密，得到第一部分。 Payload第二部分主要是包含声明（Claims），声明是关于实体（通常是用户）和附加元数据的声明，这部分是存放数据的地方，比如用户id什么的，类似下面这样： 12345&#123; "id": "1234567890", "name": "mingshan", "admin": true&#125; 然后将有效Payload用Base64进行编码，以形成JWT的第二部分。 Signature要创建签名部分，必须要有已经编码的header，编过码的Payload，一个密匙（secret）和加密算法。 例如，如果想使用HMAC SHA256算法，签名将按以下方式创建： 1234HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 详细细节请参考JWT官网 JWT官网介绍 RESTful与JWT结合进行鉴权上面只是介绍一下RESTful API和JWT，下面我们来考虑怎么实现。 首先是流程，借用JWT官网上的一幅图 从图中我们可以总结如下（以Client和Server端为例）： 首先Client发起认证请求，包含用户名和密码，进行登录操作 Server端验证用户名和密码，验证通过的话用密匙生成token，并将token存储起来，然后将token返回给Client 此时Client已经验证登录过了，下次进行请求时将token放在header的Authorization中 Server端根据规则将token解析出来，拿到subject，从到拿到用户信息，然后通过用户信息去拿已经存储的token，然后将两个token进行比较，从而判断用户是否已登录 将验证信息发送给Client 通过上面的流程分析，我们发现其实并不怎么难。但现在有几个地方我们还没有说 怎样标识哪些API需要鉴权，如何优雅地处理？ token存在哪个地方？ token的生成与解析如何去做？ 下面我们依次来分析。 标识哪些API需要鉴权标识哪些API需要鉴权，我们需要自定义注解，然后将注解加到需要鉴权的API上面就可以了，这里自定义两个注解，@Authorization 和 @CurrentUser，@Authorization就是标识哪些API需要鉴权，@CurrentUser就是将从token获取的用户信息封装到当前user对象里面，主要用在登出处理，下面是代码： 12345678910/** * @Description: * @Author: mingshan * @see com.lightblog.authorization.interceptor.AuthorizationInterceptor * @Date: Created in 19:23 2017/10/14 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Authorization &#123;&#125; 12345678910/** * @Description: * @Author: mingshan * @Date: Created in 19:29 2017/10/14 */@Target(ElementType.PARAMETER)@Retention(RetentionPolicy.RUNTIME)public @interface CurrentUser &#123;&#125; 由于我用到SpringMVC，所以我就考虑添加拦截器来处理用户的鉴权请求，Spring为我们提供了org.springframework.web.servlet.handler.HandlerInterceptorAdapter这个适配器，继承此类，可以非常方便的实现自己的拦截器。这里主要重写它的预处理方法来处理请求，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * The custom interceptor that checks out the current request has authorization. * @Author: mingshan * @Date: Created in 19:27 2017/10/14 */@Componentpublic class AuthorizationInterceptor extends HandlerInterceptorAdapter &#123; @Autowired private TokenManager tokenManager; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // Checks out the annotation of authorization that is method level. if (!(handler instanceof HandlerMethod)) &#123; return true; &#125; HandlerMethod handlerMethod = (HandlerMethod)handler; Method method = handlerMethod.getMethod(); // Gets authorization string from request header. String authorization = request.getHeader(Constants.AUTHORIZATION); // Gets the model of Token from authorization string. TokenModel token = tokenManager.getToken(authorization); // Checks out the token that is from Redis, if (tokenManager.checkToken(token)) &#123; // Puts userId into request. request.setAttribute(Constants.CURRENT_USER_ID, token.getUserId()); return true; &#125; // If verify token failed, and the current method has the annotation of authorization, // sets the response code to 401. // The 401 code means unauthorized. if (method.getAnnotation(Authorization.class) != null) &#123; response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); return false; &#125; return true; &#125;&#125; 在上面的preHandle方法里，我们首先得到处理的方法，从http请求的Authorization中拿到token，然后解析token，检测token，如果检测token成功，那么将用户id放到request中，返回true继续执行，如果检测失败，那么返回http状态码401，401意味着未认证，返回false，不继续往下执行了。 toekn存储位置在我这里我是将token存在了Redis里，用户id作为key，token作为value，解析token和检测token主要在RedisTokenManager类中，主要有创建token，删除token，从jwt中获取token以及检测token，比较简单，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * The implement class of Token manager. * @Author: mingshan * @Date: Created in 23:41 2017/10/13 */public class RedisTokenManager implements TokenManager &#123; private static final Logger logger = LoggerFactory.getLogger(RedisTokenManager.class); private RedisTemplate&lt;Long, String&gt; redisTemplate; public void setRedisTemplate(RedisTemplate&lt;Long, String&gt; redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; @Override public TokenModel creatToken(long userId) &#123; User user = new User(); user.setId(userId); String subject = JWTUtil.generalSubject(user); String token = JWTUtil.createJWT(userId, subject, Constants.JWT_TTL); TokenModel model = new TokenModel(userId, token); redisTemplate.boundValueOps(userId).set(token, Constants.TOKEN_EXPIRES_HOUR, TimeUnit.HOURS); return model; &#125; @Override public void deleteToken(long userId) &#123; redisTemplate.delete(userId); &#125; @Override public boolean checkToken(TokenModel model) &#123; if (model == null) &#123; return false; &#125; Object source = redisTemplate.boundValueOps(model.getUserId()).get(); if (source == null) &#123; return false; &#125; String token = source.toString(); if ("".equals(token) || !token.equals(model.getToken())) &#123; return false; &#125; redisTemplate.boundValueOps(model.getUserId()).expire(Constants.TOKEN_EXPIRES_HOUR, TimeUnit.HOURS); return true; &#125; @Override public TokenModel getToken(String authorization) &#123; if (authorization == null || "".equals(authorization)) &#123; return null; &#125; User user = RequestCheck.getUserFromToken(authorization); if (user == null) &#123; return null; &#125; long userId = user.getId(); String token = RequestCheck.extractJwtTokenFromAuthorizationHeader(authorization); TokenModel model = new TokenModel(userId, token); return model; &#125;&#125; 上面这个类用到了如何去从JWT中解析token，这里的getUserFromToken方法是从JWT字符中解析token，具体来说先获取Cliams，然后获取subject，再从subject获取用户信息，最后封装成User对象，序列化对象用的是fastjson，并不复杂，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @Author: mingshan * @Date: Created in 12:41 2017/12/16 */public class RequestCheck &#123; protected static final Logger logger = LoggerFactory.getLogger(RequestCheck.class); public static User getUserFromToken(String auth) &#123; if (auth == null) &#123; return null; &#125; if (!Constants.TOKEN_PREFIX.equals(auth.substring(0, 7))) &#123; return null; &#125; else &#123; String token = extractJwtTokenFromAuthorizationHeader(auth); try &#123; Claims claims = JWTUtil.parseJWT(token); String subject = claims.getSubject(); User user = JSONObject.parseObject(subject, User.class); return user; &#125; catch (Exception e) &#123; e.printStackTrace(); logger.error("解析JWT token 失败！"); &#125; &#125; return null; &#125; /** * 获取真实的toekn，去掉‘Bearer ’ * @param auth * @return */ public static String extractJwtTokenFromAuthorizationHeader(String auth) &#123; // Replace "Bearer Token" to "Token" directly return auth.replaceFirst("[B|b][E|e][A|a][R|r][E|e][R|r] ", "").replace(" ", ""); &#125; public static void main(String[] args) &#123; String s = "Bearer 122"; System.out.print(extractJwtTokenFromAuthorizationHeader(s)); User user = new User(); user.setId(1); JSONObject jo = new JSONObject(); jo.put("userId", user.getId()); System.out.print(jo.toJSONString()); &#125;&#125; token的生成与解析这里我们写了一个工具类JWTUtil，用来创建token和解析JWT，先引入jjwt，jjwt封装了操作jwt的常用操作 12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt;&lt;/dependency&gt; 其中header和Payload的编解码用到了java.util.Base64的代码， 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * @Author: mingshan * @Date: Created in 21:29 2017/12/14 */public class JWTUtil &#123; /** * * 编码 * String asB64 = Base64.getEncoder().encodeToString("some string".getBytes("utf-8")); * * 解码 * byte[] asBytes = Base64.getDecoder().decode("c29tZSBzdHJpbmc="); * System.out.println(new String(asBytes, "utf-8")); */ /** * 获得加密的key * @return 加密后的key */ public static SecretKey generateKey() &#123; byte[] encodedKey = Base64.getDecoder().decode(Constants.JWT_SECRET); SecretKey key = new SecretKeySpec(encodedKey, 0, encodedKey.length, "AES"); return key; &#125; /** * 签发 JWT * @param id * @param subject * @param ttlMillis * @return 生成的JWT token */ public static String createJWT(Long id, String subject, long ttlMillis) &#123; SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); SecretKey secretKey = generateKey(); JwtBuilder builder = Jwts.builder() .setId(id.toString()) // JWT_ID .setSubject(subject) // 主题 .setIssuedAt(now) // 签发时间 .signWith(signatureAlgorithm, secretKey); // 签名算法以及密匙 if (ttlMillis &gt;= 0) &#123; // 设置过期时间 long expMillis = nowMillis + ttlMillis; Date expDate = new Date(expMillis); builder.setExpiration(expDate); &#125; return builder.compact(); &#125; /** * 解密jwt * @param jwt * @return * @throws Exception */ public static Claims parseJWT(String jwt) throws Exception&#123; SecretKey key = generateKey(); Claims claims = Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwt).getBody(); return claims; &#125; /** * 生成subject信息 * @param user * @return */ public static String generalSubject(User user)&#123; JSONObject jo = new JSONObject(); jo.put("id", user.getId()); return jo.toJSONString(); &#125;&#125; 完整代码本博客的完整代码在这里，可以参考一下：https://github.com/mstao/LightBlog/tree/master/light-blog-web 参考http://www.scienjus.com/restful-token-authorization/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RESTful-API</tag>
        <tag>Token</tag>
        <tag>JWT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[栈结构分析]]></title>
    <url>%2F2017%2F12%2F17%2F%E6%A0%88%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[栈介绍栈是一种仅在表头进行插入和删除操作的线性表，并且属于后进先出（last-in，first-out，LIFO）原则，下面是栈的入栈和出栈的图示： 主要操作栈主要有入栈和出栈操作，但要实现完整的栈操作，我们需要定义一些方法 push 入栈，将元素压入栈顶 pop 出栈，获取栈顶元素并将其从栈中删除 peek 获取栈顶元素，但不删除 empty 判断栈是否为空 size 获取栈内元素的数量 下面来介绍一下实现这些方法的具体实现。 具体实现栈内的元素是放在数组里面的，所以我们需要一些变量来存储和描述这些数据，定义如下： 123456// 存放栈内元素的数组，默认大小为10private Object[] elementData;// 元素的数量private int elementCount;// 指定要增加的容量大小private int capacityIncrement; 在构造方法中初始数组容量，代码如下： 12345678910111213141516171819202122232425262728/** * 通过传入自定义的值来初始化数组 * @param initialCapacity 数组容初始量 * @param capacityIncrement 扩容增加的容量 */public Stack(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125;/** * 通过传入自定义的值来初始化数组 * @param initialCapacity 数组初始容量 */public Stack(int initialCapacity) &#123; this(initialCapacity, 0);&#125;/** * 构造方法初始化数组容量 */public Stack() &#123; this(10);&#125; push入栈操作需要将数据存到数组里面，如有数组有初始化大小，所以每次入栈操作需要检查数组的大小，大小不够需要进行扩容操作，代码如下： 123456789/** * 入栈 * @param data * @return 入栈的数据 */public E push(E data) &#123; addElement(data); return data;&#125; 这里调用了addElement(data)方法，我们来看看代码： 12345678/** * 向栈顶添加元素 * @param obj */private void addElement(E obj) &#123; ensureCapacity(elementCount + 1); elementData[elementCount++] = obj;&#125; 在addElement(data)方法中调用ensureCapacity来检测数组的大小，扩容操作也是在这个方法中进行的，下面是方法的代码： 123456789101112131415/** * 确保栈容量，扩容 * @param minCapacity */private void ensureCapacity(int minCapacity) &#123; int oldCapacity = elementData.length; // 判断是否需要扩容 if (oldCapacity &lt; minCapacity) &#123; // 指定要扩大多少，否则就扩容2倍 int newCapacity = oldCapacity + (this.capacityIncrement &gt; 0 ? this.capacityIncrement : oldCapacity); // 将原数组的容量拷贝到扩容后的数组 elementData = Arrays.copyOf(elementData, newCapacity); &#125;&#125; 在这个方法中，首先判断当前的数组的大小够不够用，如果不够用，那么会根据传入的自定义扩容大小capacityIncrement来进行扩容操作，如果capacityIncrement小于0，那么容量就扩大2倍。最后将原来数组的数据拷贝到新数组中。 pop出栈是将栈顶的元素移除并返回，下面是代码： 12345678910111213/** * 出栈，移除栈顶的元素 * @return 被移除的元素 */public E pop() &#123; E obj = peek(); if (size() &gt; 0) &#123; // 移除栈顶元素 elementData[elementCount - 1] = null; elementCount--; &#125; return obj;&#125; 在pop方法中，我们实则是调用了peek方法来获取栈顶元素，然后将栈顶元素移除下面来看peek的代码。 peekpeek方法是获取栈顶的元素，代码比较简单 12345678910111213/** * 获取栈顶的元素，但不移除 * @return 栈顶的元素 */@SuppressWarnings("unchecked")public E peek() &#123; int len = size(); if (len == 0) throw new EmptyStackException(); E obj = (E) elementData[elementCount - 1]; return obj;&#125; search通过传入的元素来获取该元素第一次出现的位置，如果找不到返回-1，下面是代码： 12345678910111213141516171819202122/** * 返回对象在堆栈中的位置，以 0 为基数。 * @param element * @return 元素第一次出现的位置，找不到返回-1 */public int search(Object element) &#123; int z = elementCount - 1; if (element == null) &#123; for (int i = z; i &gt; 0; i--) &#123; if (elementData[i] == null) &#123; return i; &#125; &#125; &#125; else &#123; for (int i = z; i &gt; 0; i--) &#123; if (element.equals(elementData[i])) &#123; return i; &#125; &#125; &#125; return -1;&#125; 由于栈可以存储null，所以需对null进行处理。 完整代码本篇博客的完整代码 https://github.com/mstao/data-structures/blob/master/Stack/src/pers/mingshan/stack/Stack.java]]></content>
      <categories>
        <category>数据结构</category>
        <category>栈</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双向链表结构分析]]></title>
    <url>%2F2017%2F12%2F17%2F%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[双向链表描述双向链表也叫双链表，它的每个数据结点都有两个指针，分别指向前驱结点和后继节点，同时有一个数据域来保存数据，双向链表的图示如下： 从图片可以看出，双链表的头结点的前驱结点和尾结点的后继结点为空，这一点要注意，对双链表的操作要检查这两种情况。 双向链表结构每个数据结点都有两个指针，分别指向前驱结点和后继节点，同时有一个数据域来保存数据，我们先来定义一个数据结点的结构： 12345678910111213141516171819/** * 内部Node，用于存储链表的结点 * @author mingshan * */private class Node &#123; // 存储节点的值 E item; // 指向节点的前驱结点 Node next; // 指向节点的后继结点 Node prev; Node(Node prev, E element, Node next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 从Node类我们可以看出，item代表结点存储的元素，next指向链表的后继结点，prev指向前驱结点，由于我们在写单链表时定义了LinkedList接口，所以我们直接实现这个接口好了。 下面是对双向链表的功能的具体分析。 add方法我们现在定义三个成员变量：size， first，last，用来表示链表结点的个数以及指向链表头结点和尾节点，代码与解释如下： 12345678// 链表结点数量private int size = 0;// 指向头结点private Node first;// 指向尾结点private Node last; add(E data)首先我们来实现add(E data)方法，代码如下： 12345678@Overridepublic boolean add(E data) &#123; if (data == null) throw new NullPointerException(); // 将当前结点作为尾结点 linkLast(data); return true;&#125; 在这个方法中我们调用了linkLast(data)这个方法来将当前节点作为尾结点，代码如下： 12345678910111213141516/** * 将当前结点作为尾结点 * @param e */private void linkLast(E data) &#123; final Node l = last; final Node newNode = new Node(l, data, null); last = newNode; if (l == null) &#123; first = newNode; &#125; else &#123; // 原来的尾结点指向新结点 l.next = newNode; &#125; size++;&#125; 在linkLast方法中，先获取尾结点，再构造新节点，让last指向新节点，然后开始判断原来的尾节点是否为空，为空代表链表为空，让first指向新结点即可；如果不为空，那么原来的尾结点的next指向新结点。 add(int index, E data)我们再来add(int index, E data)这个方法怎么实现，代码如下： 123456789101112131415@Overridepublic void add(int index, E data) &#123; if (data == null) throw new NullPointerException(); checkPositionIndex(index); // 判断在该索引的结点是不是尾结点 if (size == index) &#123; // 将当前结点作为尾结点 linkLast(data); &#125; else &#123; // 将结点插入到指定位置index(原来的结点之前) linkBefore(index, data); &#125;&#125; 这个方法的作用是向索引位置index处添加结点，这个时候我们就需要检测index是否有效，checkPositionIndex(index)相关的方法如下： 123456789101112/** * 检测索引位置是否合法 * @param index */private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IllegalArgumentException("参数不合法");&#125;private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size;&#125; 如果index符合以上要求，那么就要判断在该索引位置的结点是不是尾结点，如果是，直接调用linkLast(data) 将当前节点作为尾结点；如果不是，将结点插入到指定位置index(原来的结点之前)，此时调用linkBefore(index, data)方法，代码如下： 123456789101112131415161718/** * 将结点插入到指定位置index(原来的结点之前) * @param index * @param data */private void linkBefore(int index, E data) &#123; Node curr = node(index); Node pred = curr.prev; Node newNode = new Node(pred, data, curr); curr.prev = newNode; if (pred == null) &#123; first = newNode; &#125; else &#123; pred.next = newNode; &#125; size++;&#125; 在该方法中，我们需要获取在该索引位置的节点curr，curr的前驱结点pred，以及构造新节点newNode，同时还要将curr的前驱结点指向新节点，然后判断pred是否为空，如果pred为空，说明curr为头结点，那么此时就让新节点作为头结点；如果不为空，说明此时属于一般情况，在链表的中间的某个位置插入元素，那么就让prev的后继结点指向新节点就行了。 remove方法remove(int index)根据索引位置来删除元素，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940@Overridepublic E remove(int index) &#123; checkElementIndex(index); // 获取在该索引位置上的结点 Node c = node(index); E element = c.item; Node prev = c.prev; Node next = c.next; // 代表头结点 if (prev == null) &#123; // 将下一个结点置为头结点 first = next; // 将下一个结点的前驱结点置为null next.prev = null; // 将原来头结点的后继结点置为null c.next = null; &#125; else if (next == null) &#123; // 移除尾结点 last = prev; // 前一个结点的后继结点置为null prev.next = null; // 将原来尾结点的前驱结点置为null c.prev = null; &#125; else &#123; // 属于一般情况 // 将前一个结点的后继结点置为原结点的后继结点 prev.next = next; // 将后一个结点的前驱结点置为原结点的前驱结点 next.prev = prev; // 切断当前删除的结点的前驱和后继结点 c.prev = null; c.next = null; &#125; c.item = null; size--; return element;&#125; 在该方法中，还是要先检测索引是否合法，这里是checkElementIndex(index)方法，代码如下： 123456789101112/** * 检测元素位置是否合法 * @param index */private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException("查找元素位置不合法");&#125;private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size;&#125; 检测通过后就要获取在该索引处的结点信息，包括结点的数据，前驱节点和后继节点，此时有三种情况需要考虑： 如果prev为空，代表该结点为头结点，那么就将下一个结点置为头结点，然后将下一个结点的前驱结点置为null，最后将原来头结点的后继结点置为null。说白了就是讲头结点移除，同时解除头结点与后面一个节点的关系。 如果next为空，代表该结点为尾节点，那么就将尾节点的前驱节点作为尾节点，前一个结点的后继结点置为null，将原来尾结点的前驱结点置为null。 如果既不是头结点，又不是尾节点，那么就属于一般情况了，此时将前一个结点的后继结点置为原结点的后继结点，将后一个结点的前驱结点置为原结点的前驱结点，最后切断当前删除的结点的前驱和后继结点。 以上代码可以简化，具体可以参考JDK源码中java.util.LinkedList中的unlink方法，简化后的代码如下： 1234567891011121314// 代表头结点if (prev == null) &#123; first = next;&#125; else &#123; prev.next = next; c.prev = null;&#125;if (next == null) &#123; last = prev;&#125; else &#123; next.prev = prev; c.next = null;&#125; 老铁们看的懂吗(￣▽￣)／，其实和我上面的代码效果是一样的，只是把一般情况合并了，也很好理解。 set方法set方法将索引位置的结点的值替换成新的值，代码如下： 1234567891011121314@Overridepublic E set(int index, E data) &#123; if (data == null) throw new NullPointerException(); checkPositionIndex(index); // 获取原来在该索引位置上的结点 Node oldNode = node(index); // 获取原来结点的值 E oldValue = oldNode.item; // 更新值 oldNode.item = data; return oldValue;&#125; 此时获取当前索引位置的结点用到了node(index)方法，代码如下： 123456789101112131415161718192021222324/** * 根据索引获取结点 * @param index * @return */private Node node(int index) &#123; // 如果当前索引值小于当前链表长度的一半，那么从头结点开始遍历 if (index &lt; size / 2) &#123; Node temp = first; for (int i = 0; i &lt; index; i++) &#123; temp = temp.next; &#125; return temp; &#125; else &#123; // 如果当前索引值大于当前链表长度的一半，那么从尾结点反向遍历 Node temp = last; for (int i = size - 1; i &gt; index; i--) &#123; temp = temp.prev; &#125; return temp; &#125;&#125; 在node方法中，我们进行了折半查找，这样效率会高些吧，哈哈，简单就不说了。 get方法获取传入索引的结点的值，也需要遍历双链表，就不说了，代码如下： 1234567@Overridepublic E get(int index) &#123; checkElementIndex(index); // 获取其索引的结点 Node node = node(index); return node.item;&#125; 反转双链表反转双链表，这里我采用是遍历双链表，逐个链接点进行反转。原理是：使用p和q两个指针配合工作，使得两个节点间的指向反向，同时用r记录剩下的链表。图示如下： 具体代码和步骤参考如下代码：1234567891011121314151617181920212223242526272829303132333435@Overridepublic void reverse() &#123; if (first != null) &#123; // 代表指向当前进行反转的下一个结点 Node r; // p 代表进行结点指向反转的结点前一个结点 Node p = first; // q 代表进行结点指向反转的当前结点 Node q = first.next; // 首先将head指向的下一个结点置为null // 因为进行链表反转时头结点变成了尾结点，指向的下一个结点必然是null first.next = null; // 进行循环操作，p, q指向向前移动 while (q != null) &#123; // 将当前正在反转的结点的下一个结点指向r r = q.next; // 将当前结点的下一个结点指向其前一个结点(由指向后一个结点改为指向前一个结点) q.next = p; // 将当前结点的prev改为指向下一个结点 p.prev = q; // p和q都向链表后面移一位 // 原来的q变成了p p = q; // 原来的r变成了q q = r; &#125; // 将最后一个结点的prev指向为null p.prev = null; // 将原来的头结点置为尾结点 last = first; // 将最后一个结点置为头结点 first = p; &#125;&#125; 完整代码本篇博客的完整代码 https://github.com/mstao/data-structures/blob/master/LinkedList/src/pers/mingshan/linkedlist/DoubleLinkedList.java]]></content>
      <categories>
        <category>数据结构</category>
        <category>链表</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>双向链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表结构分析]]></title>
    <url>%2F2017%2F12%2F12%2F%E5%8D%95%E9%93%BE%E8%A1%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[单链表描述单链表又为单向链表，由数据域(Data)和结点域(Node)组成，数据域代表该结点所存储的元素，结点域指向下一个节点，单链表的图示如下： 单链表结构我们先定义一下单链表一个结点的结构，一个Node类： 12345678private class Node &#123; E item; Node next; public Node(E e) &#123; this.item = e; &#125;&#125; 从Node类我们可以看出，item代表结点存储的元素，next指向链表的下一个节点。谈到链表，肯定少不了链表的基本操作，比如添加结点，删除结点，获取给定索引的节点啦，所以我们先写一个链表接口LinkedList，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package pers.mingshan.linkedlist;/** * 链表接口 * @author mingshan * * @param &lt;E&gt; */public interface LinkedList&lt;E&gt; &#123; /** * 根据索引获取节点的值 * @param index 传入的索引值， 从1开始 * @return 节点的值 */ E get(int index); /** * 设置某个结点的的值 * @param index 传入的索引值， 从1开始 * @param data 要插入的元素 * @return 旧的节点的值 */ E set(int index, E data); /** * 根据index添加结点 * @param index 传入的索引值， 从1开始 * @param data 要插入的元素 * @return 插入是否成功 */ void add(int index, E data); /** * 添加结点 * @param data * @return 插入是否成功 */ boolean add(E data); /** * 根据index移除结点 * @param index 传入的索引值， 从1开始 * @return 移除成功返回该索引处的旧值 */ E remove(int index); /** * 根据data移除结点 * @param data * @return 是否移除成功 */ boolean removeAll(E data); /** * 清空链表 */ void clear(); /** * 是否包含data结点 * @param data * @return 包含返回&#123;@code true&#125;, 不包含返回 &#123;@code false&#125; */ boolean contains(E data); /** * 获取链表长度 * @return 链表长度 */ int length(); /** * 判断链表是否为空 * @return 链表为空返回&#123;@code true&#125;, 不为空返回 &#123;@code false&#125; */ boolean isEmpty(); /** * 链表反转 */ void reverse();&#125; 这么多方法，先实现哪个呢？由于我们做了很多的增删改查，那么就从增加新结点开始吧(￣▽￣)／ add方法我们首先实现add(E data)，代码如下： 1234567891011121314151617181920212223242526@Overridepublic boolean add(E data) &#123; if (data == null) throw new NullPointerException(); if (head == null) &#123; Node newNode = new Node(data); head = newNode; size++; return true; &#125; Node temp = head; // 从头结点向后遍历，获取链表最后一个节点 while (temp.next != null) &#123; // temp 始终指向下一个节点 temp = temp.next; &#125; // 根据当前元素构造新节点 Node newNode = new Node(data); // 将最后一节点的next指向新节点 temp.next = newNode; // 计数加一 size++; return true;&#125; 在add(E data)方法中，首先进行判空操作，然后检查头结点是否为空，如果头结点为空那么就把该新结点作为头结点；如果头结点不为空，那么就需要从头结点开始遍历单链表，直到找到尾节点，并将原来的尾节点的next指向新添加的结点，链表的元素数量加一。 然后实现add(int index, E data)，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 根据索引插入元素 * @param e 要插入的元素 * @param index 传入的索引值， 从1开始 */@Overridepublic void add(int index, E data) &#123; if (data == null) throw new NullPointerException(); checkPositionIndex(index); int count = 1; Node temp = head; // 从头结点向后遍历 while (temp.next != null) &#123; // 1 2 // temp temp.next // 假设现在index为2 那么原先在2位置上的节点需要向后移动一个 // 1 2 3 // temp temp.next(e) temp.next.next // 判断是否到了传入的索引 // 如果索引为1，那么将当前节点置为头结点 if (index == 1) &#123; Node newNode = new Node(data); head = newNode; head.next = temp; size++; &#125; // 判断是否到了传入的索引 if (++count == index) &#123; // 构造新节点 Node newNode = new Node(data); // 将当前的位置的节点设置为新节点 newNode.next = temp.next; temp.next = newNode; size++; &#125; // temp 始终指向下一个节点 temp = temp.next; &#125;&#125; add(int index, E data)这个方法是根据传入的索引值向链表插入元素。首选需要进行判空操作，然后检测传入的索引值是否合法，代码如下： 123456789101112/** * 检测索引位置是否合法 * @param index */private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IllegalArgumentException("参数不合法");&#125;private boolean isPositionIndex(int index) &#123; return index &gt;= 1 &amp;&amp; index &lt;= size;&#125; 检测完之后，需要判断传入的索引值的位置上的节点是否为头结点，如果是，将新结点设置为头结点，并将新结点的next指向原来的头结点。然后进行链表遍历，直到索引位置，在该位置之前插入新结点即可，具体参考代码注释。 remove方法现在我们根据索引值删除结点，代码如下：12345678910111213141516171819202122232425262728/** * 根据索引删除元素 * @param index 传入的索引值， 从1开始 */@Overridepublic E remove(int index) &#123; checkPositionIndex(index); int count = 1; Node temp = head; // 从头结点向后遍历 while (temp.next != null) &#123; if (index == 1) &#123; head = head.next; return head.item; &#125; if (++count == index) &#123; E oldValue = temp.next.item; temp.next = temp.next.next; return oldValue; &#125; // temp 始终指向下一个节点 temp = temp.next; &#125; return null;&#125; 这个删除操作也比较简单，也需要遍历单链表，直到索引位置结点，然后将结点的前驱节点的next指向索引节点的下一个节点即可。 set方法set方法将索引的结点的值设置为传入的值，也需要遍历单链表，套路都一样。代码如下：12345678910111213141516171819@Overridepublic E set(int index, E data) &#123; if (data == null) throw new NullPointerException(); checkPositionIndex(index); int count = 1; Node temp = head; while (temp != null) &#123; if (count++ == index) &#123; E oldValue = temp.item; temp.item = data; return oldValue; &#125; temp = temp.next; &#125; return null;&#125; get方法获取传入索引的结点的值，也需要遍历单链表，就不说了，代码如下：1234567891011121314@Overridepublic E get(int index) &#123; checkPositionIndex(index); int count = 1; Node temp = head; while (temp != null) &#123; if (count++ == index) &#123; return temp.item; &#125; temp = temp.next; &#125; return null;&#125; 反转单链表反转单链表，这里我采用是遍历单链表，逐个链接点进行反转。原理是：使用p和q两个指针配合工作，使得两个节点间的指向反向，同时用r记录剩下的链表。流程如下图： 具体代码和步骤参考如下代码：123456789101112131415161718192021222324252627282930313233343536/** * 链表反转 * 遍历单链表，逐个链接点进行反转。 * 原理： * 使用p和q两个指针配合工作，使得两个节点间的指向反向，同时用r记录剩下的链表。 * */@Overridepublic void reverse() &#123; if (head != null) &#123; // 代表指向当前进行反转的下一个节点 Node r; // p 代表进行节点指向反转的节点前一个节点 Node p = head; // q 代表进行节点指向反转的当前节点 Node q = head.next; // 首先将head指向的下一个节点置为null // 因为进行链表反转时头结点变成了尾节点，指向的下一个节点必然是null head.next = null; // 进行循环操作，p, q指向向前移动 while (q != null) &#123; // 将当前正在反转的节点的下一个节点指向r r = q.next; // 将当前节点的下一个节点指向其前一个节点(由指向后一个节点改为指向前一个节点) q.next = p; // p和q都向链表后面移一位 // 原来的q变成了p p = q; // 原来的r变成了q q = r; &#125; head = p; &#125;&#125; 完整代码本篇博客的完整代码 https://github.com/mstao/data-structures/blob/master/LinkedList/src/pers/mingshan/linkedlist/SingleLinkedList.java 参考http://blog.csdn.net/feliciafay/article/details/6841115]]></content>
      <categories>
        <category>数据结构</category>
        <category>链表</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>单链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恢复被Reset掉的提交]]></title>
    <url>%2F2017%2F12%2F04%2F%E6%81%A2%E5%A4%8D%E8%A2%ABReset%E6%8E%89%E7%9A%84%E6%8F%90%E4%BA%A4%2F</url>
    <content type="text"><![CDATA[记得有一次我用github的桌面客户端提交代码时，提交了我不想提交的内容，于是我就点了Revert按钮，进行了Revert操作，这个操作会撤销一个提交的同时会新建一个提交，这也不是我想要的效果，所以我就用了Reset命令，最后操作失误，提交的代码都丢了，这让我很忧伤，但我之前进行提交操作了，git会有提交记录，所以我查了查命令，发现了git reflog命令，这个命令用于记录对git仓库进行的各种操作，输入命令显示如下： 1234567891011121314D:\code\LightBlog [master ≡ +0 ~2 -0 !]&gt; git reflog4ca2fb7 HEAD@&#123;0&#125;: commit: Add spring-redis for cacheddcc61a HEAD@&#123;1&#125;: commit: Add light blog ui template1e9f0b9 HEAD@&#123;2&#125;: pull --progress --prune origin master: Fast-forward93d6519 HEAD@&#123;3&#125;: commit: Add encryption util with MD51d158ff HEAD@&#123;4&#125;: commit: fIX(#2) HttpStatus 204 -&gt;no contentef8cb50 HEAD@&#123;5&#125;: revert: Revert &quot;Refine exception handler&quot;51a7b00 HEAD@&#123;6&#125;: rebase: updating HEAD51a7b00 HEAD@&#123;7&#125;: rebase: abortinge20b30f HEAD@&#123;8&#125;: pull --progress --rebase --prune origin master: checkout e20b30f0a282cb4b1229a5ebcf220422d3685c4051a7b00 HEAD@&#123;9&#125;: commit: Refine exception handler294b1e3 HEAD@&#123;10&#125;: pull --progress --prune origin master: Merge made by the &apos;recursive&apos; strategy.927ff21 HEAD@&#123;11&#125;: commit: Add exception handler for RESTful4e2592c HEAD@&#123;12&#125;: commit: Add authorization for web with redis. 可以看见每次操作都会有记录的（没有全部贴出来），这是我们可以用git reset ID来恢复内容，ID指的第一列的东西，比如4ca2fb7，这样我们就可以找回丢失的内容了。 下面是我常用的一套命令，用来更新本地代码，这也是我经过好几次拉取远程代码冲突一大片得到的经验，git mergetool指的是当发生代码冲突时，输入此命令就会进行冲突的解决，由于我用的VS，输入此命令后就会跳到VS中来解决冲突了，对于一个文件如果冲突实在是太多，推荐winmerge工具，一个轻量且免费的冲突合并工具，我平时也用。 123456789101112131415git statusgit commit -m &apos;temp commit&apos;git stash save appconfiggit loggit pull -r origin developgit mergetool(回车合并冲突)git reset HEAD~git stash apply]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot与RabbitMQ结合使用]]></title>
    <url>%2F2017%2F11%2F25%2FSpringBoot%E4%B8%8ERabbitMQ%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[上一篇文章中是使用amqp-client来操作RabbitMQ的，但我们平常用SpringBoot比较多，SpringBoot也整合了RabbitMQ，用起来是十分方便的。 首先，我们先添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 然后在application.properties文件添加RabbitMQ的配置： 1234567# rabbitmqspring.application.name=spring-boot-rabbitmqspring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guestspring.rabbitmq.publisher-confirms=true Hello我们先来个hello，首先在发送方注入AmqpTemplate，像其它Spring Framework提供的高级抽象一样， Spring AMQP 提供了扮演核心角色的模板. 定义了主要操作的接口称为AmqpTemplate. 这些操作包含了发送和接收消息的一般行为。 在配置类RabbitConfig类生成一个名为hello_rq的队列 123456789@Configurationpublic class RabbitConfig &#123; @Bean public Queue helloQueue() &#123; return new Queue(&quot;hello_rq&quot;); &#125;&#125; 发送方： 12345678910111213@Componentpublic class Sender &#123; private final static Logger logger = LoggerFactory.getLogger(Sender.class); @Autowired private AmqpTemplate amqpTemplate; public void send() &#123; String context = "hello " + new Date(); logger.info("Sender : " + context); this.amqpTemplate.convertAndSend("hello_rq", context); &#125;&#125; 这里我们用了convertAndSend方法进行消息的发送，将消息发送到hello_rq的队列中 接收方： 1234567891011@Component@RabbitListener(queues = "hello_rq")public class Receiver &#123; private final static Logger logger = LoggerFactory.getLogger(Receiver.class); @RabbitHandler public void process(String hello) &#123; logger.info("Receiver1 : " + hello); &#125;&#125; 在接收方利用@RabbitListener注解来监听队列，利用@RabbitHandler来处理消息 测试类： 1234567891011@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class HelloTest &#123; @Autowired private Sender sender; @Test public void hello() throws Exception &#123; sender.send(); &#125;&#125; 四种 Exchange Typesfanoutfanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 生产者代码： 1234567891011121314@Componentpublic class FanoutProducer &#123; private final static Logger logger = LoggerFactory.getLogger(FanoutProducer.class); @Autowired private AmqpTemplate amqpTemplate; public void send() &#123; String message = "This is topic message ====!"; logger.info("message =&gt; " + message); this.amqpTemplate.convertAndSend("ex.fanout", "", message); &#125;&#125; 上面代码中的convertAndSend有三个参数，第一个参数设置exchange名称，第二个参数设置routingKey，第三个参数设置要发送的消息，由于是fanout，所以没必要设置routingKey的值，其实在源码中，也是最终调用channel.basicPublish方法的。源码如下： 123BasicProperties convertedMessageProperties = this.messagePropertiesConverter .fromMessageProperties(messageProperties, this.encoding);channel.basicPublish(exchange, routingKey, mandatory, convertedMessageProperties, messageToUse.getBody()); 消费者代码： 123456789101112@Component@RabbitListener(bindings = @QueueBinding(value = @Queue, exchange = @Exchange(value = "ex.fanout", type = ExchangeTypes.FANOUT)))public class FanoutConsumerA &#123; private final static Logger logger = LoggerFactory.getLogger(FanoutConsumerA.class); @RabbitHandler public void process(String message) &#123; logger.info("ConsumerA Receiver :" + message); &#125;&#125; 这里用@RabbitListener注解来监听，利用@RabbitHandler来处理消息。其中在@RabbitListener中又为队列，交换器和绑定的@QueueBinding 注解中指定参数，一个参数比较全的例子如下： 1234567891011121314@RabbitListener(bindings = @QueueBinding( value = @Queue(value = &quot;auto.headers&quot;, autoDelete = &quot;true&quot;, arguments = @Argument(name = &quot;x-message-ttl&quot;, value = &quot;10000&quot;, type = &quot;java.lang.Integer&quot;)), exchange = @Exchange(value = &quot;auto.headers&quot;, type = ExchangeTypes.HEADERS, autoDelete = &quot;true&quot;), arguments = &#123; @Argument(name = &quot;x-match&quot;, value = &quot;all&quot;), @Argument(name = &quot;foo&quot;, value = &quot;bar&quot;), @Argument(name = &quot;baz&quot;) &#125;))public class HeadersConsumerA &#123; &#123; ...&#125; 注意队列的x-message-ttl 参数设为了10秒钟，因为参数类型不是String， 因此我们指定了它的类型，在这里是Integer。有了这些声明后，如果队列已经存在了，参数必须匹配现有队列上的参数。对于header交换器，我们设置binding arguments 要匹配头中foo为bar，且baz可为任意值的消息。 x-match 参数则意味着必须同时满足两个条件。 测试类： 1234567891011@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class FanoutTest &#123; @Autowired private FanoutProducer fanoutProducer; @Test public void test() &#123; fanoutProducer.send(); &#125;&#125; directdirect类型的Exchange路由规则也比较简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中。 生产者代码： 123456789101112131415161718@Componentpublic class DirectProducer &#123; private final static Logger logger = LoggerFactory.getLogger(DirectProducer.class); @Autowired private AmqpTemplate amqpTemplate; public void send() &#123; String message = "This is topic message @====!"; logger.info("message =&gt; " + message); // 参数意义 // 第一个： exchange 名称 // 第二个： routingKey // 第三个： 发送的消息 this.amqpTemplate.convertAndSend("ex.direct", "error", message)里面的第二个参数为routingKey,设置为 &#125;&#125; 此时convertAndSend(“ex.direct”, “error”, message)里面的第二个参数为routingKey,设置为error，说明消费者的bindingKey须为error才能接受到消息，其他的接收不到。 消费者代码: 12345678910111213@Component@RabbitListener(bindings = @QueueBinding(value = @Queue, exchange = @Exchange(value = "ex.direct", type = ExchangeTypes.DIRECT), key = "info"))public class DirectConsumerA &#123; private final static Logger logger = LoggerFactory.getLogger(DirectConsumerA.class); @RabbitHandler public void process(String message) &#123; logger.info("ConsumerA Receiver :" + message); &#125;&#125; 在消费者A中，routingKey设置为info，自然接受不到消息了。 测试类： 1234567891011@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class DirectTest &#123; @Autowired private DirectProducer directProducer; @Test public void test() &#123; directProducer.send(); &#125;&#125; topic由于direct的匹配规则需要完全配置，没有灵活性，所以topic就弥补了这一缺点， routingKey 必须是由点分隔的单词列表。这些单词可以是任何东西，但通常它们指定连接到消息的一些功能。一些有效的路由键例子：“ stock.usd.nyse ”，“ nyse.vmw ”，“ quick.orange.rabbit ”。在路由选择键中可以有任意数量的字，最多255个字节。 绑定键也必须是相同的形式。binding key中可以存在两种特殊字符“*”与“#”，用于做模糊匹配： “*” 可以代替一个字。 “#” 可以代替零个或多个单词。 生产者代码: 123456789101112131415161718@Componentpublic class TopicProducer &#123; private final static Logger logger = LoggerFactory.getLogger(TopicProducer.class); @Autowired private AmqpTemplate amqpTemplate; public void send() &#123; String message = "This is topic message @====!"; logger.info("message =&gt; " + message); // 参数意义 // 第一个： exchange 名称 // 第二个： routingKey // 第三个： 发送的消息 this.amqpTemplate.convertAndSend("ex.topic", "quick.orange.rabbit", message); &#125;&#125; 此时routingKey为quick.orange.rabbit，消费者可以对这个routingKey进行模糊匹配。 消费者代码： 12345678910111213141516@Component@RabbitListener(bindings = @QueueBinding( //value = @Queue(value = "myQueue", durable = "true"), value = @Queue, // 自动生成， 自动删除 exchange = @Exchange(value = "ex.topic", ignoreDeclarationExceptions = "true", type = ExchangeTypes.TOPIC), key = "*.orange.*"))public class TopicConsumerA &#123; private final static Logger logger = LoggerFactory.getLogger(TopicConsumerA.class); @RabbitHandler public void process(String message) &#123; logger.info("ConsumerA Receiver :" + message); &#125;&#125; 此时bindingKey为.orange.，那么可以与生产者的routingKey匹配，那么这个消费者可以接受到消息。 headersheaders类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），消费者会根据设置x-match设置的配置类型(all,any)来进行匹配。 生产者代码： 12345678910111213141516171819202122232425@Componentpublic class HeadersProducer &#123; private final static Logger logger = LoggerFactory.getLogger(TopicProducer.class); @Autowired private AmqpTemplate amqpTemplate; public void send() &#123; String mes = "This is headers message ====!"; logger.info("message =&gt; " + mes); // 构建消息 Message message = MessageBuilder.withBody(mes.getBytes()) .setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN) .setMessageId("123") .setHeader("xiaoming", "123456") .build(); // 参数意义 // 第一个： exchange 名称 // 第二个： routingKey // 第三个： 发送的消息 this.amqpTemplate.convertAndSend("ex.headers", "", message); &#125;&#125; 生产者的代码比较特殊，首先我们需要构建消息，需要用到Message Builder API， MessageBuilder 和 MessagePropertiesBuilder提供了消息构建API; 它们提供了更加方便地创建消息和消息属性的方法: 1234567891011121314151617// 构建消息Message message = MessageBuilder.withBody(mes.getBytes()) .setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN) .setMessageId("123") .setHeader("xiaoming", "123456") .build();// 或者 ============================MessageProperties props = MessagePropertiesBuilder.newInstance() .setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN) .setMessageId("123") .setHeader("xiaoming", "123456") .build();Message message2 = MessageBuilder.withBody(mes.getBytes()) .andProperties(props) .build(); 其中MessageProperties.CONTENT_TYPE_TEXT_PLAIN代表 text/plain, 当然还有其他格式： 12345678910111213141516171819public static final String CONTENT_TYPE_BYTES = "application/octet-stream";public static final String CONTENT_TYPE_TEXT_PLAIN = "text/plain";public static final String CONTENT_TYPE_SERIALIZED_OBJECT = "application/x-java-serialized-object";public static final String CONTENT_TYPE_JSON = "application/json";public static final String CONTENT_TYPE_JSON_ALT = "text/x-json";public static final String CONTENT_TYPE_XML = "application/xml";public static final String SPRING_BATCH_FORMAT = "springBatchFormat";public static final String BATCH_FORMAT_LENGTH_HEADER4 = "lengthHeader4";public static final String SPRING_AUTO_DECOMPRESS = "springAutoDecompress";public static final String X_DELAY = "x-delay"; 消费者代码： 1234567891011121314151617@Component@RabbitListener(bindings = @QueueBinding(value = @Queue, exchange = @Exchange(value = "ex.headers", type = ExchangeTypes.HEADERS), arguments = &#123; @Argument(name = "x-match", value = "any"), @Argument(name = "xiaoming", value = "123456"), @Argument(name = "bbb", value = "1234567") &#125;))public class HeadersConsumerA &#123; private final static Logger logger = LoggerFactory.getLogger(HeadersConsumerA.class); @RabbitHandler public void process(String message) &#123; logger.info("ConsumerA Receiver :" + message); &#125;&#125; 此时headers的key-value形式映射为@Argument，x-match指明匹配模式，这里为any，代表只要有一个匹配到就可以接收到消息。 源码地址你可以在这里看到本博文的源代码： https://github.com/mstao/spring-boot-learning/tree/master/spring-boot-rabbitmq 参考http://www.blogjava.net/qbna350816/archive/2016/08/13/431562.html]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ中四种Exchange Types的理解]]></title>
    <url>%2F2017%2F11%2F20%2FRabbitMQ%E4%B8%AD%E5%9B%9B%E7%A7%8DExchange%20Types%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[由于在项目中用到了RabbitMQ，RabbitMQ是当前比较流行的消息中间件，所以在业余时间仔细了解下这个消息队列(Message Queue)。 RabbitMQ简介RabbitMQ实现了AMQP(Advanced Message Queuing Protocol)协议，AMQP是一种消息传递协议，是应用层协议的一个开放标准，为面向消息的中间件设计。具体介绍参考：AMQP介绍 RabbitMQ概念介绍RabbitMQ有许多重要的概念，了解这些概念对了解RabbitMQ是十分有必要的，下面简单介绍一下： RabbitMQ 消息模型 RabbitMQ消息发送时，生产者是不知道消息是否发送到某个队列中去了，生产者仅仅只能将消息发送给某个交换器。 ConnectionFactory 连接工厂类。可以创建一个连接。 Connection 在客户创建一个到某个虚拟主机的连接。 Channel 消息通道，包含了大量的API可用于编程。在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 Broker RabbbitMQ消息队列代理服务器实体。 Producer 发送消息的应用程序。 Consumer 接收消息的用户程序。 Exchange 交换器，生产者直接将消息发送给交换器。交换器将消息分发给指定的队列。它指定消息按什么规则，路由到哪个队列。 Binding 绑定，指的是交换器和队列之间的关系。它的作用就是把exchange和queue按照路由规则绑定起来。 Routing Key 路由关键字，exchange根据这个关键字进行消息投递。 vhost 虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 Excahnge Types RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种，下面分别进行介绍。 Exchange Types 简单介绍下面对这四种Exchange Types进行简单介绍，由于用到maven来组织项目，所以需要先添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.0.0&lt;/version&gt;&lt;/dependency&gt; fanoutfanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 上图中，生产者（P）发送到Exchange（X）的所有消息都会路由到图中的两个Queue，并最终被两个消费者（C1与C2）消费。 生产者代码： 12345678910111213141516171819202122232425/** * 生产者 * Exchange Types为fanout * * fanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 * @author mingshan * */public class Producer &#123; private final static String EXCHANGE_NAME = "logs"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); // 声明exchange，Exchange Types为fanout channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); String message = "Info-hello world"; channel.basicPublish(EXCHANGE_NAME, "", null, message.getBytes("UTF-8")); channel.close(); connection.close(); &#125;&#125; 由于fanout不需要选择将消息路由到哪个Queue，所以channel.basicPublish方法的第二个参数routingKey就不需要设置。 消费者代码： 12345678910111213141516171819202122232425262728293031/** * 消费者 * @author mingshan * */public class ConsumerA &#123; private final static String EXCHANGE_NAME = "logs"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); String queueName = channel.queueDeclare().getQueue(); channel.queueBind(queueName, EXCHANGE_NAME, ""); System.out.println("A Waiting for messages. To exit press CTRL+C"); Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println("A Recv '" + message + "'"); &#125; &#125;; channel.basicConsume(queueName, true, consumer); &#125;&#125; 在消费者代码中，我们的EXCHANGE_NAME需要与生产者的保持一致，channel.queueDeclare().getQueue()创建临时queue，channel.queueBind(queueName, EXCHANGE_NAME, “”)将exchange绑定到指定的queue上，第三个参数为routingKey，由于此处为fanout，所以为空。 directdirect类型的Exchange路由规则也比较简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中。 以上图为例，假设我们在生产者配置的routingKey为error，那么两个消费者都可以收到消息，如果是info，那么c2可以接收到消息，c2便接收不到消息了。 生产者代码： 1234567891011121314151617181920212223242526272829303132333435/** * 生产者 * Exchange Types为direct * * direct类型的Exchange路由规则也很简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中。 * @author mingshan * */public class Producer &#123; private final static String EXCHANGE_NAME = "logs-direct"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); // 声明exchange，Exchange Types为direct channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); System.out.println("Please enter message ---&gt;"); String message = ""; String routeKey = "error"; Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) &#123; message = scanner.nextLine(); System.out.println(" ----- " + message); channel.basicPublish(EXCHANGE_NAME, routeKey, null, message.getBytes("UTF-8")); &#125; channel.close(); connection.close(); scanner.close(); &#125;&#125; 此时生产者Exchange Tyoes设置为direct，并且routingKey设置的为error 消费者代码： 123456789101112131415161718192021222324252627282930313233/** * 消费者 * @author mingshan * */public class ConsumerA &#123; private final static String EXCHANGE_NAME = "logs-direct"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String queueName = channel.queueDeclare().getQueue(); // 此时routeKey 为 info String routeKey = "info"; channel.queueBind(queueName, EXCHANGE_NAME, routeKey); System.out.println("A Waiting for messages. To exit press CTRL+C"); Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println("A Recv '" + message + "'"); &#125; &#125;; channel.basicConsume(queueName, true, consumer); &#125;&#125; 在消费者中，我们设置的routeKey为info，此时消费者A接受不到消息了，如果routingKey为error，那么就可以接收到消息。 topic由于direct的匹配规则需要完全配置，没有灵活性，所以topic就弥补了这一缺点， routingKey 必须是由点分隔的单词列表。这些单词可以是任何东西，但通常它们指定连接到消息的一些功能。一些有效的路由键例子：“ stock.usd.nyse ”，“ nyse.vmw ”，“ quick.orange.rabbit ”。在路由选择键中可以有任意数量的字，最多255个字节。 绑定键也必须是相同的形式。binding key中可以存在两种特殊字符“*”与“#”，用于做模糊匹配： “*” 可以代替一个字。 “#” 可以代替零个或多个单词。 生产者代码： 123456789101112131415161718192021222324252627282930313233343536373839/** * 生产者 * Exchange Types为topic * &lt;ul&gt; * &lt;li&gt;routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词）， * 如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit”&lt;/li&gt; * &lt;li&gt;binding key与routing key一样也是句点号“. ”分隔的字符串&lt;/li&gt; * &lt;li&gt;binding key中可以存在两种特殊字符“*”与“#”，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词（可以是零个）&lt;/li&gt; * &lt;/ul&gt; * @author mingshan * */public class Producer &#123; private final static String EXCHANGE_NAME = "logs-topic"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); // 声明exchange，Exchange Types为headers channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); System.out.println("Please enter message ---&gt;"); String message = ""; String routeKey = "quick.orange.rabbit"; Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) &#123; message = scanner.nextLine(); System.out.println(" ----- " + message); channel.basicPublish(EXCHANGE_NAME, routeKey, null, message.getBytes("UTF-8")); &#125; channel.close(); connection.close(); scanner.close(); &#125;&#125; 消费者代码： 123456789101112131415161718192021222324252627282930313233/** * 消费者 * @author mingshan * */public class ConsumerA &#123; private final static String EXCHANGE_NAME = "logs-topic"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); String queueName = channel.queueDeclare().getQueue(); // 此时routeKey 为 *.orange.* String routeKey = "*.orange.*"; channel.queueBind(queueName, EXCHANGE_NAME, routeKey); System.out.println("A Waiting for messages. To exit press CTRL+C"); Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println("A Recv '" + message + "'"); &#125; &#125;; channel.basicConsume(queueName, true, consumer); &#125;&#125; headersheaders类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），消费者会根据设置x-match设置的配置类型(all,any)来进行匹配。 生产者代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 生产者 * Exchange Types为headers * * Headers是一个键值对，可以定义成HashMap。发送者在发送的时候定义一些键值对，接收者也可以再绑定时候传入一些键值对， * 两者匹配的话，则对应的队列就可以收到消息。匹配有两种方式all和any。这两种方式是在接收端必须要用键值"x-mactch"来定义 * 。all代表定义的多个键值对都要满足，而any则代码只要满足一个就可以了。fanout，direct，topic exchange的routingKey都需要要字符串形式的， * 而headers exchange则没有这个要求，因为键值对的值可以是任何类型。 * @author mingshan * */public class Producer &#123; private final static String EXCHANGE_NAME = "logs-headers"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); // 声明exchange，Exchange Types为headers channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.HEADERS); Map&lt;String,Object&gt; headers = new HashMap&lt;String, Object&gt;(); headers.put("xiaoming", "123456"); AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder(); builder.deliveryMode(MessageProperties.PERSISTENT_TEXT_PLAIN.getDeliveryMode()); builder.priority(MessageProperties.PERSISTENT_TEXT_PLAIN.getPriority()); builder.headers(headers); AMQP.BasicProperties theProps = builder.build(); System.out.println("Please enter message ---&gt;"); Scanner scanner = new Scanner(System.in); String message = ""; while (scanner.hasNext()) &#123; message = scanner.nextLine(); channel.basicPublish(EXCHANGE_NAME, "", theProps, message.getBytes("UTF-8")); &#125; channel.close(); connection.close(); scanner.close(); &#125;&#125; 消费者代码： 12345678910111213141516171819202122232425262728293031323334353637/** * 消费者 * @author mingshan * */public class ConsumerA &#123; private final static String EXCHANGE_NAME = "logs-headers"; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.HEADERS); String queueName = channel.queueDeclare().getQueue(); Map&lt;String, Object&gt; headers = new HashMap&lt;String, Object&gt;(); headers.put("x-match", "any");//all any headers.put("xiaoming", "123456"); headers.put("bbb", "56789"); channel.queueBind(queueName, EXCHANGE_NAME, "", headers); System.out.println("A Waiting for messages. To exit press CTRL+C"); Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println("A Recv '" + message + "'"); &#125; &#125;; channel.basicConsume(queueName, true, consumer); &#125;&#125; 源码链接你可以在这个地方看到本篇博客代码： https://github.com/mstao/rabbitmq-learning 参考 http://www.rabbitmq.com/getstarted.html http://www.rabbitmq.com/tutorials/amqp-concepts.html http://blog.csdn.net/whycold/article/details/41119807]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RabbitMQ</tag>
        <tag>Exchange Types</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock源码笔记 - 释放锁（JDK 1.8）]]></title>
    <url>%2F2017%2F11%2F12%2FReentrantLock%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%20-%20%E9%87%8A%E6%94%BE%E9%94%81%2F</url>
    <content type="text"><![CDATA[ReentrantLock源码学习 - 释放锁（unlock） 上次谈到了利用ReentrantLock的非公平和公平加锁方式，那么接下来看看释放锁的流程 首先调用ReentrantLock的unlock方法 123public void unlock() &#123; sync.release(1);&#125; 然后会调用AbstractQueuedSynchronizer（AQS）的release方法，在这个方法中首先会调用ReentrantLock的Sync的tryRelease方法，来进行尝试释放锁，如果返回true，那么获取CLH队列的头结点，判断头结点不为空并且头结点的状态不为0（None），那么就调用AQS的unparkSuccessor方法。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 在tryRelease方法里，首先让当前的state与传入的值（这里为1）进行相减，然后得到c，判断当前线程是不是获取独占锁的线程，如果不是，直接抛出异常；如果是，那么需要判断c是否为0，因为只有c为0时，才符合释放独占锁的条件，这是设置独占锁线程为null，最后设置下state的值（注意这里c为0不为0都会设置） 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 接下来来看方法unparkSuccessor，该方法的作用就是为了释放node节点的后继结点。 123456789101112131415161718192021222324252627282930private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ // 获取节点的状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 利用CAS 将状态设置为0 /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 获取节点的后继节点 Node s = node.next; // 判断后继节点是否为空 或者 后者后继节点的状态为CANCELLED if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 将后继节点置为null // 从尾节点从后向前开始遍历知道节点为空或者当前节点为止 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) // 如果此时节点的状态小于等于0 s = t; // 将此节点赋给传入节点的后继节点 &#125; if (s != null) // 节点不为空，释放 LockSupport.unpark(s.thread);&#125; 参考：http://blog.csdn.net/luonanqin/article/details/41871909]]></content>
      <categories>
        <category>Java</category>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Lock</tag>
        <tag>JUC</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Spring Data Redis中使用AOP进行数据缓存]]></title>
    <url>%2F2017%2F11%2F11%2F%E5%9C%A8%20Spring%20Data%20Redis%E4%B8%AD%E4%BD%BF%E7%94%A8AOP%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[为什么要对数据进行缓存当我们将数据从数据库中取出来后，如果我们需要再一次进行同样的操作，获取相同的数据，那么再次查询数据库无疑不是很好的方式，这时我们可以考虑来将我们的数据缓存起来，当再次获取相同的数据时，直接从缓存拿就行了。 进行缓存需要考虑什么问题 缓存数据存在什么地方？ 怎样识别相同的操作(判断两次取的数据相同，生成唯一标识) 数据更新时缓存该如何处理？ 缓存数据是否设置过期时间？ 如何序列化查询结果？查询结果可能是单个实体对象，也可能是一个List。 代码该写在哪？不能对原有代码有侵入性 针对以上问题，我们下面来慢慢分析解决。 采用Redis缓存数据Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 我们在 Spring 中使用 Redis 是通过 Spring Data Redis 提供的 RedisTemplate 来操作Redis 添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.4.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; spring集合Redis的配置如下： 123456789101112131415161718192021222324252627&lt;!-- redis 相关配置 --&gt;&lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;" /&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;" /&gt; &lt;property name="testOnBorrow" value="true" /&gt;&lt;/bean&gt;&lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" p:host-name="$&#123;redis.host&#125;" p:port="$&#123;redis.port&#125;" p:pool-config-ref="poolConfig"/&gt;&lt;!-- redis template definition --&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;!-- 设置 Redis 连接工厂--&gt; &lt;property name="connectionFactory" ref="jedisConnectionFactory"/&gt; &lt;!-- 设置默认 Serializer ，包含 keySerializer &amp; valueSerializer --&gt; &lt;property name="defaultSerializer"&gt; &lt;bean class="com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer"/&gt; &lt;/property&gt; &lt;!-- 单独设置 keySerializer --&gt; &lt;property name="keySerializer"&gt; &lt;bean class="com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer"/&gt; &lt;/property&gt; &lt;!-- 单独设置 valueSerializer --&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer"/&gt; &lt;/property&gt;&lt;/bean&gt; 为查询生成唯一标识由于Redis是以key-value形式存储数据，所以我们要考虑该如何对查询生成唯一的标识呢？首先我们可以想到可以根据sql语句来作为key，但ORM框架我用的是MyBatis，这就不是一个好的方式。其实如果两次查询调用的类名、方法名和参数值相同，我们就可以确定这两次查询结果一定是相同的（在数据没有变动的前提下）。因此，我们可以将这三个元素组合成一个字符串做为key, 就解决了标识问题。代码如下： 123456789101112131415161718192021/** * 生成缓存需要的key * @param clazzName * @return 生成的key */private String generateKey(String clazzName, String methodName, Object[] args) &#123; StringBuffer sb = new StringBuffer(clazzName); sb.append(Constants.ELIMITER); sb.append(methodName); sb.append(Constants.ELIMITER); if (args != null) &#123; for (Object arg : args) &#123; sb.append(arg); sb.append(Constants.ELIMITER); &#125; &#125; // 去除最后一个分隔符 sb.replace(sb.length() - 1, sb.length(), Constants.ELIMITER); return sb.toString();&#125; 代码该写在什么地方由于考虑到不能对原有代码有侵入性，所以我们就要用到AOP了。我们可以把从数据库查询出来的数据映射到实体类，然后将其序列化为json，从缓存中取出来后再进行反序列化，代码如下： 12345678910111213141516171819202122232425/** * 序列化数据 * @param source * @return json字符串 */private String serialize(Object source) &#123; return JSON.toJSONString(source);&#125;/** * 反序列化 * @param source * @param clazz * @param modelType * @return 反序列化的数据 */private Object deserialize(String source, Class&lt;?&gt; clazz, Class&lt;?&gt; modelType) &#123; // 判断是否为List if (List.class.isAssignableFrom(clazz)) &#123; return JSON.parseArray(source, modelType); &#125; // 正常反序列化 return JSON.parseObject(source, clazz);&#125; 具体实现因为我们要拦截的是Mapper接口方法，因此必须命令spring使用JDK的动态代理而不是cglib的代理。为此，我们需要做以下配置：1234&lt;!-- 当proxy-target-class为false时使用JDK动态代理 --&gt;&lt;!-- 为true时使用cglib --&gt;&lt;!-- cglib无法拦截接口方法 --&gt;&lt;aop:aspectj-autoproxy proxy-target-class=&quot;false&quot; /&gt; 然后我们定义两个方法级别的自定义注解，其中RedisCache代表该方法需要进行缓存数据，RedisEvict代表需要清除缓存12345678@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Documentedpublic @interface RedisCache &#123; @SuppressWarnings("rawtypes") Class type(); int expire() default -1; //缓存多少秒,默认无限期 &#125; 123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface RedisEvict &#123; @SuppressWarnings("rawtypes") Class type();&#125; 注解使用方式 1234567891011121314@Override@RedisCache(type = User.class)public User selectByPrimaryKey(Integer id) &#123; return userDao.selectByPrimaryKey(id);&#125;@Override@RedisEvict(type = User.class)public User deleteByPrimaryKey(Integer id) &#123; userDao.deleteByPrimaryKey(id); User user = new User(); user.setId(id); return user;&#125; 首先对于要进行数据缓存操作，我们先要生成唯一标识key值，然后去Redis查询，判断缓存是否命中 如果缓存命中，那么将数据反序列化，将其返回 如果缓存未命中，那么去数据库查询数据，然后将数据进行序列化，这是需要判断是否设置了超时时间，如果没有设置，那么默认无限期，如果设置了，那么对数据设置时间。 具体AOP代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274@Aspect@Componentpublic class RedisCacheAspect &#123; public static final Logger logger = LoggerFactory.getLogger(RedisCacheAspect.class); @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; /** * 从Redis获取缓存的数据或者将数据缓存到Redis * @param pjp * @return 获取到的数据 * @throws Throwable */ @Around("execution(* com.han.service..*Impl.select*(..))" + "|| execution(* com.han.service..*Impl.get*(..))" + "|| execution(* com.han.service..*Impl.find*(..))" + "|| execution(* com.han.service..*Impl.search*(..))") @SuppressWarnings(&#123; "unchecked", "rawtypes" &#125;) public Object cache(ProceedingJoinPoint pjp) throws Throwable &#123; // 生成key String key = getKey(pjp); if (logger.isDebugEnabled())&#123; logger.debug("已生成key = &#123;&#125;" + key); &#125; // 得到目标方法 Method targetMethod = getTargetMethod(pjp); // 得到被代理的方法上的注解 Class&lt;?&gt; modelType = targetMethod.getAnnotation(RedisCache.class).type(); String hashName = modelType.getName(); // 利用Redis的Hash数据类型（散列） HashOperations opsForHash = redisTemplate.opsForHash(); // 检查redis中是否有缓存 String value = (String) opsForHash.get(hashName, key); // 最终返回结果 Object result = null; // 判断缓存是否命中 if (value != null) &#123; // 缓存命中 if (logger.isDebugEnabled()) &#123; logger.debug("缓存命中, value = &#123;&#125;", value); &#125; // 得到被代理方法的返回值类型 Class&lt;?&gt; returnType = ((MethodSignature) pjp.getSignature()).getReturnType(); // 反序列化从缓存中拿到的json result = deserialize(value, returnType, modelType); if (logger.isDebugEnabled()) &#123; logger.debug("反序列化结果 = &#123;&#125;", result); &#125; &#125; else &#123; // 缓存未命中 if (logger.isDebugEnabled()) &#123; logger.debug("缓存未命中"); &#125; // 跳过缓存,到后端查询数据 result = pjp.proceed(pjp.getArgs()); // 序列化查询结果 String jsonStr = serialize(result); // 获取设置的缓存时间 int timeout = targetMethod.getAnnotation(RedisCache.class).expire(); // 如果没有设置过期时间,则无限期缓存(默认-1) if (timeout &lt;= 0) &#123; opsForHash.put(hashName, key, jsonStr); &#125; else &#123; final TimeUnit unit = TimeUnit.SECONDS; final long rawTimeout = TimeoutUtils.toMillis(timeout, unit); // 设置缓存时间 redisTemplate.execute(new RedisCallback&lt;Object&gt;() &#123; @Override public Object doInRedis(RedisConnection redisConn) throws DataAccessException &#123; // 配置文件中指定了这是一个String类型的连接 // 所以这里向下强制转换一定是安全的 StringRedisConnection conn = (StringRedisConnection) redisConn; // 判断hash名是否存在 // 如果不存在，创建该hash并设置过期时间 if (!conn.exists(hashName)) &#123; conn.hSet(hashName, key, jsonStr); conn.expire(hashName, rawTimeout); &#125; else &#123; conn.hSet(hashName, key, jsonStr); &#125; return null; &#125; &#125;); &#125; &#125; return result; &#125; /** * 在方法调用前清除缓存，然后调用业务方法 * @param jp * @return 获取到的数据 * @throws Throwable */ @Around("execution(* com.han.service..*Impl.delete*(..))" + "|| execution(* com.han.service..*Impl.remove*(..))") @SuppressWarnings("rawtypes") public Object evictCache(ProceedingJoinPoint pjp) throws Throwable &#123; // 得到目标的方法 Method targetMethod = getTargetMethod(pjp); // 得到被代理的方法上的注解 Class modelType = targetMethod.getAnnotation(RedisEvict.class).type(); if (logger.isDebugEnabled()) &#123; logger.debug("清空缓存:&#123;&#125;", modelType.getName()); &#125; // 清除对应缓存 redisTemplate.delete(modelType.getName()); return pjp.proceed(pjp.getArgs()); &#125; /** * 更新缓存的数据 * @return 新获取的数据 */ @Around("execution(* com.han.service..*Impl.update*(..))" + "|| execution(* com.han.service..*Impl.insert*(..))" + "|| execution(* com.han.service..*Impl.save*(..))") @SuppressWarnings(&#123; "unchecked", "rawtypes" &#125;) public Object updateCache(ProceedingJoinPoint pjp) throws Throwable &#123; // 生成key String key = getKey(pjp); if (logger.isDebugEnabled())&#123; logger.debug("已生成key = &#123;&#125;" + key); &#125; // 得到目标方法 Method targetMethod = getTargetMethod(pjp); // 得到被代理的方法上的注解 Class&lt;?&gt; modelType = targetMethod.getAnnotation(RedisCache.class).type(); String hashName = modelType.getName(); // 利用Redis的Hash数据类型（散列） HashOperations opsForHash = redisTemplate.opsForHash(); // 跳过缓存,到后端查询数据 Object result = pjp.proceed(pjp.getArgs()); // 序列化查询结果 String jsonStr = serialize(result); if (logger.isDebugEnabled()) &#123; logger.debug("序列化结果 = &#123;&#125;", result); &#125; // 获取设置的缓存时间 int timeout = targetMethod.getAnnotation(RedisCache.class).expire(); // 如果没有设置过期时间,则无限期缓存(默认-1) if (timeout &lt;= 0) &#123; opsForHash.put(hashName, key, jsonStr); &#125; else &#123; final TimeUnit unit = TimeUnit.SECONDS; final long rawTimeout = TimeoutUtils.toMillis(timeout, unit); // 设置缓存时间 redisTemplate.execute(new RedisCallback&lt;Object&gt;() &#123; @Override public Object doInRedis(RedisConnection redisConn) throws DataAccessException &#123; // 配置文件中指定了这是一个String类型的连接 // 所以这里向下强制转换一定是安全的 StringRedisConnection conn = (StringRedisConnection) redisConn; // 判断hash名是否存在 // 如果不存在，创建该hash并设置过期时间 if (!conn.exists(hashName)) &#123; conn.hSet(hashName, key, jsonStr); conn.expire(hashName, rawTimeout); &#125; else &#123; conn.hSet(hashName, key, jsonStr); &#125; return null; &#125; &#125;); &#125; return result; &#125; /** * 得到目标方法 * @param pjp * @return 目标方法 * @throws SecurityException * @throws NoSuchMethodException */ private Method getTargetMethod(ProceedingJoinPoint pjp) throws NoSuchMethodException, SecurityException &#123; Signature sig = pjp.getSignature(); if (!(sig instanceof MethodSignature)) &#123; throw new IllegalArgumentException("该注解只能用于方法"); &#125; MethodSignature msig = (MethodSignature) sig; Object target = pjp.getTarget(); Method targetMethod = target.getClass().getMethod(msig.getName(), msig.getParameterTypes()); return targetMethod; &#125; /** * 通过类名，方法名和参数来获取对应的key * @param pjp * @return 生成的key */ private String getKey(ProceedingJoinPoint pjp) &#123; // 获取类名 String clazzName = pjp.getTarget().getClass().getName(); // 获取方法名 String methodName = pjp.getSignature().getName(); // 方法参数 Object[] args = pjp.getArgs(); // 生成key return generateKey(clazzName, methodName, args); &#125; /** * 生成缓存需要的key * @param clazzName * @return 生成的key */ private String generateKey(String clazzName, String methodName, Object[] args) &#123; StringBuffer sb = new StringBuffer(clazzName); sb.append(Constants.ELIMITER); sb.append(methodName); sb.append(Constants.ELIMITER); if (args != null) &#123; for (Object arg : args) &#123; sb.append(arg); sb.append(Constants.ELIMITER); &#125; &#125; // 去除最后一个分隔符 sb.replace(sb.length() - 1, sb.length(), Constants.ELIMITER); return sb.toString(); &#125; /** * 序列化数据 * @param source * @return json字符串 */ private String serialize(Object source) &#123; return JSON.toJSONString(source); &#125; /** * 反序列化 * @param source * @param clazz * @param modelType * @return 反序列化的数据 */ private Object deserialize(String source, Class&lt;?&gt; clazz, Class&lt;?&gt; modelType) &#123; // 判断是否为List if (clazz.isAssignableFrom(List.class)) &#123; return JSON.parseArray(source, modelType); &#125; // 正常反序列化 return JSON.parseObject(source, clazz); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Spring Data</tag>
        <tag>AOP</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock源码笔记 - 获取锁（JDK 1.8）]]></title>
    <url>%2F2017%2F11%2F10%2FReentrantLock%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%20-%20%E8%8E%B7%E5%8F%96%E9%94%81%2F</url>
    <content type="text"><![CDATA[ReentrantLock 学习 - 获取锁（JDK 1.8） ReentrantLock 提供非公平锁与公平锁两种加锁方式, 默认加锁方式为非公平锁。 ReentrantLock类的结构为： 从图中可以看出，ReentrantLock类包含三个静态内部类： Sync NonfairSync FairSync 其中Sync类继承AbstractQueuedSynchronize（AQS), NonfairSync和FairSync继承Sync。 ReentrantLock的基本用法：12345678910111213class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // block until condition holds try &#123; // ... method body &#125; finally &#123; lock.unlock() &#125; &#125; &#125; ReentrantLock的创建 非公平锁 1Lock lock = new ReentrantLock(); 公平锁 1Lock lock = new ReentrantLock(true); 由于默认创建的为非公平锁，所以想创建公平锁，就需要向其构造方法传入true。 创建非公平锁的构造方法为： 1234567/** * Creates an instance of &#123;@code ReentrantLock&#125;. * This is equivalent to using &#123;@code ReentrantLock(false)&#125;. */public ReentrantLock() &#123; sync = new NonfairSync();&#125; 创建公平锁的构造方法为： 12345678910/** * 根据传入的布尔值来判断创建哪种锁 * Creates an instance of &#123;@code ReentrantLock&#125; with the * given fairness policy. * * @param fair &#123;@code true&#125; if this lock should use a fair ordering policy */public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 非公平锁非公平锁的用法1lock.lock(); 在ReetrantLock类的内部提供了一个加锁的方法： 123public void lock() &#123; sync.lock();&#125; 在这个方法里又调用了==sync==的==lock==方法，又因为Sync这个类为一个抽象类，在ReentrantLock类实例化的时候，根据参数来判断调用哪个具体的类。 这里先谈谈非公平锁的加锁实现。 非公平锁实现简单步骤： 基予CAS(Compare And Swap)将state由0设置为1。 如果设置成功，那么直接获得锁，并设置独占锁的线程为当前线程。 如果设置失败，原先内存state的值不是0，已经有其他线程获得锁，那么就会再获取一次state。 如果state为0， 那么就会再次利用CAS将state的值由0设置为1，如果成功，设置独占锁的线程为当前线。 如果state不为0，那么需要判断当前线程是否是独占锁的线程，如果是，那么就将state加1， 并且判断当前state的值不能小于0；如果不是，那么就将该线程封装在一个Node(AQS里面)里,并加入到等待列队里，等其他线程唤醒。 具体流程如下：首先通过ReentrantLock的lock方法调用到其内部类NonFairLock的lock方法 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 在lock方法中，先调用compareAndSetState方法来将state由0设置为1，如果设置成功，设置当前线程为独占锁线程，如果失败，则调用AbstractQueuedSynchronizer类的acquire(1)方法。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 向aquire方法传入参数1，此方法是线程获取临界资源的顶层入口， 如果获得到资源则直接返回，如果失败，则将当前先后才能放入到等待列队，直到获取到资源才返回。此过程忽略中断影响，模式为独占模式。 因为这个方法涉及到线程的入队操作，下面来看看AbstractQueuedSynchronizer类内部封装的Node. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 同步等待队列（双向链表）节点 */static final class Node &#123; static final Node SHARED = new Node(); // 一个标记：用于表明该节点在独占模式下进行等待 static final Node EXCLUSIVE = null; // 线程被取消了 static final int CANCELLED = 1; // 节点等待触发 static final int SIGNAL = -1; // 节点等待条件 static final int CONDITION = -2; // 节点状态需要向后传播 static final int PROPAGATE = -3; volatile int waitStatus; // 前驱节点 volatile Node prev; // 后继节点 volatile Node next; // 线程 volatile Thread thread; Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; tryAcquire方法会调用ReentrantLock中NonfairSync内部类中的tryAcquire方法 123protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; 然后调用nonfairTryAcquire方法进行再一次尝试获取锁 123456789101112131415161718192021222324final boolean nonfairTryAcquire(int acquires) &#123; // 当前线程 final Thread current = Thread.currentThread(); // 再一次获取state int c = getState(); // 如果state为0，说明其他线程已经释放了锁，可以尝试获取锁 if (c == 0) &#123; // 利用CAS来设置当前state的值 if (compareAndSetState(0, acquires)) &#123; // 如果成功则设置当前线程为独占锁线程，然后直接返回 setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果当前state不是0，则判断当前线程是否为独占锁线程 else if (current == getExclusiveOwnerThread()) &#123; // 将state进行+1操作，判断state值后返回 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; // 获取锁失败，考虑将线程加入等待队列&#125; 在nonfairTryAcquire方法为再一次尝试获取锁，这个过程可能获取锁的线程已经释放了锁，所以再一次判断state的值，如果state的值为0，那么利用CAS将state由0设值为1，如果成功，获取锁成功，设值当前线程为独占锁线程，直接返回；如果state不为0，则判断当前线程是否为独占锁线程（可重入锁来源，state每加一次1，那么就需要释放锁的次数也要+1，这样才能保证state最终在线程释放锁的情况下值为0），如果是，将state加1，然后返回；其他情况返回false，获取锁失败。 如果当前线程获取锁失败，就需要将该线程加入等待队列的末尾。该等待列队是CLH队列，队列的示意图如下： 123 +------+ prev +-----+ +-----+head | | &lt;---- | | &lt;---- | | tail +------+ +-----+ +-----+ 接下来就会调用AQS的addWaiter(Node.EXCLUSIVE)方法 123456789101112131415161718192021222324private Node addWaiter(Node mode) &#123; // 根据当前线程创建一个Node节点，并设置为独占模式 Node node = new Node(Thread.currentThread(), mode); // 试图进行快速入队操作，仅尝试一次 // 将队列的尾节点tail赋给pred Node pred = tail; // 判断尾节点是否为空 if (pred != null) &#123; // 将尾节点作为创造出来的节点的前驱节点，即将创造出来的节点 // 链接到为尾节点后 node.prev = pred; // 利用CAS将尾节点tail由pred设置为node // 此时队列 node1 &lt;-&gt; node // 再加上 node1 &lt;-&gt; prev // 所以此时队列应为 node1 &lt;-&gt; prev &lt;-&gt; node if (compareAndSetTail(pred, node)) &#123; // 如果成功，则将pred的后继节点为node pred.next = node; return node; &#125; &#125; enq(node); // 正常入队 return node;&#125; 具体的实现流程已在代码中注释，如果不是快速入队，那么就进行正常入队，即调用AQS的enq(node)方法 12345678910111213141516171819202122private Node enq(final Node node) &#123; // 等待，直到插入到队列位置 for (;;) &#123; // 将尾节点tail赋给t Node t = tail; // 判断尾节点是否为空，如果尾节点为空，说明队列为空 if (t == null) &#123; // Must initialize // 生成一个新节点，将head由null设置为新节点的值 // 如果设置失败，说明在这个过程中已经有其他线程设置过head了 // 当成功的将这个dummy节点设置到head节点上去时，我们又将这个head节点// 设置给了tail节点，即head与tail都是当前这个dummy节点， // 之后有新节点入队的话，就插入到该dummy之后 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //如果尾节点不为空，则按照快速入队操作进行操作 node.prev = t; if (compareAndSetTail(t, node)) &#123; // 尝试将尾节点设置为node t.next = node; // 将node节点设置为尾节点,即将尾节点的后继节点设置为node节点 return t; // 返回原先的尾节点 &#125; &#125; &#125;&#125; 入队成功之后需要调用AQS的acquireQueued(addWaiter(Node.EXCLUSIVE), arg))方法 123456789101112131415161718192021222324252627282930/** * 队列中的结点在独占且忽略中断的模式下获取锁 * 如果获取成功则返回false * 如果获取失败 */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; // 失败标志 try &#123; boolean interrupted = false; //中断标志 for (;;) &#123; // 无限等待 final Node p = node.predecessor(); // 获取插入节点的前一个节点p // 仅当当前的节点的前驱节点并且 // 尝试获取锁成功，跳出循环 // 当第一次循环就获取成功了，interrupted为false，不需要中断 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); // 设置头结点 p.next = null; // help GC failed = false; return interrupted; &#125; // 当获取(锁)失败后，检查并且更新结点状态, 挂起当前节点并检查中断 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 如果acquireQueued方法没有跳出循环（获取锁失败），那么就要判断当前节点是否可以安全的挂起（park），下面就会调用AQS的shouldParkAfterFailedAcquire(Node pred, Node node) 方法1234567891011121314151617181920212223242526272829303132333435363738394041/** * 当获取(资源)失败后，检查并且更新结点状态 */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 获取前驱节点的状态 // 当且仅当状态为SIGNAL时，表示当前节点在以后可以被唤醒，那么就可以进行挂起// （park）操作了 // 此时 ws的值为-1 if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // ws大于零说明前驱节点的状态为CANCEL, 即为1 // 即前驱节点的线程被取消了，需要将其从队列中除去，最终返回false // 不能被安全的挂起 if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; // 这句话node.prev = pred = pred.prev; // 相当于 // pred = pred.prev; // node.prev = pred; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); // 找到pred结点前面最近的一个状态不为CANCELLED的结点 pred.next = node; // 将该节点的后继节点设置为当前节点 &#125; else &#123; // waitStatus 为PROPAGATE -3 或者是0 表示无状态,(为CONDITION -2时，表示此节点在condition queue中) /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 利用CAS来将当前节点的前驱节点的状态设置为SIGNAL // 如果设置成功的话，下次再来访问 状态就为SIGNAL了 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; // 如果ws不为SIGNAL, 其他情况全部返回false&#125; 在该方法中需要判断当前节点的前驱节点的状态，如果状态为SIGNAL时，表示当前节点在以后可以被唤醒，那么就可以进行挂起了如果不是 那么就需要判断该前驱节点（线程）是否被取消了，如果被取消，那么这个前驱节点应该从队列中除去，再经过while循环找到pred结点前面最近的一个状态不为CANCELLED的结点，并将当前节点的前驱节点设置为该节点； 如果该前驱节点的waitStatus不为CANCELLED,那么利用CAS将当前节点的前驱节点的状态设置为SIGNAL 接下来就会执行AQS 中的parkAndCheckInterrupt()方法 1234567/** * 进行挂起（park）操作并且返回该线程是否被中断 */private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); //挂起当前线程 return Thread.interrupted(); // 如果当前线程已经被中断了，返回true&#125; parkAndCheckInterrupt方法首先执行挂起（park）操作，然后返回该线程是否已经被中断。 此时回到acquireQueued(final Node node, int arg)方法，看finally语句块中的cancelAcquire(node)方法，该方法在挂起失败后执行 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 取消继续获取锁 */private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist // node为空，返回 if (node == null) return; // node节点内的线程置为空 node.thread = null; // Skip cancelled predecessors // 该节点的前驱节点 Node pred = node.prev; // 找到pred结点前面最近的一个状态不为CANCELLED的结点 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // node结点为尾结点，则利用CAS设置尾结点为pred结点 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123;// node结点不为尾结点，或者CAS设置不成功 // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; // （pred结点不为头结点，并且pred结点的状态为SIGNAL）或者 // ws小于0，并且比较并设置等待状态为SIGNAL成功，并且pred结点内的线程不为空 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; // 获取节点的后继节点 // 如果后继节点不为空 并且后继节点的等待状态小于等于0 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); // 比较并设置pred.next = next; &#125; else &#123; unparkSuccessor(node); // 释放节点的后继节点 &#125; node.next = node; // help GC &#125;&#125; 在该方法中取消继续获取锁。 在该方法中会调用一个方法unparkSuccessor，该方法的作用就是为了释放node节点的后继结点。 123456789101112131415161718192021222324252627282930private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ // 获取节点的状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 利用CAS 将状态设置为0 /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 获取节点的后继节点 Node s = node.next; // 判断后继节点是否为空 或者 后者后继节点的状态为CANCELLED if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 将后继节点置为null // 从尾节点从后向前开始遍历知道节点为空或者当前节点为止 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) // 如果此时节点的状态小于等于0 s = t; // 将此节点赋给传入节点的后继节点 &#125; if (s != null) // 节点不为空，释放 LockSupport.unpark(s.thread);&#125; 至此，ReentrantLock获取非公平锁的步骤就结束了。 公平锁如果需要使用公平锁，那么在创建ReentrantLock实例的时候需要向其构造函数传入布尔值true，然后在构造方法里利用三元运算创建公平锁的实例 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 公平锁的用法1lock.lock(); 公平锁加锁的简单步骤：获取一次state的值 如果state为0，查看CLH队列中是否还有其他线程在等待获取锁，如果有，则获取锁失败；如果没有，则利用CAS将state的值由0设置为1，如果成功，设置独占锁的线程为当前线。 如果state不为0或者CLH队列中还有其他线程在等待获取锁，查看当前线程是不是已经是独占锁的线程了，如果是，则将当前的锁数量+1；如果不是，则将该线程封装在一个Node内，并加入到等待队列中去。等待被其前一个线程节点唤醒。 此过程严格遵守“先到先得”策略。 公平锁与非公平锁的重要区别是：非公平锁在要获取锁的时候，首先会尝试直接获取锁，而公平锁则需要判断CLH队列中是否还有其他线程在等待获取锁。 公平锁具体获取流程：首先调用FairSync静态内部类的lock方法，在这个方法中直接调用AQS的acquire方法123final void lock() &#123; acquire(1);&#125; AQS的acquire方法如下： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 然后会调用FairSync的tryAcquire方法 123456789101112131415161718192021222324252627282930/** * 和非公平锁的区别：即使当前锁是空闲的，也要查看CLH队列中是否还有其他线程在等 * 待获取锁，如果有则获取失败，严格遵守“先到先得”的策略 */protected final boolean tryAcquire(int acquires) &#123; // 当前线程 final Thread current = Thread.currentThread(); // 获取state int c = getState(); // 判断state的值是否为0 if (c == 0) &#123; // 这一步是判断CLH队列中是否还有其他等待获取锁的线程，如果有返回true，没有则返回false // 同时还需要利用CAS将state由0设置为1 // 如果上述两步都返回true，那么设置独占锁线程为当前线程 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果当前state不是0，则判断当前线程是否为独占锁线程 else if (current == getExclusiveOwnerThread()) &#123; // 将state进行+1操作，判断state值后返回 int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; // 获取锁失败，考虑将线程加入等待队列&#125; 在这个方法中，首先获取state的值，判断当前是否可以获取锁 如果state为0，说明锁没有被其他线程获取，但由于是公平锁，那么需要判断CLH队列中是否还有其他线程在等待获取锁，如果有，那么就获取锁失败了；如果没有，则需要利用CAS将state由0设置为1，这两步都返回true，那么设置独占锁线程为当前线程 如果当前state不是0，则判断当前线程是否为独占锁线程，如果是，将state加1，然后返回 其他情况返回false，获取锁失败。 判断CLH队列中是否还有其他等待获取锁的线程需要调用CAS的hasQueuedPredecessors方法123456789101112131415/** * 判断CLH队列中是否还有其他等待获取锁的线程 * 如果当前线程之前有一个排队的线程，返回true * 如果当前线程在队列的头部或队列为空，返回false */public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 接下来的流程和非公平一样。 总结：非公平锁与公平锁获取锁对比： NonfairSync： 非公平锁在要获取锁的时候，首先会尝试直接获取锁 FairSync 而公平锁则需要判断CLH队列中是否还有其他线程在等待获取锁 ReentrantLock是基于AbstractQueuedSynchronizer（AQS）实现的，AQS可以实现独占锁也可以实现共享锁，ReentrantLock只是使用了其中的独占锁模式。 参考：http://www.cnblogs.com/java-zhao/p/5131544.html]]></content>
      <categories>
        <category>Java</category>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Lock</tag>
        <tag>JUC</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之观察者模式]]></title>
    <url>%2F2017%2F10%2F17%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[我们在生活中会遇到这样一些例子，比如你订阅了某人的博客，那么这个人发布博客的时候会将消息推送给你，而且不是只推送你自己一人，只要订阅了该人的博客，那么订阅者都会收到通知，像这样的例子生活中实在是太多了。其实这种操作可以抽象一下，A对象（观察者）对B对象（被观察者）的某种变化高度敏感，需要在B变化的一瞬间做出反应，同时在B对象中维护着所有A的集合。我们在实际编程中称这种模式为观察者模式，有时也称为发布/订阅(Publish/Subscribe)模型。 在JDK的util包中已经帮我们实现了观察者模式，不过我们还是先通过自己写代码来看看观察者到底是怎么回事，自己该如何简单的实现，相信通过自己的简单实现，来理解JDK的观察者模式的实现是十分容易的。 在观察者模式中，首先要有两个角色，观察者与被观察者，这两者拥有的功能是不同的。对于观察者，需要有一个方法来接收被观察者发出的信息(update)，而对于被观察者而言，需要在其内部维护一个观察者的列表，用来记录需要通知的观察者(list)，所以需要一个添加观察者的方法(addWatcher），同时还要有一个方法可以用来移除观察者(removeWatcher), 最后我们需要一个用来通知所有观察者的方法(notifyWatchers), 一切准备就绪，那么我们来看代码吧。 先定义两个接口，观察者(Watcher)和被观察者(Watched),代码如下： 首先是观察者接口，定义了update方法用来接收通知 123456789101112/** * 观察者 * @author mingshan * */public interface Watcher &#123; /** * 用来接收通知 */ void update();&#125; 然后是被观察者接口，定义了三个方法： 123456789101112131415161718192021222324/** * 被观察者 * @author mingshan * */public interface Watched &#123; /** * 添加观察者 * @param watcher */ void addWatcher(Watcher watcher); /** * 移除观察者 * @param watcher */ void removeWatcher(Watcher watcher); /** * 通知观察者 */ void notifyWatchers();&#125; 我们先实现被观察者，重写接口的方法，在其内部维护一个列表，用来存放所有的观察者，当需要通知观察者时，我们就可以调用notifyWatchers方法了，遍历通知所有观察者。 12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.List;public class Thief implements Watched &#123; private List&lt;Watcher&gt; list = new ArrayList&lt;Watcher&gt;(); @Override public void addWatcher(Watcher watcher) &#123; list.add(watcher); &#125; @Override public void removeWatcher(Watcher watcher) &#123; list.remove(watcher); &#125; @Override public void notifyWatchers() &#123; for (Watcher watcher: list) &#123; watcher.update(); &#125; &#125;&#125; 我们再实现观察者，重写update方法 12345678910111213141516171819public class Police implements Watcher &#123; @Override public void update() &#123; System.out.println("小偷正在偷东西，警察行动！"); &#125;&#125;------------------------------public class Inspector implements Watcher &#123; @Override public void update() &#123; System.out.println("小偷正在偷东西，城管行动！"); &#125;&#125; 最后我们写个测试类测试一下 123456789101112131415import org.junit.Test;public class ObserverTest &#123; @Test public void test() &#123; Thief thief = new Thief(); Police police = new Police(); Inspector inspector = new Inspector(); thief.addWatcher(police); thief.addWatcher(inspector); thief.notifyWatchers(); &#125;&#125; 以上是我们自己实现的观察者模式，前面说过了在JDK中已经帮我们实现好了观察者模式，那么我们来用一下： 观察者： 123456789101112131415161718/** * 被观察者 (JDK) * @author mingshan * */public class Thief extends Observable &#123; @Override public String toString() &#123; return "我是小偷-_-"; &#125; public void work() &#123; System.out.println("ss准备下手偷东西了！"); setChanged(); notifyObservers("-小偷说话：哈哈，你猜我是谁-"); &#125;&#125; 观察者： 12345678910111213141516171819202122232425import java.util.Observable;import java.util.Observer;public class Police implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(o + "小偷正在偷东西，警察行动！"+ arg); &#125;&#125;——————————————————————————————————————import java.util.Observable;import java.util.Observer;public class Inspector implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(o + "小偷正在偷东西，城管行动！" + arg); &#125;&#125; 测试类： 1234567891011121314import org.junit.Test;public class ObserverTest &#123; @Test public void test() &#123; Thief thief = new Thief(); Police police = new Police(); Inspector inspector = new Inspector(); thief.addObserver(police); thief.addObserver(inspector); thief.work(); &#125;&#125; 在Observable类源码中，我们可以看到有个changed的布尔值成员变量，用来标志当前对象是否已经被改变，所有在通知观察者之前我们将其置为true 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class Observable &#123; private boolean changed = false; private Vector&lt;Observer&gt; obs; /** Construct an Observable with zero Observers. */ public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; /** * 添加观察者，并且一个观察者只能被添加一次 */ public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; /** * 移除观察者 */ public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; /** * 通知所有的观察者 */ public void notifyObservers() &#123; notifyObservers(null); &#125; /** * 通知所有的观察者(遍历)，同时可以将一些信息传递给观察者，实际上是调用观察** 者的update方法 */ public void notifyObservers(Object arg) &#123; /* * a temporary array buffer, used as a snapshot of the state of * current Observers. */ Object[] arrLocal; synchronized (this) &#123; if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; /** * 删除观察者 */ public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; /** * 将判断当前对象是否改变的flag设置为true */ protected synchronized void setChanged() &#123; changed = true; &#125; /** * 将判断当前对象是否改变的flag设置为false */ protected synchronized void clearChanged() &#123; changed = false; &#125; /** * 判断当前对象是否改变 * */ public synchronized boolean hasChanged() &#123; return changed; &#125; /** * 统计观察者数量 */ public synchronized int countObservers() &#123; return obs.size(); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>观察者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2017%2F10%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[我们在项目中会遇到这样一些情况，比如一个类，我们想让这个类在系统中有且仅有一个对象，不能够重复创建类的实例，因为这种类是无状态的，我们只需要有过一个类的实例就行了。这时我们需要用到设计模式的单例模式。 单例模式分为饿汉式和懒汉式，下面对这两种模式简单介绍: 饿汉式是指当系统启动或者类被加载时就已经创建了类的实例 懒汉式是指当该类第一次被调用的时候才会去创建该类的实例 单例模式有很多实现，不同实现有优有劣，下面谈谈单例的具体的一些实现 单例模式 - 饿汉式如果不实现懒加载的话，那么就用饿汉式实现单例就比较简单，首先让无参构造函数私有化，我们可以直接对该类进行实例化，然后将其赋值给类的成员变量instance，然后提供一个外部可以访问的方法来获取类的实例。下面是代码。 1234567891011121314/** * 单例模式 - 饿汉式 * 线程安全，但未实现懒加载。 * @author mingshan * */public class SingletonDemo1 &#123; private SingletonDemo1() &#123;&#125; private static final SingletonDemo1 instance = new SingletonDemo1(); public static SingletonDemo1 getInstance() &#123; return instance; &#125;&#125; 单例模式 - 懒汉式如果想实现懒加载，那么就要用到懒汉式了。懒汉式是当类第一次被调用的时候才被实例化，但这个时候就会出现线程安全问题，所以我们需要对进行类实例化的部分进行加锁，来保证类的实例只有一个，由于加锁的问题，性能就会降低。虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance()方法。代码如下： 123456789101112131415161718192021/** * 单例模式 - 懒汉模式 * 实现延迟加载 ，所以 getInstance() 方法必须同步 * * 此方法实现单例模式 性能比饿汉式低 * @author mingshan * */public class SingletonDemo2 &#123; private static SingletonDemo2 instance = null; private SingletonDemo2() &#123;&#125; public static synchronized SingletonDemo2 getInstance() &#123; if (instance == null) &#123; instance = new SingletonDemo2(); &#125; return instance; &#125;&#125; 还有一种实现懒加载的方式使用静态内部类来实现单例，由于静态内部类外部不能被访问到，这一种写法简单，比较容易理解，推荐使用。 123456789101112131415161718/** * 单例模式 使用静态内部类 实现延迟加载 * 比较推荐 * @author mingshan * */public class SingletonDemo3 &#123; private SingletonDemo3()&#123;&#125; private static class SingletonHolder &#123; private static final SingletonDemo3 instance = new SingletonDemo3(); &#125; public static SingletonDemo3 getInstance() &#123; return SingletonHolder.instance; &#125;&#125; 上面写了一个线程安全的单例模式的懒汉式，但却不是十分理想，假如同时有好多线程去调用getInstance方法，那么同一时间只有一个线程能够获取到类的实例，其他的线程都要排队等待该线程释放锁，效率低下。所以此时引出了“双重检验锁”。现在同时有两个线程进入到getInstance方法中，那么两个线程都会进入到第一个判空语句块中，因为此时还没有创建类的实例，接下来只有一个线程能获取到锁，进入到synchronized (SingletonDemo4.class){}语句块中，创建类的实例后释放锁，当前等待线程就会获取到锁，此时如果没有第二次判空操作，那么第二个线程就会再创建一次类的实例，这样就违背了单例的原则，所以双重检验锁就是这么来的。因为上来不是直接就加锁，而是在进行判空后加锁，也就是只有该类还没有被实例化时才会被加锁，当有实例了就不用加锁了，自然就提高了性能。当代码如下： 1234567891011121314151617181920212223/** * 懒汉式的再次优化 * 双重检验锁，解决线程安全问题 * @author mingshan * */public class SingletonDemo4 &#123; private volatile static SingletonDemo4 instance = null; private SingletonDemo4() &#123;&#125; public static SingletonDemo4 getInstance() &#123; if (instance == null) &#123; synchronized (SingletonDemo4.class) &#123; if (instance == null) &#123; instance = new SingletonDemo4(); &#125; &#125; &#125; return instance; &#125;&#125; 这里用到了volatile关键字，这里保证了不同线程对这个变量进行操作时的可见性。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
        <tag>单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈基于ZooKeeper的分布式锁]]></title>
    <url>%2F2017%2F10%2F08%2F%E8%B0%88%E8%B0%88%E5%9F%BA%E4%BA%8EZooKeeper%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[分布式锁可以基于以下几种方式实现： 基于数据库的乐观锁，用于分布式锁 基于缓存(Redis, memcached)实现分布式锁 基于ZooKeeper实现分布式锁 在这篇文章中，主要讲讲ZooKeeper以及分布式锁的实现，通过了解基于ZooKeeper分布式锁实现的原理，我们会对ZooKeeper有一个基本的了解。 ZooKeeper介绍首先谈谈ZooKeeper，ZooKeeper是一种为分布式应用所设计的高可用、高性能且一致的开源协调服务，它提供了一项基本服务：分布式锁服务。由于ZooKeeper的开源特性，后来我们的开发者在分布式锁的基础上，摸索了出了其他的使用方法：配置维护、组服务、分布式消息队列、分布式通知/协调等。 在ZooKeeper中，有一个被称为ZNode的节点，在该节点可以存储同步相关的数据，并且多个ZNode节点可以形成类似下图的结构。 基本命令：123456789101112131415161. 查看节点 ls /2. 创建节点 create /zk myData3. 查看节点 get /zk4. 设置节点 set /zk myData25. 删除节点 delete /zk6. 创建临时节点 create -e /han data7. 创建顺序节点 create -s /han/ data8. 创建顺序临时节点 create -s -e /han/ data ZNode客户端可以在一个ZNode上设置一个监视器（Watch），如果该ZNode数据发生变更，ZooKeeper会通知客户端，从而触发监视器中实现的逻辑的执行。其中ZNode有以下几种类型： PERSISTENT PERSISTENT_SEQUENTIAL EPHEMERAL EPHEMERAL_SEQUENTIAL 下面分别解释一下： PERSISTENT为持久节点，持久节点是指在节点创建后，就一直存在，直到有删除操作来主动清除这个节点——不会因为创建该节点的客户端会话失效而消失。ZooKeeper命令： 1create /zk myData PERSISTENT_SEQUENTIAL为持久顺序节点，基本特性与持久节点一致，但每个父节点会为他的第一级子节点维护一份时序，会记录每个子节点创建的先后顺序。命令： 1create -s /han/ data 用这条命令的话，需要先创建/han节点，节点类型为PERSISTENT。 EPHEMERAL为临时节点，客户端会话失效或连接关闭后，该节点会被自动删除，且不能在临时节点下面创建子节点，命令： 1create -e /han 如果在临时节点下面还要创建子节点，那么zk就会提示：Ephemerals cannot have children EPHEMERAL_SEQUENTIAL为临时顺序节点，该节点的除了不是持久性节点，其他特性与持久顺序节点一致。命令： 1create -s -e /han/ data 不利用EPHEMERAL_SEQUENTIA简单实现首先我们需要一个业务,这里模拟一下订单生成，利用时间加上序号来表示，代码如下： 1234567891011121314151617181920package pers.mingshan.ZookeeperLock;import java.text.SimpleDateFormat;import java.util.Date;/** * 订单号生成器 * @author mingshan * */public class OrderCodeGenerator &#123; private int i = 0; public String getOrderCode() &#123; SimpleDateFormat sdf = new SimpleDateFormat("yy-MM-dd HH:mm:ss - "); Date date = new Date(); sdf.format(date); return sdf.format(date) + ++i; &#125;&#125; 这里只是简单模拟一下，不考虑其他因素。然后我们需要对外提供获取订单号的服务，这里我们用到了CountDownLatch, CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。所以我们需要所有的线程都创建完毕后去同时生成订单编号，模拟一下并发。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package pers.mingshan.ZookeeperLock;import java.util.concurrent.CountDownLatch;import java.util.concurrent.locks.Lock;import org.apache.log4j.Logger;public class OrderServiceImpl implements Runnable &#123; private static OrderCodeGenerator generator = new OrderCodeGenerator(); // 同时并发的线程数 private static final int NUM = 10; private Logger logger = Logger.getLogger(getClass()); // 根据线程数初始化倒计数器 private static CountDownLatch cdl = new CountDownLatch(NUM); // lock锁 private static final Lock lock = new ZookeeperDistributeLock(); public void createOrderCode() &#123; String orderCode = null; lock.lock(); try &#123; orderCode = generator.getOrderCode(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; logger.info((Thread.currentThread().getName() + ": 成功获取锁 =====&gt; " + orderCode)); &#125; @Override public void run() &#123; try &#123; // 等待其他线程初始化 cdl.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; createOrderCode(); &#125; public static void main(String[] args) &#123; OrderServiceImpl service = new OrderServiceImpl(); for (int i = 0; i &lt; NUM; i++) &#123; new Thread(service).start(); // 每初始化一个线程， 计数器减一 cdl.countDown(); &#125; &#125;&#125; 在这个类中，我们实例化了ZookeeperDistributeLock，然后我们对获取订单编号的方法进行加锁操作，在finally语句块中执行释放锁操作。 下面来看ZookeeperDistributeLock，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package pers.mingshan.ZookeeperLock;import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.exception.ZkNodeExistsException;import org.apache.log4j.Logger;/** * 利用Zookeeper节点名称的唯一性进行加锁和释放锁操作。 * 利用znode名称唯一性进行加锁，所有客户端去竞争加锁，但只有一个会加锁 * 成功，其他客户端需要等待加锁成功的客户端去释放锁，释放锁操作则是删除该节点， * 同时通知所有watch这个节点的客户端，其他的客户端再竞争加锁。 * 由于释放锁会通知所有watch该节点的客户端，所以会出现羊群效应， * 造成资源浪费。 * @author mingshan * */public class ZookeeperDistributeLock implements Lock &#123; private static Logger logger = Logger.getLogger(ZookeeperDistributeLock.class); // Zookeeper IP和端口 private static final String ZK_IP_PORT = "localhost:2181"; // Node 的名称 private static final String LOCK_NODE = "/lockS"; // 创建 Zookeeper 的客户端 private ZkClient zkClient = new ZkClient(ZK_IP_PORT); // 减数器 private static CountDownLatch cdl = null; /** * 阻塞式加锁 */ @Override public void lock() &#123; // 先尝试加锁，加锁成功后就直接返回 if (tryLock()) &#123; return; &#125; // 如果不成功， 需要等待其他线程 释放锁 waitForLock(); // 递归调用加锁 lock(); &#125; /** * 等待其他线程释放锁 */ private void waitForLock() &#123; // 给节点加 监听器 IZkDataListener listener = new IZkDataListener() &#123; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; logger.info("----node delete event------"); if (cdl != null) &#123; cdl.countDown(); &#125; &#125; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; // TODO Auto-generated method stub &#125; &#125;; // 执行订阅node节点的数据变化 zkClient.subscribeDataChanges(LOCK_NODE, listener); if (zkClient.exists(LOCK_NODE)) &#123; try&#123; cdl = new CountDownLatch(1); cdl.await(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; // 取消订阅node节点的数据变化 zkClient.unsubscribeDataChanges(LOCK_NODE, listener); &#125; /** * 实现非阻塞式加锁 * @return */ @Override public boolean tryLock() &#123; try &#123; zkClient.createPersistent(LOCK_NODE); return true; &#125; catch (ZkNodeExistsException e) &#123; logger.error("加锁失败 -- reason -" + e.getMessage()); return false; &#125; &#125; /** * 解锁 */ @Override public void unlock() &#123; zkClient.delete(LOCK_NODE); &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; // TODO Auto-generated method stub return false; &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; // TODO Auto-generated method stub &#125; @Override public Condition newCondition() &#123; // TODO Auto-generated method stub return null; &#125;&#125; 利用Zookeeper节点名称的唯一性进行加锁和释放锁操作。利用znode名称唯一性进行加锁，所有客户端去竞争加锁，但只有一个会加锁成功， 其他客户端需要等待加锁成功的客户端去释放锁，释放锁操作则是删除该节点，同时通知所有watch这个节点的客户端，其他的客户端再竞争加锁。由于释放锁会通知所有watch该节点的客户端，所以会出现羊群效应，造成资源浪费。 利用EPHEMERAL_SEQUENTIA解决“羊群效应”实现逻辑： 首先创建一个持久节点 在trylock方法中先判断当前临时顺序节点是否存在，如果不存在，那么就创建一个临时顺序节点，临时顺序节点为持久节点的子节点 然后获取所有的临时顺序节点并进行排序，判断当前节点是否为最小节点 如果当前结点为最小节点，说明当前可以加锁 如果当前临时节点并非最小，代表当前客户端没有获取锁，需要继续等待,此时获取比当前节点序号小的节点（比当前节点小的最大节点, 将此值赋给beforePath,例如： 当前节点是 /lock/000000003, 那么beforePath为 /lock/000000002，只有当beforePath获得锁并且释放锁后，当前客户端才能去获取锁,这样可以 避免羊群效应 在lock方法中，首先会调用trylock进行尝试加锁，如果加锁失败，那么就要调用waitForLock方法，在该方法中，对当前临时顺序节点的前一个节点进行监听，此时只需给前面的节点的添加wathcher即可。 实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144package pers.mingshan.ZookeeperLock;import java.util.Collections;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.I0Itec.zkclient.serialize.SerializableSerializer;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * * @author mingshan * */public class ZookeeperImproveDistributeLock implements Lock&#123; private static final Logger logger = LoggerFactory.getLogger(ZookeeperImproveDistributeLock.class); // Zookeeper IP和端口 private static final String ZK_IP_PORT = "localhost:2181"; // Node 的名称 private static final String LOCK_ROOT_NODE = "/lock"; // 创建 Zookee的客户端 private ZkClient zkClient = new ZkClient(ZK_IP_PORT, 1000, 1000, new SerializableSelizer()); // 当前创建的节点 private String selfPath; // 当前节点的前一个节点 private String beforePath; // 节点默认值 private String data = "data"; // 减数器 private static CountDownLatch cdl = null; public ZookeeperImproveDistributeLock() &#123; // 先创建一个主节点，以便其他线程在此节点之下创建临时顺序节点 if (!this.zkClient.exists(LOCK_ROOT_NODE)) &#123; this.zkClient.createPersistent(LOCK_ROOT_NODE); &#125; &#125; @Override public void lock() &#123; // 先尝试加锁，加锁成功后就直接返回 if (!tryLock()) &#123; waitForLock(); lock(); &#125; else &#123; logger.info(Thread.currentThread().getName() + "---获取锁"); &#125; &#125; private void waitForLock() &#123; // 给节点加 监听器 IZkDataListener listener = new IZkDataListener() &#123; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; logger.info("----before node delete event------"); if (cdl != null) &#123; cdl.countDown(); &#125; &#125; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; &#125; &#125;; // 此时只需给前面的节点的添加wathcher即可 zkClient.subscribeDataChanges(this.beforePath, listener); if (zkClient.exists(this.beforePath)) &#123; try&#123; cdl = new CountDownLatch(1); cdl.await(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; // 取消订阅前面的节点的变化 zkClient.unsubscribeDataChanges(this.beforePath, listener); &#125; @Override public boolean tryLock() &#123; // 判断当前节点是否存在 if (this.selfPath == null || this.selfPath.length() == 0) &#123; // 在当前节点下创建临时顺序节点，例如0000000034, // 生成的节点应为 /lock/0000000034 this.selfPath = this.zkClient.createEphemeralSequential(LOCK_ROOT_NODE + "/", data); logger.info("当前节点为 ————&gt; " + this.selfPath); &#125; // 获取所有的临时顺序节点，并进行排序 List&lt;String&gt; allESNodes = zkClient.getChildren(LOCK_ROOT_NODE); Collections.sort(allESNodes); logger.info("0 ————&gt; "+ allESNodes.get(0)); // 判断当前节点是否为最小节点 if (this.selfPath.equals(LOCK_ROOT_NODE + "/" + allESNodes.get(0))) &#123; // 如果当前结点为最小节点，说明当前可以加锁 return true; &#125; else &#123; // 如果当前临时节点并非最小，代表当前客户端没有获取锁，需要继续等待, // 此时获取比当前节点序号小的节点（比当前节点小的最大节点, 将此值赋给beforePath // 例如： 当前节点是 /lock/000000003, 那么beforePath为 /lock/000000002， // 只有当beforePath获得锁并且释放锁后，当前客户端才能去获取锁 // 这样可以 避免羊群效应 int wz = Collections.binarySearch(allESNodes, this.selfPath.substring(6)); this.beforePath = LOCK_ROOT_NODE + "/" + allESNodes.get(wz - 1); &#125; return false; &#125; @Override public void unlock() &#123; // 删除当前节点，释放锁 zkClient.delete(this.selfPath); &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; // TODO Auto-generated method stub return false; &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; // TODO Auto-generated method stub &#125; @Override public Condition newCondition() &#123; // TODO Auto-generated method stub return null; &#125;&#125; 上面的代码还有其他实现方式，代码如下（网上的）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204package pers.mingshan.ZookeeperLock;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.apache.zookeeper.*;import org.apache.zookeeper.data.Stat;import java.util.List;import java.io.IOException;import java.util.Collections;import java.util.concurrent.CountDownLatch;public class ZookeeperOptimizedDistributedLock implements Watcher&#123; private int threadId; private ZooKeeper zk = null; private String selfPath; private String waitPath; private String LOG_PREFIX_OF_THREAD; private static final int SESSION_TIMEOUT = 10000; private static final String GROUP_PATH = "/disLocks"; private static final String SUB_PATH = "/disLocks/sub"; private static final String CONNECTION_STRING = "localhost:2181"; private static final int THREAD_NUM = 10; //确保连接zk成功 private CountDownLatch connectedSemaphore = new CountDownLatch(1); //确保所有线程运行结束 private static final CountDownLatch threadSemaphore = new CountDownLatch(THREAD_NUM); private static final Logger LOG = LoggerFactory.getLogger(ZookeeperOptimizedDistributedLock.class); public ZookeeperOptimizedDistributedLock(int id) &#123; this.threadId = id; LOG_PREFIX_OF_THREAD = "【第"+threadId+"个线程】"; &#125; public static void main(String[] args) &#123; for(int i = 0; i &lt; THREAD_NUM; i++) &#123; final int threadId = i + 1; new Thread() &#123; @Override public void run() &#123; try &#123; ZookeeperOptimizedDistributedLock dc = new ZookeeperOptimizedDistributedLock(threadId); dc.createConnection(CONNECTION_STRING, SESSION_TIMEOUT); //GROUP_PATH不存在的话，由一个线程创建即可； synchronized (threadSemaphore)&#123; dc.createPath(GROUP_PATH, "该节点由线程" + threadId + "创建", true); &#125; dc.getLock(); &#125; catch (Exception e) &#123; LOG.error("【第"+threadId+"个线程】 抛出的异常："); e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; try &#123; threadSemaphore.await(); LOG.info("所有线程运行结束!"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取锁 * @return */ private void getLock() throws KeeperException, InterruptedException &#123; selfPath = zk.create(SUB_PATH, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); LOG.info(LOG_PREFIX_OF_THREAD+"创建锁路径:"+selfPath); if(checkMinPath())&#123; getLockSuccess(); &#125; &#125; /** * 创建节点 * @param path 节点path * @param data 初始数据内容 * @return */ public boolean createPath( String path, String data, boolean needWatch) throws KeeperException, InterruptedException &#123; if(zk.exists(path, needWatch)==null)&#123; LOG.info( LOG_PREFIX_OF_THREAD + "节点创建成功, Path: " + this.zk.create( path, data.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT ) + ", content: " + data ); &#125; return true; &#125; /** * 创建ZK连接 * @param connectString ZK服务器地址列表 * @param sessionTimeout Session超时时间 */ public void createConnection( String connectString, int sessionTimeout ) throws IOException, InterruptedException &#123; zk = new ZooKeeper( connectString, sessionTimeout, this); connectedSemaphore.await(); &#125; /** * 获取锁成功 */ public void getLockSuccess() throws KeeperException, InterruptedException &#123; if (zk.exists(this.selfPath,false) == null) &#123; LOG.error(LOG_PREFIX_OF_THREAD+"本节点已不在了..."); return; &#125; LOG.info(LOG_PREFIX_OF_THREAD + "获取锁成功，赶紧干活！"); Thread.sleep(2000); LOG.info(LOG_PREFIX_OF_THREAD + "删除本节点："+selfPath); zk.delete(this.selfPath, -1); releaseConnection(); threadSemaphore.countDown(); &#125; /** * 关闭ZK连接 */ public void releaseConnection() &#123; if ( this.zk !=null ) &#123; try &#123; this.zk.close(); &#125; catch ( InterruptedException e ) &#123;&#125; &#125; LOG.info(LOG_PREFIX_OF_THREAD + "释放连接"); &#125; /** * 检查自己是不是最小的节点 * @return */ public boolean checkMinPath() throws KeeperException, InterruptedException &#123; List&lt;String&gt; subNodes = zk.getChildren(GROUP_PATH, false); Collections.sort(subNodes); int index = subNodes.indexOf( selfPath.substring(GROUP_PATH.length() + 1)); switch (index)&#123; case -1:&#123; LOG.error(LOG_PREFIX_OF_THREAD+"本节点已不在了..."+selfPath); return false; &#125; case 0:&#123; LOG.info(LOG_PREFIX_OF_THREAD+"子节点中，我果然是老大"+selfPath); return true; &#125; default:&#123; this.waitPath = GROUP_PATH +"/"+ subNodes.get(index - 1); LOG.info(LOG_PREFIX_OF_THREAD+"获取子节点中，排在我前面的"+waitPath); try&#123; zk.getData(waitPath, true, new Stat()); return false; &#125;catch(KeeperException e)&#123; if(zk.exists(waitPath,false) == null)&#123; LOG.info(LOG_PREFIX_OF_THREAD+"子节点中，排在我前面的"+waitPath+"已失踪，幸福来得太突然?"); return checkMinPath(); &#125;else&#123; throw e; &#125; &#125; &#125; &#125; &#125; @Override public void process(WatchedEvent event) &#123; if(event == null)&#123; return; &#125; Event.KeeperState keeperState = event.getState(); Event.EventType eventType = event.getType(); if ( Event.KeeperState.SyncConnected == keeperState) &#123; if ( Event.EventType.None == eventType ) &#123; LOG.info( LOG_PREFIX_OF_THREAD + "成功连接上ZK服务器" ); connectedSemaphore.countDown(); &#125;else if (event.getType() == Event.EventType.NodeDeleted &amp;&amp; event.getPath().equals(waitPath)) &#123; LOG.info(LOG_PREFIX_OF_THREAD + "收到情报，排我前面的家伙已挂，我是不是可以出山了？"); try &#123; if(checkMinPath())&#123; getLockSuccess(); &#125; &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;else if ( Event.KeeperState.Disconnected == keeperState ) &#123; LOG.info( LOG_PREFIX_OF_THREAD + "与ZK服务器断开连接" ); &#125; else if ( Event.KeeperState.AuthFailed == keeperState ) &#123; LOG.info( LOG_PREFIX_OF_THREAD + "权限检查失败" ); &#125; else if ( Event.KeeperState.Expired == keeperState ) &#123; LOG.info( LOG_PREFIX_OF_THREAD + "会话失效" ); &#125; &#125;&#125; 参考http://blog.csdn.net/desilting/article/details/41280869]]></content>
      <categories>
        <category>Java</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ZooKeeper</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用SpringMVC实现RESTful API，并与Swagger集成生成API文档]]></title>
    <url>%2F2017%2F10%2F01%2F%E5%88%A9%E7%94%A8SpringMVC%E5%AE%9E%E7%8E%B0RESTful%20API%EF%BC%8C%E5%B9%B6%E4%B8%8ESwagger%E9%9B%86%E6%88%90%E7%94%9F%E6%88%90API%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[认识RESTful APIRESTful API是目前比较成熟的API设计理论，它通过统一的API接口来对外提供服务，这样对其他调用者来说比较友好，更加容易实现前后端分离。那么如果要使用RESTful API来写我们的代码，那么就需要先知道RESTful API规范。 参考RESTful API规范下面是两篇文章讲解RESTful API的，推荐： RESTful API 设计指南 RESTful API 设计最佳实践 SpringMVC实现RESTful APISpringMVC提供了一些注解来实现RESTful API, 例如@RestController，同时我们用Swagger来生成API文档，这样更加利于测试API。 常见swagger注解一览与使用最常用的5个注解 @Api：修饰整个类，描述Controller的作用@ApiOperation：描述一个类的一个方法，或者说一个接口@ApiParam：单个参数描述@ApiModel：用对象来接收参数@ApiProperty：用对象接收参数时，描述对象的一个字段 其它若干 @ApiResponse：HTTP响应其中1个描述@ApiResponses：HTTP响应整体描述@ApiClass@ApiError@ApiErrors@ApiParamImplicit@ApiParamsImplicit 其中@ApiOperation和@ApiParam参数说明 @ApiOperation和@ApiParam为添加的API相关注解，参数说明如下：@ApiOperation(value = “接口说明”, httpMethod = “接口请求方式”, response = “接口返回参数类型”, notes = “接口发布说明”；其他参数可参考源码；@ApiParam(required = “是否必须参数”, name = “参数名称”, value = “参数具体描述” 添加依赖首先在pom.xml文件中添加swagger依赖 123456789101112131415161718192021&lt;!-- swagger --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mangofactory&lt;/groupId&gt; &lt;artifactId&gt;swagger-springmvc&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.5.1&lt;/version&gt;&lt;/dependency&gt; Swagger-UI配置首先从Swagger-UI下载地址下载Swagger-UI文件，然后将其拷贝到webapp目录下，我这里新建了一个swagger文件夹，然后解压后的文件拷贝到这个文件夹里面了。 修改swagger/index.html文件，默认是从连接http://petstore.swagger.io/v2/swagger.json获取 API 的JSON，这里需要将url值修改为http://{ip}:{port}/{projectName}/api-docs的形式，{}中的值根据自身情况填写。比如我的url值为：http://localhost:8080/lightblog/api-docs 编写swagger配置文件配置完Swagger-UI后，我们需要配置Swagger，并将其交给Spring进行管理。SwaggerConfig类代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.lightblog.swagger;import com.mangofactory.swagger.configuration.SpringSwaggerConfig;import com.mangofactory.swagger.models.dto.ApiInfo;import com.mangofactory.swagger.plugin.EnableSwagger;import com.mangofactory.swagger.plugin.SwaggerSpringMvcPlugin;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;/** * @Description: * @Author: Minsghan * @Date: Created in 16:40 2017/10/3 * @Modified By: */@Configuration@EnableWebMvc//如果没加这个会报错@EnableSwagger//上面三个注释都是必要的@ComponentScan(basePackages="com.lightblog.controller")//添加这个注释，会自动扫描该类中的每一个方法自动生成api文档public class SwaggerConfig &#123; private SpringSwaggerConfig springSwaggerConfig; /** * Required to autowire SpringSwaggerConfig */ @Autowired public void setSpringSwaggerConfig(SpringSwaggerConfig springSwaggerConfig) &#123; this.springSwaggerConfig = springSwaggerConfig; &#125; /** * Every SwaggerSpringMvcPlugin bean is picked up by the swagger-mvc * framework - allowing for multiple swagger groups i.e. same code base * multiple swagger resource listings. */ @Bean public SwaggerSpringMvcPlugin customImplementation() &#123; return new SwaggerSpringMvcPlugin(this.springSwaggerConfig) .apiInfo(apiInfo()) .includePatterns(".*?"); &#125; private ApiInfo apiInfo() &#123; ApiInfo apiInfo = new ApiInfo( "springmvc搭建swagger", "spring-API swagger测试", "My Apps API terms of service", "499445428@qq.com", "web app", "My Apps API License URL"); return apiInfo; &#125;&#125; 将 springSwaggerConfig加载到spring容器，配置如下： 1234&lt;!-- 将 springSwaggerConfig加载到spring容器 --&gt;&lt;bean class=&quot;com.mangofactory.swagger.configuration.SpringSwaggerConfig&quot; /&gt;&lt;!-- 将自定义的swagger配置类加载到spring容器 --&gt;&lt;bean class=&quot;com.lightblog.swagger.SwaggerConfig&quot; /&gt; Controller实现REST API以及与Swagger集成在Controller中，我们不需要返回页面了，而是要返回json格式的数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137package com.lightblog.controller;import com.lightblog.model.User;import com.lightblog.service.UserService;import com.wordnik.swagger.annotations.Api;import com.wordnik.swagger.annotations.ApiOperation;import com.wordnik.swagger.annotations.ApiParam;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.*;import org.springframework.web.util.UriComponentsBuilder;import java.util.List;/** * @Description: The api of user. * @Author: Minsghan * @Date: Created in 15:27 2017/10/3 * @Modified By: */@Api(value="user")@RestController@RequestMapping("/api/user")public class UserController extends BaseController &#123; @Autowired private UserService userService; /** * @Author: Mingshan * @Description: Get list of user. * @param: null * @Date: 15:16 2017/10/3 */ @RequestMapping(value = "", method = RequestMethod.GET) @ApiOperation(value="获取所有用户信息", httpMethod="GET", notes="Get users", response=ResponseEntity.class) public ResponseEntity&lt;List&lt;User&gt;&gt; listAllUsers() &#123; List&lt;User&gt; users = userService.findAll(); if(users.isEmpty())&#123; // You many decide to return HttpStatus.NOT_FOUND return new ResponseEntity&lt;List&lt;User&gt;&gt;(HttpStatus.NO_CONTENT); &#125; return new ResponseEntity&lt;List&lt;User&gt;&gt;(users, HttpStatus.OK); &#125; /** * @Author: Mingshan * @Description: Get information of user by id. * @param: * @param id * @Date: 15:34 2017/10/3 */ @RequestMapping(value = "/&#123;id&#125;", method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_VALUE) @ApiOperation(value="获取用户信息", httpMethod="GET", notes="Get user by id", response=User.class) public ResponseEntity&lt;User&gt; getUser(@ApiParam(required=true,value="用户ID",name="id")@PathVariable("id") long id) &#123; logger.info("Fetching User with id " + id); User user = userService.findById(id); if (user == null) &#123; logger.info("User with id " + id + " not found"); return new ResponseEntity&lt;User&gt;(HttpStatus.NOT_FOUND); &#125; return new ResponseEntity&lt;User&gt;(user, HttpStatus.OK); &#125; /** * @Author: Mingshan * @Description: Create a user. * @param: * @param null * @Date: 15:34 2017/10/3 */ @RequestMapping(value = "", method = RequestMethod.POST) @ApiOperation(value="新增用户", httpMethod="POST", notes="Create user", response=ResponseEntity.class) public ResponseEntity&lt;Void&gt; createUser(@ApiParam(required=true,value="用户信息",name="User") @RequestBody User user, UriComponentsBuilder ucBuilder) &#123; logger.info("Creating User " + user.getName()); if (userService.isUserExist(user)) &#123; System.out.println("A User with name " + user.getName() + " already exist"); return new ResponseEntity&lt;Void&gt;(HttpStatus.CONFLICT); &#125; userService.insert(user); HttpHeaders headers = new HttpHeaders(); headers.setLocation(ucBuilder.path("/user/&#123;id&#125;").buildAndExpand(user.getId()).toUri()); return new ResponseEntity&lt;Void&gt;(headers, HttpStatus.CREATED); &#125; /** * @Author: Mingshan * @Description: Update a user. * @param: * @param null * @Date: 15:33 2017/10/3 */ @RequestMapping(value = "/&#123;id&#125;", method = RequestMethod.PUT) @ApiOperation(value="更新用户信息", httpMethod="PUT", notes="Update user", response=User.class) public ResponseEntity&lt;User&gt; updateUser(@ApiParam(required=true,value="用户ID",name="id")@PathVariable("id") long id, @RequestBody User user) &#123; logger.info("Updating User " + id); User currentUser = userService.findById(id); if (currentUser == null) &#123; logger.info("User with id " + id + " not found"); return new ResponseEntity&lt;User&gt;(HttpStatus.NOT_FOUND); &#125; currentUser.setName(user.getName()); currentUser.setAge(user.getAge()); userService.update(currentUser); return new ResponseEntity&lt;User&gt;(currentUser, HttpStatus.OK); &#125; /** * @Author: Mingshan * @Description: Delete a user by id. * @param: * @param null * @Date: 15:32 2017/10/3 */ @RequestMapping(value = "/&#123;id&#125;", method = RequestMethod.DELETE) @ApiOperation(value="删除用户", httpMethod="DELETE", notes="Delete user by id", response=ResponseEntity.class) public ResponseEntity&lt;Void&gt; deleteUser(@ApiParam(required=true,value="用户ID",name="id")@PathVariable("id") long id) &#123; logger.info("Fetching &amp; Deleting User with id " + id); User user = userService.findById(id); if (user == null) &#123; logger.info("Unable to delete. User with id " + id + " not found"); return new ResponseEntity&lt;Void&gt;(HttpStatus.NOT_FOUND); &#125; userService.delete(id); return new ResponseEntity&lt;Void&gt;(HttpStatus.NO_CONTENT); &#125;&#125; 运行截图 参考 http://blog.csdn.net/fansunion/article/details/51923720 http://blog.csdn.net/w605283073/article/details/51338765 官网：http://swagger.io/ GitHub： swagger-springmvc:https://github.com/martypitt/swagger-springmvc swagger-ui:https://github.com/swagger-api/swagger-ui swagger-core:https://github.com/swagger-api/swagger-core swagger-spec：https://github.com/swagger-api/swagger-spec]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RESTful-API</tag>
        <tag>Swagger</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Service层进行事务控制]]></title>
    <url>%2F2017%2F09%2F15%2F%E5%9C%A8Service%E5%B1%82%E8%BF%9B%E8%A1%8C%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[利用接口回调实现JDBCTemplate 设计一个回调接口JDBCCallback, 用来设置参数和获取结果集, 代码如下： 123456public interface JDBCCallback&lt;T&gt; &#123; T rsToObject(ResultSet rs) throws SQLException; void setParams(PreparedStatement pstmt) throws SQLException;&#125; 设计一个抽象类JDBCAbstractCallBack，该类实现JDBCCallback接口，重写接口中的两个方法， 不需要具体实现，只需要重写一下就可以了，这样在DAO层用的时候不用这两个方法全部都要实现，代码如下： 123456789101112131415161718/** * JDBC abstract callback class, implements &#123;@link JDBCCallback&#125; interface. * @author Mingshan * * @param &lt;T&gt; */public abstract class JDBCAbstractCallBack&lt;T&gt; implements JDBCCallback&lt;T&gt; &#123; @Override public T rsToObject(ResultSet rs) throws SQLException &#123; return null; &#125; @Override public void setParams(PreparedStatement pstmt) throws SQLException &#123; // NOOP &#125;&#125; 设计一个JDBCTemplate类，该类实现增删改查的基本方法，把公共的代码抽取出来，以便DAO层去调用JDBCTemplate来实现具体的业务，部分代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * JDBC Template, applys for delete, query, update, save functions. * @author Mingshan * * @param &lt;T&gt; */public class JDBCTemplate&lt;T&gt; &#123; /** * Querys data by sql. */ public List&lt;T&gt; query(String sql, JDBCCallback&lt;T&gt; jdbcCallback) &#123; Connection conn = null; PreparedStatement pstmt = null; ResultSet rs = null; List&lt;T&gt; data = new ArrayList&lt;T&gt;(); boolean needMyClose = false; try &#123; // Gets connection of JDBC. ConnectionHolder connectionHolder = (ConnectionHolder) AppContext.getAppContext() .getObject(Constants.APP_REQUEST_THREAD_CONNECTION); if (connectionHolder != null) &#123; conn = connectionHolder.getConn(); &#125; if (conn == null) &#123; conn = DB.getConn(); needMyClose = true; &#125; pstmt = DB.getPrepareStatement(conn, sql); // Sets parameters for PreparedStatement. jdbcCallback.setParams(pstmt); rs = pstmt.executeQuery(); while (rs.next()) &#123; // Gets data from database. T object = jdbcCallback.rsToObject(rs); data.add(object); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new DBException(); &#125; finally &#123; DB.close(rs); DB.close(pstmt); if (needMyClose) &#123; DB.close(conn); &#125; &#125; return data; &#125; public void update(String sql, JDBCCallback&lt;T&gt; jdbcCallback) &#123; Connection conn = null; PreparedStatement pstmt = null; boolean needMyClose = false; try &#123; ConnectionHolder connectionHolder = (ConnectionHolder) AppContext.getAppContext() .getObject(Constants.APP_REQUEST_THREAD_CONNECTION); if (connectionHolder != null) &#123; conn = connectionHolder.getConn(); &#125; if (conn == null) &#123; conn = DB.getConn(); needMyClose = true; &#125; pstmt = DB.getPrepareStatement(conn, sql); jdbcCallback.setParams(pstmt); pstmt.execute(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new DBException(); &#125; finally &#123; DB.close(pstmt); if (needMyClose) &#123; DB.close(conn); &#125; &#125; &#125;&#125; 其他的增删改查可以按照上面的模式进行扩展，就不写了。 在DAO层使用JDBCTemplate，部分代码如下：1234567891011121314151617181920212223242526272829303132public class UserDaoImpl implements UserDao &#123; private JDBCTemplate&lt;User&gt; jdbcTemplate; public void setJdbcTemplate(JDBCTemplate&lt;User&gt; jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; @Override public User findUserByUserName(final String userName) &#123; User user = null; String sql = "SELECT * FROM user WHERE user_name = ?"; user = jdbcTemplate.queryOne(sql, new JDBCAbstractCallBack&lt;User&gt;() &#123; @Override public User rsToObject(ResultSet rs) throws SQLException &#123; User user = new User(); user.setPassword(rs.getString(Constants.USER_PASSWORD)); user.setUserName(rs.getString(Constants.USER_USER_NAME)); user.setId(rs.getInt(Constants.USER_ID)); return user; &#125; @Override public void setParams(PreparedStatement pstmt) throws SQLException &#123; pstmt.setString(1, userName); &#125; &#125;); return user; &#125;&#125; —————————————————————————OVER———————————————————————————— 如何在Service层进行事务控制？ 设计一个ConnectionHolder类，用来存放Connection。 该类有两个成员变量 Connection conn, boolean isOpenTransaction, 并且提供getter和setter方法。 Connection conn 用来存放Connection, boolean isOpenTransaction 用来判断需不需要开启事务 编写ConnectionProxy类，并实现InvocationHandler接口，该类用来真正实现事务控制，具体解析如下： 首先需要获取配置的事务传播，用来判断哪些方法需要进行事务控制，哪些不需要，可以参考Spring配置事务的代码，这里先模拟一下，XML配置信息如下，然后需要对XML配置信息进行解析，然后以map形式返回，这时我们就可以按照我们的需求来判断当前要调用Service层的方法到底是属于哪一种，进而判断是否要进行事务控制。如果需要关闭数据库连接，那么数据库连接应在代理类中关闭。 判读connectionHolder对象是否已被创建，如果已被创建，直接使用，然后进行事务控制判断；如果不存在，那么在这里创建，需要拿到数据库连接，然后进行事务控制判断。这里用到了Connection共用，即一个request只有一个Connection。 利用反射调用方法， 此时方法会出现异常， 需要进行捕获。如果事务开启，并且调用方法出现异常了，那么就需要事 务回滚，最后关闭连接。 DAO层的写法请参考JDBCTemplate, 为了防止数据库连接中断，需要DAO层再进行一次连接判断，此时数据库的连接就 需要在DAO层关闭了。 事务配置：1234567891011&lt;!-- TransactionInterceptor --&gt;&lt;bean id="TransactionInterceptor"&gt; &lt;property name="transactionAttributes"&gt; &lt;prop key="update*" propagation="REQUIRED"&gt;&lt;/prop&gt; &lt;prop key="delete*" propagation="REQUIRED"&gt;&lt;/prop&gt; &lt;prop key="save*" propagation="REQUIRED"&gt;&lt;/prop&gt; &lt;prop key="find*" propagation="SUPPORTS"&gt;&lt;/prop&gt; &lt;prop key="select*" propagation="SUPPORTS"&gt;&lt;/prop&gt; &lt;/property&gt;&lt;/bean&gt; 代理类代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * JDBC ConnectionProxy. * @author Mingshan * */public class ConnectionProxy implements InvocationHandler &#123; private Object target; private TransactionConfig transactionConfig = AppContext.getAppContext().getTransactionConfig(); public void setTarget(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; // If current thread close connection. boolean needMyClose = false; boolean isCommitOrRollBackTran = false; Map&lt;String, String&gt; tranAttributeMap = transactionConfig.getTranAttributeMap(); String[] allowed = getTransactionAttribute(transactionConfig); String originKey = method.getName() + "*"; // Before advice. ConnectionHolder connectionHolder = (ConnectionHolder) AppContext.getAppContext() .getObject(Constants.APP_REQUEST_THREAD_CONNECTION); if (connectionHolder == null) &#123; Connection conn = DB.getConn(); connectionHolder = new ConnectionHolder(); connectionHolder.setConn(conn); if (StringUtil.matchStr(method.getName(), allowed) &amp;&amp; (tranAttributeMap.get(originKey).equals("REQUIRED"))) &#123; connectionHolder.setOpenTran(true); DB.setAutoCommit(conn, false); isCommitOrRollBackTran = true; &#125; AppContext.getAppContext().addObject(Constants.APP_REQUEST_THREAD_CONNECTION, connectionHolder); isCommitOrRollBackTran = true; needMyClose = true; &#125; else &#123; if (StringUtil.matchStr(method.getName(), allowed) &amp;&amp; (tranAttributeMap.get(originKey).equals("REQUIRED"))) &#123; if (!connectionHolder.isOpenTran()) &#123; connectionHolder.setOpenTran(true); DB.setAutoCommit(connectionHolder.getConn(), false); isCommitOrRollBackTran = true; &#125; &#125; &#125; try &#123; result = method.invoke(target, args); if (isCommitOrRollBackTran) &#123; DB.commit(connectionHolder.getConn()); &#125; &#125; catch (Throwable throwable) &#123; if (isCommitOrRollBackTran) &#123; DB.rollback(connectionHolder.getConn()); &#125; &#125; finally &#123; // After advice. if (needMyClose) &#123; connectionHolder = (ConnectionHolder) AppContext.getAppContext() .getObject(Constants.APP_REQUEST_THREAD_CONNECTION); DB.close(connectionHolder.getConn()); &#125; &#125; return result; &#125; /** * Stores key in map as an array. * @param transactionConfig * @return String[] */ public String[] getTransactionAttribute(TransactionConfig transactionConfig) &#123; Map&lt;String, String&gt; tranAttributeMap = transactionConfig.getTranAttributeMap(); Set&lt;String&gt; keySet = tranAttributeMap.keySet(); String[] methodPrefixs =new String[keySet.size()]; int i = 0; for (String key : keySet) &#123; int index = key.indexOf("*"); if (index == -1) &#123; key = key.substring(0, key.length() - 1); methodPrefixs[i] = key; &#125; else &#123; methodPrefixs[i] = key; &#125; i++; &#125; return methodPrefixs; &#125;&#125; 附：ApplicationContextFilter12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Application Context Filter, include &#123;@link HttpServletRequest&#125; request, * &#123;@link HttpServletResponse&#125; response, &#123;@link Connection&#125; JDBC Connection. * @author Mingshan * */public class AppContextFilter implements Filter &#123; private TransactionConfig transactionConfig = null; public AppContextFilter() &#123;&#125; public void init(FilterConfig fConfig) throws ServletException &#123; ServletContext servletContext = fConfig.getServletContext(); transactionConfig = (TransactionConfig) servletContext.getAttribute("transactionConfig"); &#125; public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; AppContext appContext = AppContext.getAppContext(); appContext.addObject(Constants.APP_CONTEXT_REQUEST, request); appContext.addObject(Constants.APP_CONTEXT_RESPONSE, response); appContext.setTransactionConfig(transactionConfig); ConnectionHolder connectionHolder = (ConnectionHolder) AppContext.getAppContext() .getObject(Constants.APP_REQUEST_THREAD_CONNECTION); boolean needMyClose = false; if(connectionHolder == null) &#123; connectionHolder = new ConnectionHolder(); Connection conn = DB.getConn(); connectionHolder.setConn(conn); AppContext.getAppContext().addObject(Constants.APP_REQUEST_THREAD_CONNECTION, connectionHolder); needMyClose = true; &#125; try &#123; chain.doFilter(request, response); &#125; catch (IOException ioException) &#123; throw ioException; &#125; catch (ServletException servletException) &#123; throw servletException; &#125; catch (RuntimeException runntimeException) &#123; throw runntimeException; &#125; finally &#123; if (needMyClose) &#123; connectionHolder = (ConnectionHolder) AppContext.getAppContext() .getObject(Constants.APP_REQUEST_THREAD_CONNECTION); DB.close(connectionHolder.getConn()); &#125; appContext.clear(); &#125; &#125; public void destroy() &#123; // NOOP &#125;&#125; —————————————————————————OVER————————————————————————————]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用hibernate进行多表查询问题]]></title>
    <url>%2F2017%2F08%2F10%2F%E5%88%A9%E7%94%A8hibernate%E8%BF%9B%E8%A1%8C%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在Hibernate框架中，一个实体类映射为一个数据库表，在进行多表查询时,如何将不同表中的数据整合起来，并且映射为一个实体类是利用Hibernate进行多表查询的关键，根据我的理解，先将代码整理一下： 实体类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Entity@Table(name = "ps_trends")public class Trends implements Serializable &#123; private static final long serialVersionUID = -2228382525594394975L; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private int id; @Column(name = "item_title") private String itemTitle; @Column(name = "item_content") private String itemContent; @Column(name = "type_id") private int typeId; @Column(name = "add_time") private String addTime; @Column(name = "view_count") private int viewCount; @Column(name = "is_image") private int isImage; @Column(name = "is_publish") private int isPublish; //临时属性 @Transient private String itemTypeFlag; @Transient private String itemTypeName; public Trends() &#123;&#125; public Trends(int id, String itemTitle, String itemContent, String addTime, int viewCount, String itemTypeName,String itemTypeFlag) &#123; super(); this.id = id; this.itemTitle = itemTitle; this.itemContent = itemContent; this.addTime = addTime; this.viewCount = viewCount; this.itemTypeName = itemTypeName; this.itemTypeFlag = itemTypeFlag; &#125; setter ，getter方法&#125; 这里有两个属性注解为Transient，因为它们不是主表的映射字段。同时写一个有参构造方法，构造方法的参数列表即为要查询的映射字段。 DaoImpl方法1234567@Overridepublic Trends findTrendsInfoById(int id) &#123; String hql="select new com.primaryschool.home.entity.Trends(t.id,t.itemTitle,t.itemContent,t.addTime,t.viewCount,tt.itemTypeName,tt.itemTypeFlag)from Trends t,TrendsType tt where tt.id=t.typeId and t.id=? and t.isPublish=1"; Query query=sessionFactory.getCurrentSession().createQuery(hql); query.setInteger(0, id); return (Trends) query.uniqueResult();&#125; 在findTrendsInfoById(int id)方法中，hql语句有些特别，它是将两个表的需要字段传入到Trends实体类的构造方法中，这样就可以直接利用getter方法进行取值了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux目录结构]]></title>
    <url>%2F2017%2F08%2F03%2FLinux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Linux目录结构： /: 根目录，一般根目录下只存放目录，不要存放文件，/etc、/bin、/dev、/lib、/sbin应该和根目录放置在一个分区中 /bin:/usr/bin: 可执行二进制文件的目录，如常用的命令ls、tar、mv、cat等。 /boot: 放置linux系统启动时用到的一些文件。/boot/vmlinuz为linux的内核文件，以及/boot/gurb。建议单独分区，分区大小100M即可 /dev：存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱mount /dev/cdrom /mnt。 /etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有/etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d修改配置文件之前记得备份。注：/etc/X11存放与x windows有关的设置。 /home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~表示当前用户的家目录，~test表示用户test的家目录。建议单独分区，并设置较大的磁盘空间，方便用户存放数据 /lib:/usr/lib:/usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助，比较重要的目录为/lib/modules。 /lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下，通常这个目录会自动出现在装置目录下。如加载硬盘于/disk 中，此目录下就会自动产生目录/disk/lost+found /mnt:/media：光盘默认挂载点，通常光盘挂载于/mnt/cdrom下，也不一定，可以选择任意位置进行挂载。 /opt：给主机额外安装软件所摆放的目录。如：FC4使用的Fedora 社群开发软件，如果想要自行安装新的KDE 桌面软件，可以将该软件安装在该目录下。以前的 Linux 系统中，习惯放置在 /usr/local 目录下 /proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有/proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/*等 /root：系统管理员root的家目录，系统第一个启动的分区为/，所以最好将/root和/放置在一个分区下。 /sbin:/usr/sbin:/usr/local/sbin：放置系统管理员使用的可执行命令，如fdisk、shutdown、mount等。与/bin不同的是，这几个目录是给系统管理员root使用的命令，一般用户只能”查看”而不能设置和使用。 /tmp：一般用户或正在执行的程序临时存放文件的目录,任何人都可以访问,重要数据不可放置在此目录下 /srv：服务启动之后需要访问的数据目录，如www服务需要访问的网页数据存放在/srv/www内 /usr：应用程序存放目录，/usr/bin存放应用程序，/usr/share存放共享数据，/usr/lib存放不能直接运行的，却是许多程序运行所必需的一些函数库文件。/usr/local:存放软件升级包。/usr/share/doc:系统说明文件存放目录。/usr/share/man: 程序说明文件存放目录，使用 manls时会查询/usr/share/man/man1/ls.1.gz的内容建议单独分区，设置较大的磁盘空间 /var：放置系统执行过程中经常变化的文件，如随时更改的日志文件/var/log，/var/log/message：所有的登录文件存放目录，/var/spool/mail：邮件存放的目录，/var/run:程序或服务启动后，其PID存放在该目录下。建议单独分区，设置较大的磁盘空间 转载自：https://www.cnblogs.com/CoderJYF/p/6092604.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基本命令]]></title>
    <url>%2F2017%2F08%2F01%2FLinux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[目录操作： 创建目录： 1mkdir $HOME/testFolder 切换目录： 使用 cd 命令切换目录 1cd $HOME/testFolder 使用 cd ../ 命令切换到上一级目录 1cd ../ 移动目录 使用 mv 命令移动目录 1mv $HOME/testFolder /var/tmp 删除目录 使用 rm -rf 命令删除目录 1rm -rf /var/tmp/testFolder 查看目录下的文件 使用 ls 命令查看 /etc 目录下所有文件和文件夹 1ls /etc 文件操作 创建文件 使用 touch 命令创建文件 1touch ~/testFile 复制文件 使用 cp 命令复制文件 1cp ~/testFile ~/testNewFile 删除文件 使用 rm 命令删除文件, 输入 y 后回车确认删除 1rm ~/testFile 查看文件内容 使用 cat 命令查看 .bash_history 文件内容 1cat ~/.bash_history 过滤, 管道与重定向 过滤 过滤出 /etc/passwd 文件中包含 root 的记录 1grep &apos;root&apos; /etc/passwd 递归地过滤出 /var/log/ 目录中包含 linux 的记录 1grep -r &apos;linux&apos; /var/log/ 管道 简单来说, Linux 中管道的作用是将上一个命令的输出作为下一个命令的输入, 像 pipe 一样将各个命令串联起来执行, 管道的操作符是 | 比如, 我们可以将 cat 和 grep 两个命令用管道组合在一起 1cat /etc/passwd | grep &apos;root&apos; 过滤出 /etc 目录中名字包含 ssh 的目录(不包括子目录) 1ls /etc | grep &apos;ssh&apos; 重定向 可以使用 &gt; 或 &lt; 将命令的输出重定向到一个文件中 1echo &apos;Hello World&apos; &gt; ~/test.txt 运维常用命令 ping 命令 对 cloud.tencent.com 发送 4 个 ping 包, 检查与其是否联通 1ping -c 4 cloud.tencent.com netstat 命令 netstat 命令用于显示各种网络相关信息，如网络连接, 路由表, 接口状态等等 列出所有处于监听状态的tcp端口 1netstat -lt 查看所有的端口信息, 包括 PID 和进程名称 1netstat -tulpn ps 命令 过滤得到当前系统中的 ssh 进程信息 1ps -aux | grep &apos;ssh]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java枚举探究]]></title>
    <url>%2F2017%2F07%2F26%2Fjava%E6%9E%9A%E4%B8%BE%E6%8E%A2%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[在jdk1.5中引入枚举这个小功能，这个功能虽然用的不多，但是却给我们的开发带来很多便利，我们今天来看看java的枚举是个什么样子。 枚举的主要操作方法12345678protected Enum(String name,int ordinal) //接受枚举的名称和枚举的常量创建枚举对象 protected final Object clone()throws CloneNotSupportedException //克隆枚举对象 public final int compareTo(E o) //比较枚举与指定对象的顺序public final boolean equals(Object other) //比较两个枚举对象 public final int hashCode() //返回枚举常量的哈希码 public final String name() //返回枚举类的名称 public final int ordinal() //返回枚举常量的序号 public static &lt;T extends Enum&lt;T&gt;&gt; T valueOf(Class&lt;T&gt; enum Type,String name) //返回带指定名称的指定枚举类型的枚举常量 先定义一个枚举，用enum关键字12345678/** * 定义枚举 * @author mingshan * */public enum EnumTest &#123; MON, TUE, WED, THU, FRI, SAT, SUN;&#125; 这里将星期定义为枚举类型，但没有赋值，既然已经定义好了，那么就先测试一下吧。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 枚举测试 * @author mingshan * */public class Test &#123; public static void main(String[] args) &#123; //遍历枚举 for(EnumTest e : EnumTest.values()) &#123; System.out.println(e.toString()); &#125; System.out.println("我是分割线------"); //switch 操作 EnumTest fri = EnumTest.FRI; switch(fri)&#123; case MON : System.out.println("今天是星期一"); break; case FRI : System.out.println("今天是星期五"); break; default : System.out.println("-----"); break; &#125; //返回 System.out.println(fri.getDeclaringClass()); //利用compareTo进行比较 switch (fri.compareTo(EnumTest.SAT)) &#123; case -1: System.out.println("之前"); break; case 1: System.out.println("之后"); break; default: break; &#125; &#125;&#125; 我们可以遍历枚举，用java的foreach进行遍历，调用枚举的values方法获取定义的枚举列表，但当我们编写自定义enum时，却不包含values这个方法，这个方法是当我门编译文件时，编译器自动帮我们加上的。枚举还可以进行switch操作，可以对获取的枚举进行判断。利用compareTo函数进行比较两个枚举的顺序 给 enum 对象加一下 value 的属性和 getValue() 的方法123456789101112131415161718192021222324252627282930313233343536373839/** * 赋初值 * 给 enum 对象加一下 value 的属性和 getValue() 的方法 * @author mingshan * */public enum EnumTest2 &#123; MON(1), TUE(2), WED(3), THU(4), FRI(5), SAT(6) &#123; @Override public boolean isRest() &#123; return true; &#125; &#125;, SUN(0) &#123; @Override public boolean isRest() &#123; return true; &#125; &#125;; private int value; private EnumTest2(int value) &#123; this.value = value; &#125; public int getValue() &#123; return value; &#125; public boolean isRest() &#123; return false; &#125;&#125; 获取属性值 1234/** * 获取属性值 */System.out.println(EnumTest2.FRI.getValue()); EnumSet的使用 1234567//EnumSet的使用EnumSet&lt;EnumTest2&gt; allOf = EnumSet.allOf(EnumTest2.class);//遍历枚举for (EnumTest2 enumTest2 : allOf) &#123; System.out.println(enumTest2.toString());&#125; EnumMap的使用 12345678910EnumMap&lt;EnumTest2, Object&gt; enumMap = new EnumMap&lt;&gt;(EnumTest2.class);enumMap.put(EnumTest2.FRI, "星期五");enumMap.put(EnumTest2.SUN, "星期天");//遍历mapfor (Entry&lt;EnumTest2, Object&gt; enumTest2 : enumMap.entrySet()) &#123; System.out.println(enumTest2.getKey()+"---"+enumTest2.getValue());&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多态学习]]></title>
    <url>%2F2017%2F07%2F25%2Fjava%E5%A4%9A%E6%80%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[在java多态中，引用与对象可以是不同的类型，如: 1A b=new B(); 运用多态时，引用类型可以是实际对象类型的父类，即实际对象类型已经是一个比较具体的类，而引用类型则是一个比较抽象的类，任何extends过声明引用类型的对象都可以赋值给这个引用变量，这样就可以做出类似动态数组的东西，如下: 123456Animal[] a=new Animal[2];a[0]=new Dog();a[1]=new Cat();for(int i=0;i&lt;a.length;i++)&#123; a[i].eat();&#125; a数组里面可以放任何Animal的子类对象，调用的时候可以把子类都当作Animal来操作，实际上调用的是子类的方法，是不是很好玩呢→_→ 当然，多态的应用很广泛呢，参数和返回类型也可以多态，如下: 1234567891011121314151617class Vet&#123; public void giveShot(Anmial a)&#123; a.makeNoise(); &#125;&#125;class Pet&#123; public void a()&#123; Vet v=new Vet(); Dog dog=new Dog(); Cat cat=new Cat(); v.giveShot(dog); v.giveShot(cat); &#125;&#125; giveShot会接受任何Animal的子类的对象实例，根据传入的参数不同，会调用不同对象的方法。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于java中的泛型与反射构建通用DAO层]]></title>
    <url>%2F2017%2F07%2F23%2F%E5%9F%BA%E4%BA%8Ejava%E4%B8%AD%E7%9A%84%E6%B3%9B%E5%9E%8B%E4%B8%8E%E5%8F%8D%E5%B0%84%E6%9E%84%E5%BB%BA%E9%80%9A%E7%94%A8DAO%E5%B1%82%2F</url>
    <content type="text"><![CDATA[在利用hibernate写通用DAO层时需要获取泛型的类型，比如我在写hql的update语句时需要获取泛型的实体类，由于泛型有擦除机制，所以与需要在运行过程中获取泛型的类型产生了矛盾。此时需要利用反射机制来实现此功能，下面来看一个小例子。 首先建一个实体类Dog1234567891011121314151617181920212223import java.io.Serializable;public class Dog implements Serializable &#123; private static final long serialVersionUID = 8108340856807454651L; private int age; private String name; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 然后写一个基类，在此类中可以获取泛型的类型1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.han.one;import java.lang.reflect.Field;import java.lang.reflect.ParameterizedType;import java.util.HashMap;import java.util.Map;/** * 通过反射获取泛型实例 */public class Genericity&lt;T&gt; &#123; @SuppressWarnings("rawtypes") protected Class clazz; @SuppressWarnings("unchecked") /** * 把泛型的参数提取出来的过程放入到构造函数中写，因为 * 当子类创建对象的时候，直接调用父类的构造函数 */ public Genericity() &#123; // 通过反射机制获取子类传递过来的实体类的类型信息 ParameterizedType type = (ParameterizedType) this.getClass().getGenericSuperclass(); //得到t的实际类型 clazz = (Class&lt;T&gt;) type.getActualTypeArguments()[0]; &#125; /** * 获取指定实例的所有属性名及对应值的Map实例 * @param entity 实例 * @return 字段名及对应值的Map实例 */ protected Map&lt;String, Object&gt; getFieldValueMap(T entity) &#123; // key是属性名，value是对应值 Map&lt;String, Object&gt; fieldValueMap = new HashMap&lt;String, Object&gt;(); // 获取当前加载的实体类中所有属性 Field[] fields = this.clazz.getDeclaredFields(); for (int i = 0; i &lt; fields.length; i++) &#123; Field f = fields[i]; // 属性名 String key = f.getName(); //属性值 Object value = null; // 忽略序列化版本ID号 if (! "serialVersionUID".equals(key)) &#123; // 取消Java语言访问检查 f.setAccessible(true); try &#123; value =f.get(entity); &#125; catch (IllegalArgumentException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; fieldValueMap.put(key, value); &#125; &#125; return fieldValueMap; &#125;&#125; 在此类的构造方法中利用反射获取子类传递过来的实体类的类型信息，getFieldValueMap方法用于获取该实体类的属性信息 最后写一个测试类12345678910111213141516171819202122232425262728293031package com.han.one;import java.util.Map;import java.util.Set;/** * 测试：通过反射获取运行过程中泛型实例 * */public class GenericityTest extends Genericity&lt;Dog&gt; &#123; public static void main(String[] args) &#123; GenericityTest gt = new GenericityTest(); //赋值 Dog dd = new Dog(); dd.setAge(1); dd.setName("旺财"); Map&lt;String,Object&gt; map = gt.getFieldValueMap(dd); //遍历 Set&lt;Map.Entry&lt;String, Object&gt;&gt; entrySet = map.entrySet(); for (Map.Entry&lt;String, Object&gt; entry : entrySet) &#123; String key = entry.getKey(); Object value = entry.getValue(); System.out.println(key + "---" + value); &#125; &#125;&#125; 在这个测试类中，此类继承基类，并向其传递实体类，这样在父类中就可以通过反射获取泛型的类型了。 以此为基础，就可以构建通用的DAO了，代码如下：12345678910111213141516171819202122232425public class BaseDaoImpl&lt;T&gt; implements IBaseDao&lt;T&gt; &#123; @Autowired private SessionFactory sessionFactory; @SuppressWarnings("rawtypes") private final Class clazz; @SuppressWarnings("unchecked") public BaseDaoImpl() &#123; // 通过反射机制获取子类传递过来的实体类的类型信息 ParameterizedType type = (ParameterizedType) this.getClass().getGenericSuperclass(); clazz = (Class&lt;T&gt;) type.getActualTypeArguments()[0]; &#125; @Override public boolean update(T t) &#123; StringBuffer stringBuffer = new StringBuffer(); stringBuffer.append("update " + this.clazz.getSimpleName()); stringBuffer.append(" u set u.itemTitle=:itemTitle ,u.itemContent=:itemContent,u.addTime=:addTime,u.isImage=:isImage,u.isPublish=:isPublish,u.author=:author where u.id=:id"); System.out.println(stringBuffer.toString()); Query query = sessionFactory.getCurrentSession().createQuery(stringBuffer.toString()); query.setProperties(t); return (query.executeUpdate()&gt;0); &#125;&#125; 这里只是在update方法中利用反射获取实体类，通过拼装hql语句来达到重用目的，当然参数也可以动态获取，这里只是个小例子。 总结 java中泛型与反射的应用很广泛，想要完全掌握不是那么容易，多写多练是比较好的方式^_^]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于首页feed流如何展示和数据库如何设计问题]]></title>
    <url>%2F2017%2F07%2F15%2F%E5%85%B3%E4%BA%8E%E9%A6%96%E9%A1%B5feed%E6%B5%81%E5%A6%82%E4%BD%95%E5%B1%95%E7%A4%BA%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近在做一个简单的问答网站，首页的内容需要根据用户关注的话题和关注的问题等来展示最新的动态信息，刚开始的时候我想数据库表的设计是关键。 这里涉及到两个概念 推模式（push）和拉模式（pull），这里有两篇大神分享的知识 新浪微博架构和FEED架构分析–人人架构paper0023新浪博客和微博feed系统的推(push)模式和拉(pull)模式和时间分区拉模式架构探讨，讲解的比较清楚 简单来说，什么是推，什么是拉呢？ 推模式是一个用户发表了一条动态，那么后台就遍历关注该用户的所有用户，向他们的feed中推送一条动态 拉模式与推模式相反，当用户刷新首页时，后台会遍历该用户关注的用户的动态信息，并将动态信息压入到该用户的feed中 简单介绍完推拉模式后，下面就要考虑数据库表该怎么设计了，我采用的是最简单的推模式，毕竟新手嘛，先掌握实现流程。 首先设计feed表，这里我设计一个feed表来存储推送的信息，该表主要有以下几个字段 id 自增id suid 推送者uid ruid 接收者uid item_id 推送的信息id type 推送信息类型 add_time 推送时间 这是我感觉很简单的feed表，毕竟我那个问答站推送类型不是太多，当然还需要为这个表设计索引哦。设计完数据库表后，下面该考虑后台推送逻辑和代码如何实现以及前台首页如何渲染feed流信息。 后台我用的是PHP的ThinkPHP框架，新手表示该框架很好用，用该框架可以快速实现的我的想法，我感觉这一点还是很好的。首先在推送类型的选择中我选择了以下几种推送类型 当一个话题下有新话题发起时，推送给关注该话题的用户 当一个问题有回答时，推送给关注该问题的用户 当一个话题的问题有新回答时，推送给关注该话题的用户 上面推送过程中会产生大量的重复信息，所以需要在推送时对推送信息进行过滤，以避免重复的推送信息出现。代码就是当上面的推送类型产生时，将信息写入到feed表中，这里并没有对推送用户进行筛选（对推送用户的筛选可以降低数据库的压力）。 前台渲染的话需要对信息进行排序整合，并对每一条动态信息进行标记，以便在模板渲染时匹配对应的模板。我写的简单部分整合代码，需要对信息进行遍历整合（这里没写） //如果推送类型 为a 则代表推送信息类型为 用户关注的话题有关的问题或关注的问题产生的回答 $aid=$val[&apos;item_id&apos;]; /**根据回答id获取获取与此回答有关的信息**/ //获取推送人的uid $suid=$val[&apos;suid&apos;]; //获取当前用户对回答的赞同状态 $upvote_status=$this-&gt;getUpvoteStatusByAid($aid, $uid); //获取feed流 回答信息 $a_info_all=$this-&gt;getFeedAnswerInfo($aid); $question_id=$a_info_all[0][&apos;question_id&apos;]; //根据问题id获取与此问题相关的话题信息 $tinfo_a=D(&apos;Topic&apos;)-&gt;getFeedTopicByQuestion($question_id); //将话题信息追加到回答信息数组中 $a_info_all[0][&apos;topic&apos;]= $tinfo_a; //将当前用户对回答的赞同状态最佳到信息数组中 $a_info_all[0][&apos;upvote_status&apos;]=$upvote_status; //将整理后的信息添加到feed数组中，并做一个标记 a,以便在模板中判断解析 $arr_fd[&apos;answer&apos;]=$a_info_all; $arr_fd[&apos;feed_flag&apos;]=&apos;a&apos;; $feed_return_arr[]= $arr_fd; 这里 $feed_return_arr[]是一个三维数组，在模板渲染的时候要注意一下。上面是我对feed流简单的思考，如果是真实网络环境下这种简单的实现有许多大问题，比如feed表数据量过大，是否设定一个时间阀对表中超过该时间阀的推送信息进行删除以减少feed表的记录量等等。所以这种方式并不适合真实的网络环境，需要将推拉模式结合进行使用。]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用uploadify插件上传文件时java后台获取不到当前session问题]]></title>
    <url>%2F2017%2F07%2F10%2F%E5%88%A9%E7%94%A8uploadify%E6%8F%92%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%97%B6java%E5%90%8E%E5%8F%B0%E8%8E%B7%E5%8F%96%E4%B8%8D%E5%88%B0%E5%BD%93%E5%89%8Dsession%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[我在利用uploadify插件上传文件时发现java后台获取不到当前用户的session值，即当前的用户的session保存的信息失效，导致拦截器将上传请求拦截，这里的拦截器主要对登录的信息进行拦截验证，正因为此原因，导致上传文件失败，后来在利用firebug查找请求的时候，发现uploadify插件会自动生成一个新的session，导致原来的session失效，解决方法是将jsessionid通过url传到后台，这样后台就能识别当前session，问题也就解决了。代码如下： 12345$("#uploadify").uploadify(&#123; debug : false, swf : CTPPATH+'/admin/static/uploadify/js/uploadify.swf', //swf文件路径 method : 'get', // 提交方式 uploader : CTPPATH+'/processUpload.ado;jsessionid=$&#123;pageContext.session.id&#125;', // 服务器端处理该上传请求的程序(servlet, struts2-Action) )&#125;; 代码中有许多属性这里没有贴出来，这里主要看uploader属性，uploader属性为CTPPATH+’/processUpload.ado;jsessionid=${pageContext.session.id}’，即在请求url中附上;jsessionid=${pageContext.session.id}，这样上传就没问题了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站消息推送之long polling（长轮询）初探]]></title>
    <url>%2F2017%2F07%2F09%2F%E7%BD%91%E7%AB%99%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E4%B9%8Blong%20polling%EF%BC%88%E9%95%BF%E8%BD%AE%E8%AF%A2%EF%BC%89%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[网站的消息推送功能应用很广泛，比如论坛，问答网站等等都需要推送消息，那么采用什么样的推送方式更加便捷，更加节省服务器资源呢，这个需要根据网站的流量和规模来决定，因为long polling是我最先接触到的，我就来谈谈它吧。 长轮询初看像是轮流查询的意思，其实不是，它是客户端通过ajax发出请求，然后客户端挂起，等待服务器端响应，服务器端会检测有无新消息，如果有消息，服务器端会将新消息推送给客户端，结束本次请求，如果在有效请求期内没有新消息出现，那么会一直检测有无新消息出现。连接会保持一段时间周期直到数据或状态改变或者时间过期，通过这种机制来减少无效的客户端和服务器间的交互。 虽然长轮循比传统的轮询性能会有些提高，但在服务器端数据变化非常频繁的情况下，两者的性能并不能差多少，因为都是客户端先请求，服务器再响应，只是两者服务器端响应的机制不同。下面来说说代码，服务器端我用的是php，客户端用的是jQuery 服务器端代码： 12345678910111213141516171819202122232425262728293031/** * @desc ajax长轮询 来获取通知消息信息 * @return 通知信息数量&gt;o */public function longPolling() &#123; if(!$_GET['timed']) exit(); date_default_timezone_set("PRC"); session_write_close(); //防止session访问互斥问题 set_time_limit(0);//无限请求超时时间 $timed = $_GET['timed']; while (true) &#123; sleep(3); // 休眠3秒 //判断有无新通知出现 $no_count=D('Notifications')-&gt;getNotificationsCount($this-&gt;uid); if ($no_count&gt;0) &#123; $responseTime = time(); // 返回数据信息，请求时间、返回数据时间、耗时 $content=array( 'result' =&gt;$no_count, 'reponse_time' =&gt;$responseTime, 'request_time' =&gt;$timed, 'use_time' =&gt;($responseTime - $timed) ); echo $this-&gt;ajaxReturn($content); exit(); &#125; else &#123; // 模拟没有数据变化，将休眠 hold住连接 sleep(13); exit(); &#125; &#125;&#125; 从服务器段代码可以看出，里面有个while(true){}死循环，只有有新信息或者连接失效时会退出循环。 客户端代码：123456789101112131415161718192021222324252627282930$(function()&#123; /** * 消息的处理 递归调用 */ (function longPolling() &#123; $.ajax(&#123; url: MODULE+"/Notifications/longPoll", data: &#123;"timed": Date.parse(new Date())/1000&#125;, dataType: "json", timeout: 70000,//单位毫秒 error: function (XMLHttpRequest, textStatus, errorThrown) &#123; if (textStatus == "timeout") &#123; // 请求超时 longPolling(); // 递归调用 &#125; else &#123; // 其他错误，如网络错误等 longPolling(); &#125; &#125;, success: function (data, textStatus) &#123; //此时已有消息过来了，将消息数量显示 $('.nav-counter').text(data.result); if (textStatus == "success") &#123; // 请求成功，继续请求 longPolling(); &#125; &#125; &#125;); &#125;)();&#125;); 客户端代码调用ajax进行处理，逻辑已经很清楚了。 以上就是我对long polling的理解，虽然长轮询较轮询有了不错的改进，但还是会消耗很多的服务器资源，并不是十分理想的网站消息推送方案。]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php json_encode函数使用遇到的问题]]></title>
    <url>%2F2017%2F07%2F01%2Fphp%20%20json_encode%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在php中有一个函数可以将数组转化为json数据存储格式，这个函数就是json_encode但在使用这个函数时转化的格式不一致，比如：1234567891011121314//关联二位数组$a2=array( '1'=&gt;array('name'=&gt;'john','age'=&gt;'32'), '2'=&gt;array('name'=&gt;'tom','age'=&gt;'22'));$json2=json_encode($a2);echo $json2."&lt;br&gt;"; //&#123;"1":&#123;"name":"john","age":"32"&#125;,"2":&#123;"name":"tom","age":"22"&#125;&#125;//索引二维数组$a3=array( array('name'=&gt;'zz','age'=&gt;'31'), array('name'=&gt;'we','AGE'=&gt;'12') ); $json3=json_encode($a3); echo $json3."&lt;br&gt;";//[&#123;"name":"zz","age":"31"&#125;,&#123;"name":"we","AGE":"12"&#125;] 关联二维数组和索引二维数组转化为json数据格式不同，这时在前台用js解析json的时候就有差别 对于关联数组生成的json数据格式 ，在前台直接用js的eval()将其转化为json对象，然后根据{key:value}取值 对于索引数组生成的json数据格式，用js的eval()转为json对象后，由于[]代表数组格式，所以遇到[]还是按照数组取值，遇到{key:value}这种形式的按照对象取值就行了 当数组维数多的时候需要根据转换后的json数据格式用js进行相应的解析，避免出错。]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaweb下载文件时IE浏览器下报错问题]]></title>
    <url>%2F2017%2F06%2F15%2Fjavaweb%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%97%B6IE%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%8B%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近做的网站的一个下载功能出现了问题，在firefox浏览器以及360浏览器下下载均正常，也能将中文正常转换，但在IE浏览器下却出现了问题，当点击下载链接的时候，后台直接报错：后台我怎么兼容也不能解决问题，我下载的部分java代码： 进过我仔细查找，发现我前台通过get方式提交的文件名包含一下字符，导致浏览器解析url不一致，所以需要将url通过javascript进行转码，即用encodeURIComponent函数进行编码，代码如下 1&lt;a href="javascript:location.href='$&#123;pageContext.request.contextPath&#125;/download.do?realname='+encodeURIComponent('$&#123;file_list.real_name&#125;')+'&amp;filename='+encodeURIComponent('$&#123;file_list.file_name&#125;');" class="file-name"&gt;$&#123;file_list.file_name&#125;&lt;/a&gt; 通过将文件名编码之后就能解决问题了]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaee 配置Tomcat数据源问题]]></title>
    <url>%2F2017%2F06%2F08%2Fjavaee%20%E9%85%8D%E7%BD%AETomcat%E6%95%B0%E6%8D%AE%E6%BA%90%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近用javaee写网站配置数据源时遇到了这个错误: java.lang.ClassCastException: org.apache.tomcat.dbcp.dbcp.PoolingDataSource$PoolGuardConnectionWrapper cannot be cast to com.mysql.jdbc.Connection 经过我查看代码发现有些类中包导错了，涉及到数据库的包应该导入java.sql.*这个相关的，而我用ide自动导入为jdbc那个了，发生了类型不匹配问题，改掉就不会报这个错了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown-01]]></title>
    <url>%2F2017%2F06%2F07%2Fmarkdown-01%2F</url>
    <content type="text"><![CDATA[试试一下markdowm 这是一个标题 这是第一行列表项 这是第二行列表项 列表Markdown 支持有序列表和无序列表。 无序列表使用星号、加号或是减号作为列表标记： * Red * Green * Blue 等同于： + Red + Green + Blue 也等同于： - Red - Green - Blue 有序列表则使用数字接着一个英文句点： 1. Bird 2. McHale 3. Parish 代码区块markdown使用 来将代码包裹起来 分割线 链接1System.out.println(&quot;helllo world&quot;); 1[This link](http://example.net/) has no title attribute. This link has no title attribute. 强调Markdown 使用星号（）和底线（_）作为标记强调字词的符号，被 或 包围的字词会被转成用 标签包围，用两个 * 或 包起来的话，则会被转成 ，例如：1234567*single asterisks*_single underscores_**double asterisks**__double underscores__ 会转成：1234567&lt;em&gt;single asterisks&lt;/em&gt;&lt;em&gt;single underscores&lt;/em&gt;&lt;strong&gt;double asterisks&lt;/strong&gt;&lt;strong&gt;double underscores&lt;/strong&gt;]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaee 配置数据源后数据库连接未及时关闭出现的问题]]></title>
    <url>%2F2017%2F06%2F06%2Fjavaee%20%20%E9%85%8D%E7%BD%AE%E6%95%B0%E6%8D%AE%E6%BA%90%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%9C%AA%E5%8F%8A%E6%97%B6%E5%85%B3%E9%97%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[我在配置要数据源后没有仔细检查我的代码，有些数据库连接没有及时关闭，报以下异常: org.apache.tomcat.dbcp.dbcp.SQLNestedException: Cannot get a connection, pool error Timeout waiting for idle objec 这个异常产生的原因是在使用完数据库连接后没有及时关闭，导致数据库连接池的连接没有可供使用的连接，进而报异常。解决的方法是检查代码，将数据库连接及时关闭，并且在context.xml文件中加上 removeAbandoned=”true” removeAbandonedTimeout=”60”logAbandoned=”true” 这样就解决问题了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F05%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
